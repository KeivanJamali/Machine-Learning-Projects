{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "folder = r\"data/Anaheim/Scaled/random_0/10\"\n",
    "attraction = pd.read_csv(f'{folder}/attraction.csv')\n",
    "production = pd.read_csv(f'{folder}/production.csv')\n",
    "real_od_matrix = pd.read_csv(f'{folder}/real_od_matrix.csv', index_col=0)\n",
    "travel_time = pd.read_csv(f'{folder}/travel_time_matrix.csv', index_col=0)\n",
    "train_od_matrix = pd.read_csv(f'{folder}/at_miss0.10_train_od_matrix.csv', index_col=0)\n",
    "val_od_matrix = pd.read_csv(f'{folder}/at_miss0.10_val_od_matrix.csv', index_col=0)\n",
    "test_od_matrix = pd.read_csv(f'{folder}/at_miss0.10_test_od_matrix.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1024001416.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 24\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class Dataloader(Dataset):\n",
    "    def __init__(self, root, transformer=None, pre_transformer=None):\n",
    "        \"\"\" \n",
    "        root = where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processesd_dir (processed data)\n",
    "        \"\"\"\n",
    "        super(Dataloader, self).__init__(root, transformer, pre_transformer)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" if this file exists in the raw_dir, the download is not triggered.\n",
    "        \"\"\"\n",
    "        return \"attraction.csv\", \"production.csv\", \"real_od_matrix.csv\", \"travel_time_matrix.csv\", \"at_miss0.10_train_od_matrix.csv\", \"at_miss0.10_val_od_matrix.csv\", \"at_miss0.10_test_od_matrix.csv\"\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in raw_dir, processing will skiped.\"\"\"\n",
    "        return \"not_implemented.pt\"\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(real_od_matrix\u001b[38;5;241m.\u001b[39miloc[i, j])\n\u001b[0;32m     36\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(edge_index, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m---> 37\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Create masks for train, validation, and test\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "folder = r\"data/Anaheim/Scaled/random_0/10\"\n",
    "attraction = pd.read_csv(f'{folder}/attraction.csv')\n",
    "production = pd.read_csv(f'{folder}/production.csv')\n",
    "real_od_matrix = pd.read_csv(f'{folder}/real_od_matrix.csv', index_col=0)\n",
    "travel_time = pd.read_csv(f'{folder}/travel_time_matrix.csv', index_col=0)\n",
    "train_od_matrix = pd.read_csv(f'{folder}/at_miss0.10_train_od_matrix.csv', index_col=0)\n",
    "val_od_matrix = pd.read_csv(f'{folder}/at_miss0.10_val_od_matrix.csv', index_col=0)\n",
    "test_od_matrix = pd.read_csv(f'{folder}/at_miss0.10_test_od_matrix.csv', index_col=0)\n",
    "\n",
    "# Prepare node features\n",
    "node_features = np.vstack((attraction[\"0\"].values, production[\"0\"].values)).T\n",
    "\n",
    "# Prepare edge index and edge attributes\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "labels = []\n",
    "for i in range(travel_time.shape[0]):\n",
    "    for j in range(travel_time.shape[1]):\n",
    "        if i != j:  # Assuming no self-loops\n",
    "            edge_index.append([i, j])\n",
    "            if train_od_matrix.iloc[i, j] in [\"False\", \"No_connection\"]:\n",
    "                edge_attr.append([travel_time.iloc[i, j]])\n",
    "            else:\n",
    "                edge_attr.append([travel_time.iloc[i, j], float(train_od_matrix.iloc[i, j])])\n",
    "            labels.append(real_od_matrix.iloc[i, j])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "# Create masks for train, validation, and test\n",
    "train_mask = []\n",
    "val_mask = []\n",
    "test_mask = []\n",
    "for i in range(train_od_matrix.shape[0]):\n",
    "    for j in range(train_od_matrix.shape[1]):\n",
    "        if i != j:  # Assuming no self-loops\n",
    "            train_mask.append(train_od_matrix.iloc[i, j] != \"False\" and train_od_matrix.iloc[i, j] != \"No_connection\")\n",
    "            val_mask.append(val_od_matrix.iloc[i, j] != \"False\" and val_od_matrix.iloc[i, j] != \"No_connection\")\n",
    "            test_mask.append(test_od_matrix.iloc[i, j] != \"False\" and test_od_matrix.iloc[i, j] != \"No_connection\")\n",
    "\n",
    "train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "test_mask = torch.tensor(test_mask, dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 16)\n",
    "        self.conv2 = GCNConv(16, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads=1):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, 16, heads=heads)\n",
    "        self.conv2 = GATConv(16 * heads, out_channels, heads=1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion, mask):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_attr).view(-1)\n",
    "    loss = criterion(out[mask], data.y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data, mask):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_attr).view(-1)\n",
    "    pred = out[mask].detach().cpu().numpy()\n",
    "    true = data.y[mask].detach().cpu().numpy()\n",
    "    return r2_score(true, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2286386638879776, Validation R²: -93.13689324207938\n",
      "Epoch 100, Loss: 0.005003111436963081, Validation R²: -0.22499677682995234\n",
      "Epoch 200, Loss: 0.004984183702617884, Validation R²: -0.20265408230275272\n",
      "Epoch 300, Loss: 0.004963832441717386, Validation R²: -0.18858898373962285\n",
      "Epoch 400, Loss: 0.004943173378705978, Validation R²: -0.17511712999346285\n",
      "Epoch 500, Loss: 0.004923421889543533, Validation R²: -0.1632392757301766\n",
      "Epoch 600, Loss: 0.004905179142951965, Validation R²: -0.15343754956477862\n",
      "Epoch 700, Loss: 0.004888656083494425, Validation R²: -0.14583521941671873\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgcn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     15\u001b[0m         val_r2 \u001b[38;5;241m=\u001b[39m test(gcn_model, data, val_mask)\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, optimizer, criterion, mask)\u001b[0m\n\u001b[0;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[mask], data\u001b[38;5;241m.\u001b[39my[mask])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare the data object\n",
    "data = Data(x=torch.tensor(node_features, dtype=torch.float),\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=labels)\n",
    "\n",
    "# Train GCN\n",
    "gcn_model = GCN(in_channels=2, out_channels=37)\n",
    "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss = train(gcn_model, data, optimizer, criterion, train_mask)\n",
    "    if epoch % 100 == 0:\n",
    "        val_r2 = test(gcn_model, data, val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss}, Validation R²: {val_r2}')\n",
    "\n",
    "# Evaluate GCN\n",
    "test_r2 = test(gcn_model, data, test_mask)\n",
    "print(f'GCN Test R²: {test_r2}')\n",
    "\n",
    "# Train GAT\n",
    "gat_model = GAT(in_channels=2, out_channels=37)\n",
    "optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(10000):\n",
    "    loss = train(gat_model, data, optimizer, criterion, train_mask)\n",
    "    if epoch % 100 == 0:\n",
    "        val_r2 = test(gat_model, data, val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss}, Validation R²: {val_r2}')\n",
    "\n",
    "# Evaluate GAT\n",
    "test_r2 = test(gat_model, data, test_mask)\n",
    "print(f'GAT Test R²: {test_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1406/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.46369633078575134, Validation R²: -200.97040817734933\n",
      "Epoch 100, Loss: 0.004774666391313076, Validation R²: -0.2133450190961601\n",
      "Epoch 200, Loss: 0.004762969445437193, Validation R²: -0.1925298427379265\n",
      "Epoch 300, Loss: 0.004750616382807493, Validation R²: -0.18980318828436915\n",
      "Epoch 400, Loss: 0.004737409297376871, Validation R²: -0.18707524853999957\n",
      "Epoch 500, Loss: 0.004724108148366213, Validation R²: -0.18455535077891327\n",
      "Epoch 600, Loss: 0.004711231216788292, Validation R²: -0.18236438797256227\n",
      "Epoch 700, Loss: 0.004699103068560362, Validation R²: -0.18056557703969256\n",
      "Epoch 800, Loss: 0.004687908571213484, Validation R²: -0.1791806222292751\n",
      "Epoch 900, Loss: 0.004677723161876202, Validation R²: -0.17820593607038004\n",
      "Epoch 1000, Loss: 0.0046685440465807915, Validation R²: -0.17761839073256858\n",
      "Epoch 1100, Loss: 0.004660314414650202, Validation R²: -0.1773858100732164\n",
      "Epoch 1200, Loss: 0.0046529462561011314, Validation R²: -0.17747365501151458\n",
      "Epoch 1300, Loss: 0.0046463338658213615, Validation R²: -0.17784390149939222\n",
      "Epoch 1400, Loss: 0.004640365485101938, Validation R²: -0.1784628874120946\n",
      "Epoch 1500, Loss: 0.004634929355233908, Validation R²: -0.1792982703570114\n",
      "Epoch 1600, Loss: 0.004629920236766338, Validation R²: -0.18032404714358097\n",
      "Epoch 1700, Loss: 0.004625238012522459, Validation R²: -0.18151615429392365\n",
      "Epoch 1800, Loss: 0.004620786290615797, Validation R²: -0.18285686963916348\n",
      "Epoch 1900, Loss: 0.004616471938788891, Validation R²: -0.18432969126407261\n",
      "Epoch 2000, Loss: 0.004612238612025976, Validation R²: -0.18593513391771155\n",
      "Epoch 2100, Loss: 0.004608118906617165, Validation R²: -0.18780810019415695\n",
      "Epoch 2200, Loss: 0.004603919107466936, Validation R²: -0.18968161216091106\n",
      "Epoch 2300, Loss: 0.004599538631737232, Validation R²: -0.19172824386108211\n",
      "Epoch 2400, Loss: 0.004594867117702961, Validation R²: -0.19375504881512318\n",
      "Epoch 2500, Loss: 0.0045897820964455605, Validation R²: -0.19576901079665676\n",
      "Epoch 2600, Loss: 0.004584142938256264, Validation R²: -0.1982057090535836\n",
      "Epoch 2700, Loss: 0.004577788058668375, Validation R²: -0.20040105574381295\n",
      "Epoch 2800, Loss: 0.004570540506392717, Validation R²: -0.20315704359544262\n",
      "Epoch 2900, Loss: 0.004562194924801588, Validation R²: -0.20578428218635136\n",
      "Epoch 3000, Loss: 0.004552541300654411, Validation R²: -0.2085354660571741\n",
      "Epoch 3100, Loss: 0.004542139824479818, Validation R²: -0.21141584553107373\n",
      "Epoch 3200, Loss: 0.0045309485867619514, Validation R²: -0.21529664654726388\n",
      "Epoch 3300, Loss: 0.004518924746662378, Validation R²: -0.21968530575368805\n",
      "Epoch 3400, Loss: 0.004506260622292757, Validation R²: -0.22340961053480712\n",
      "Epoch 3500, Loss: 0.004493827931582928, Validation R²: -0.22787426460328963\n",
      "Epoch 3600, Loss: 0.004482663702219725, Validation R²: -0.24125307386040973\n",
      "Epoch 3700, Loss: 0.004469160921871662, Validation R²: -0.21850932605018403\n",
      "Epoch 3800, Loss: 0.0044557699002325535, Validation R²: -0.23875892388356834\n",
      "Epoch 3900, Loss: 0.00444412836804986, Validation R²: -0.22336961757318696\n",
      "Epoch 4000, Loss: 0.00443077739328146, Validation R²: -0.23211821482774853\n",
      "Epoch 4100, Loss: 0.004417563322931528, Validation R²: -0.23714191048836009\n",
      "Epoch 4200, Loss: 0.004405036568641663, Validation R²: -0.24030375336903753\n",
      "Epoch 4300, Loss: 0.004403062630444765, Validation R²: -0.26118173255372623\n",
      "Epoch 4400, Loss: 0.004380342084914446, Validation R²: -0.24619691214941453\n",
      "Epoch 4500, Loss: 0.00436220271512866, Validation R²: -0.22445273982429526\n",
      "Epoch 4600, Loss: 0.004344781395047903, Validation R²: -0.2435133764719548\n",
      "Epoch 4700, Loss: 0.004325789865106344, Validation R²: -0.24033387085089464\n",
      "Epoch 4800, Loss: 0.004305664915591478, Validation R²: -0.2384095561984294\n",
      "Epoch 4900, Loss: 0.004285299219191074, Validation R²: -0.23024727776277887\n",
      "Epoch 5000, Loss: 0.004276110325008631, Validation R²: -0.2730643426442194\n",
      "Epoch 5100, Loss: 0.004268610384315252, Validation R²: -0.16465202755183972\n",
      "Epoch 5200, Loss: 0.0042191157117486, Validation R²: -0.23379880681476317\n",
      "Epoch 5300, Loss: 0.004218354355543852, Validation R²: -0.18530461526006303\n",
      "Epoch 5400, Loss: 0.004167730920016766, Validation R²: -0.25128550186350784\n",
      "Epoch 5500, Loss: 0.004140980076044798, Validation R²: -0.23198992925888295\n",
      "Epoch 5600, Loss: 0.004115879535675049, Validation R²: -0.23190940650893888\n",
      "Epoch 5700, Loss: 0.004092182498425245, Validation R²: -0.25381151417618986\n",
      "Epoch 5800, Loss: 0.00429921830072999, Validation R²: -0.09813269416745762\n",
      "Epoch 5900, Loss: 0.004041759297251701, Validation R²: -0.270874587514939\n",
      "Epoch 6000, Loss: 0.004032149910926819, Validation R²: -0.30813183826167423\n",
      "Epoch 6100, Loss: 0.003991133999079466, Validation R²: -0.26422229481015647\n",
      "Epoch 6200, Loss: 0.003969585057348013, Validation R²: -0.22755443966938516\n",
      "Epoch 6300, Loss: 0.003948110621422529, Validation R²: -0.2904831716989842\n",
      "Epoch 6400, Loss: 0.00391707569360733, Validation R²: -0.26822784581149905\n",
      "Epoch 6500, Loss: 0.0038944680709391832, Validation R²: -0.24898857210318615\n",
      "Epoch 6600, Loss: 0.0038798064924776554, Validation R²: -0.16920185269396049\n",
      "Epoch 6700, Loss: 0.0038458677008748055, Validation R²: -0.2555584447140655\n",
      "Epoch 6800, Loss: 0.0038247210904955864, Validation R²: -0.2228054600045577\n",
      "Epoch 6900, Loss: 0.003799700178205967, Validation R²: -0.24816104580978893\n",
      "Epoch 7000, Loss: 0.0037805039901286364, Validation R²: -0.29294780466305714\n",
      "Epoch 7100, Loss: 0.003800320206210017, Validation R²: -0.15572178246155\n",
      "Epoch 7200, Loss: 0.003931214101612568, Validation R²: -0.4566472624548099\n",
      "Epoch 7300, Loss: 0.0036986302584409714, Validation R²: -0.23550744961277204\n",
      "Epoch 7400, Loss: 0.0038654173258692026, Validation R²: -0.5855790521341557\n",
      "Epoch 7500, Loss: 0.0036549975629895926, Validation R²: -0.24956280076072845\n",
      "Epoch 7600, Loss: 0.0036448633763939142, Validation R²: -0.3145437704671903\n",
      "Epoch 7700, Loss: 0.0037093523424118757, Validation R²: -0.43599896578168695\n",
      "Epoch 7800, Loss: 0.003589172149077058, Validation R²: -0.28143851144327936\n",
      "Epoch 7900, Loss: 0.00356091745197773, Validation R²: -0.17885023429599056\n",
      "Epoch 8000, Loss: 0.003563133766874671, Validation R²: -0.34833550997868357\n",
      "Epoch 8100, Loss: 0.003502319101244211, Validation R²: -0.27344849005996896\n",
      "Epoch 8200, Loss: 0.0035156765952706337, Validation R²: -0.1596729367634282\n",
      "Epoch 8300, Loss: 0.003458095481619239, Validation R²: -0.28895353631360043\n",
      "Epoch 8400, Loss: 0.0034608638379722834, Validation R²: -0.08220844723955123\n",
      "Epoch 8500, Loss: 0.003440683474764228, Validation R²: -0.35896021393513067\n",
      "Epoch 8600, Loss: 0.0033754559699445963, Validation R²: -0.23245252912429115\n",
      "Epoch 8700, Loss: 0.0033832264598459005, Validation R²: -0.3833868989046143\n",
      "Epoch 8800, Loss: 0.0036122684832662344, Validation R²: -0.027283231702546873\n",
      "Epoch 8900, Loss: 0.003313819644972682, Validation R²: -0.27174018889941887\n",
      "Epoch 9000, Loss: 0.0035144402645528316, Validation R²: -0.7545595377838143\n",
      "Epoch 9100, Loss: 0.0032490496523678303, Validation R²: -0.20584668635826198\n",
      "Epoch 9200, Loss: 0.0032313873525708914, Validation R²: -0.21852455395820103\n",
      "Epoch 9300, Loss: 0.003229530295357108, Validation R²: -0.09264944505713957\n",
      "Epoch 9400, Loss: 0.003179766470566392, Validation R²: -0.1672352570010427\n",
      "Epoch 9500, Loss: 0.003160132560878992, Validation R²: -0.16501594848151502\n",
      "Epoch 9600, Loss: 0.003180526429787278, Validation R²: -0.2803122255144621\n",
      "Epoch 9700, Loss: 0.0031416791025549173, Validation R²: -0.07314432305301177\n",
      "Epoch 9800, Loss: 0.003249378642067313, Validation R²: -0.06249632466781607\n",
      "Epoch 9900, Loss: 0.0030610645189881325, Validation R²: -0.16883871292467956\n",
      "Epoch 10000, Loss: 0.0030646047089248896, Validation R²: -0.225453370792003\n",
      "Epoch 10100, Loss: 0.0030654924921691418, Validation R²: -0.09255237089246293\n",
      "Epoch 10200, Loss: 0.0029972929041832685, Validation R²: -0.14466502044003904\n",
      "Epoch 10300, Loss: 0.002976921619847417, Validation R²: -0.14671095504986398\n",
      "Epoch 10400, Loss: 0.0029847989790141582, Validation R²: -0.20424536557120088\n",
      "Epoch 10500, Loss: 0.0029340265318751335, Validation R²: -0.12663487902561155\n",
      "Epoch 10600, Loss: 0.002972254529595375, Validation R²: -0.3220139207066599\n",
      "Epoch 10700, Loss: 0.0028966537211090326, Validation R²: -0.21144457424565122\n",
      "Epoch 10800, Loss: 0.0028722863644361496, Validation R²: -0.11157156267265766\n",
      "Epoch 10900, Loss: 0.0029794443398714066, Validation R²: -0.46279570362797173\n",
      "Epoch 11000, Loss: 0.0030992866959422827, Validation R²: 0.010576311529546745\n",
      "Epoch 11100, Loss: 0.002815324580296874, Validation R²: -0.12717280574501433\n",
      "Epoch 11200, Loss: 0.0029776133596897125, Validation R²: 0.06728728809448425\n",
      "Epoch 11300, Loss: 0.0027815266512334347, Validation R²: -0.12030642416806714\n",
      "Epoch 11400, Loss: 0.0028078402392566204, Validation R²: -0.06178850304474581\n",
      "Epoch 11500, Loss: 0.002751487772911787, Validation R²: -0.17882307028051247\n",
      "Epoch 11600, Loss: 0.0027904182206839323, Validation R²: -0.30406279454904905\n",
      "Epoch 11700, Loss: 0.002725270576775074, Validation R²: -0.03973822653890391\n",
      "Epoch 11800, Loss: 0.002698487602174282, Validation R²: -0.07579226659184846\n",
      "Epoch 11900, Loss: 0.0028519926127046347, Validation R²: -0.1084519729101614\n",
      "Epoch 12000, Loss: 0.002743518678471446, Validation R²: 0.009425077198200293\n",
      "Epoch 12100, Loss: 0.0027822942938655615, Validation R²: 0.05936643565725386\n",
      "Epoch 12200, Loss: 0.004397662356495857, Validation R²: -1.279184128584951\n",
      "Epoch 12300, Loss: 0.0026769728865474463, Validation R²: -0.11552313120891844\n",
      "Epoch 12400, Loss: 0.0026530090253800154, Validation R²: 0.0031219042493793037\n",
      "Epoch 12500, Loss: 0.002598634222522378, Validation R²: -0.06376577110909065\n",
      "Epoch 12600, Loss: 0.0026247063651680946, Validation R²: 0.02890204747108227\n",
      "Epoch 12700, Loss: 0.0026824502274394035, Validation R²: -0.3317670278531404\n",
      "Epoch 12800, Loss: 0.0025579589419066906, Validation R²: -0.10606783177347734\n",
      "Epoch 12900, Loss: 0.002553408034145832, Validation R²: -0.03978630870674671\n",
      "Epoch 13000, Loss: 0.0025337242987006903, Validation R²: -0.060605473803384546\n",
      "Epoch 13100, Loss: 0.002549576573073864, Validation R²: 0.008318992650085844\n",
      "Epoch 13200, Loss: 0.0025359410792589188, Validation R²: -0.18263135691034504\n",
      "Epoch 13300, Loss: 0.003191424999386072, Validation R²: -0.9120942926866391\n",
      "Epoch 13400, Loss: 0.002507856348529458, Validation R²: -0.00765881413016567\n",
      "Epoch 13500, Loss: 0.0024677186738699675, Validation R²: -0.09679024045533491\n",
      "Epoch 13600, Loss: 0.002462562406435609, Validation R²: -0.02372477419692709\n",
      "Epoch 13700, Loss: 0.00248576607555151, Validation R²: -0.24938590710647102\n",
      "Epoch 13800, Loss: 0.0028815781697630882, Validation R²: 0.016386369670595702\n",
      "Epoch 13900, Loss: 0.002419052179902792, Validation R²: -0.0792227025230221\n",
      "Epoch 14000, Loss: 0.0024263139348477125, Validation R²: -0.15361457009598323\n",
      "Epoch 14100, Loss: 0.0036162424366921186, Validation R²: -0.5190952780442208\n",
      "Epoch 14200, Loss: 0.0023884326219558716, Validation R²: -0.07711496714964983\n",
      "Epoch 14300, Loss: 0.0025830871891230345, Validation R²: 0.03507083239341946\n",
      "Epoch 14400, Loss: 0.0023691412061452866, Validation R²: -0.1038287995831082\n",
      "Epoch 14500, Loss: 0.0023564372677356005, Validation R²: -0.05090524836094712\n",
      "Epoch 14600, Loss: 0.002466815523803234, Validation R²: -0.49617247452315394\n",
      "Epoch 14700, Loss: 0.002464586403220892, Validation R²: -0.4108227274149703\n",
      "Epoch 14800, Loss: 0.003015759866684675, Validation R²: -0.9793442555143961\n",
      "Epoch 14900, Loss: 0.00269723660312593, Validation R²: 0.08462004074757845\n",
      "Epoch 15000, Loss: 0.002454702975228429, Validation R²: 0.07193274477492562\n",
      "Epoch 15100, Loss: 0.0023173687513917685, Validation R²: 0.006953603455097324\n",
      "Epoch 15200, Loss: 0.0022999700158834457, Validation R²: -0.023792522074094435\n",
      "Epoch 15300, Loss: 0.0026086154393851757, Validation R²: -0.6021055711509189\n",
      "Epoch 15400, Loss: 0.002295662183314562, Validation R²: -0.21753092785570471\n",
      "Epoch 15500, Loss: 0.0023194490931928158, Validation R²: -0.16765741973926396\n",
      "Epoch 15600, Loss: 0.0022756122052669525, Validation R²: -0.12683689689924815\n",
      "Epoch 15700, Loss: 0.002714435802772641, Validation R²: 0.05428124885508534\n",
      "Epoch 15800, Loss: 0.002737300470471382, Validation R²: 0.0986526040506972\n",
      "Epoch 15900, Loss: 0.0022900179028511047, Validation R²: 0.03524130254104274\n",
      "Epoch 16000, Loss: 0.002239965135231614, Validation R²: -0.015457744997758427\n",
      "Epoch 16100, Loss: 0.0022160131484270096, Validation R²: -0.03788413039618166\n",
      "Epoch 16200, Loss: 0.002245410578325391, Validation R²: 0.02563426466592089\n",
      "Epoch 16300, Loss: 0.0023981877602636814, Validation R²: 0.10591885516409716\n",
      "Epoch 16400, Loss: 0.0021955783013254404, Validation R²: -0.026371383829243866\n",
      "Epoch 16500, Loss: 0.002207862911745906, Validation R²: -0.12625365533462718\n",
      "Epoch 16600, Loss: 0.002179208677262068, Validation R²: -0.08131121576444422\n",
      "Epoch 16700, Loss: 0.002171721775084734, Validation R²: -0.02652432656717152\n",
      "Epoch 16800, Loss: 0.0021684435196220875, Validation R²: -0.07398961695302919\n",
      "Epoch 16900, Loss: 0.0022029445972293615, Validation R²: -0.1721316217476272\n",
      "Epoch 17000, Loss: 0.0023244484327733517, Validation R²: -0.25204546188642674\n",
      "Epoch 17100, Loss: 0.0021773814223706722, Validation R²: 0.04554779179285873\n",
      "Epoch 17200, Loss: 0.0022525291424244642, Validation R²: 0.13802052269185539\n",
      "Epoch 17300, Loss: 0.0021320944651961327, Validation R²: -0.0461913442365911\n",
      "Epoch 17400, Loss: 0.003088720142841339, Validation R²: 0.07639942735023031\n",
      "Epoch 17500, Loss: 0.002292271936312318, Validation R²: -0.06414189365619216\n",
      "Epoch 17600, Loss: 0.0023600764106959105, Validation R²: 0.1086909754319405\n",
      "Epoch 17700, Loss: 0.002326027024537325, Validation R²: 0.056688051798032046\n",
      "Epoch 17800, Loss: 0.0021024146117269993, Validation R²: -0.018175299985974336\n",
      "Epoch 17900, Loss: 0.002096236916258931, Validation R²: -0.032579415445237236\n",
      "Epoch 18000, Loss: 0.0020893702749162912, Validation R²: -0.03848489807803457\n",
      "Epoch 18100, Loss: 0.0020824887324124575, Validation R²: -0.03830320816350219\n",
      "Epoch 18200, Loss: 0.0020794833544641733, Validation R²: -0.01610665282215873\n",
      "Epoch 18300, Loss: 0.002072738017886877, Validation R²: -0.05285388404740732\n",
      "Epoch 18400, Loss: 0.0020673091057687998, Validation R²: -0.039155901791065206\n",
      "Epoch 18500, Loss: 0.0020666150376200676, Validation R²: -0.07456899820727592\n",
      "Epoch 18600, Loss: 0.002062728861346841, Validation R²: -0.03892540463548477\n",
      "Epoch 18700, Loss: 0.002216649241745472, Validation R²: -0.332531854905721\n",
      "Epoch 18800, Loss: 0.0020472959149628878, Validation R²: -0.011060263273915183\n",
      "Epoch 18900, Loss: 0.0020456151105463505, Validation R²: -0.017846498292679813\n",
      "Epoch 19000, Loss: 0.0022161537781357765, Validation R²: 0.1199466395494555\n",
      "Epoch 19100, Loss: 0.0020306233782321215, Validation R²: -0.029758400321859835\n",
      "Epoch 19200, Loss: 0.002032936317846179, Validation R²: -0.008464066825240923\n",
      "Epoch 19300, Loss: 0.0021346367429941893, Validation R²: -0.21849463758025855\n",
      "Epoch 19400, Loss: 0.002016715006902814, Validation R²: -0.019672600384300187\n",
      "Epoch 19500, Loss: 0.00202555232681334, Validation R²: 0.004089691760515657\n",
      "Epoch 19600, Loss: 0.0020100087858736515, Validation R²: 0.0010975069522564107\n",
      "Epoch 19700, Loss: 0.002037191763520241, Validation R²: -0.001735173652743116\n",
      "Epoch 19800, Loss: 0.0019996792543679476, Validation R²: -0.016102723508647276\n",
      "Epoch 19900, Loss: 0.0020096097141504288, Validation R²: -0.09512621819101685\n",
      "Epoch 20000, Loss: 0.0022554825991392136, Validation R²: 0.14781993926781167\n",
      "Epoch 20100, Loss: 0.001989375799894333, Validation R²: -0.025740883912740875\n",
      "Epoch 20200, Loss: 0.002010289579629898, Validation R²: -0.12176642870646859\n",
      "Epoch 20300, Loss: 0.0020033549517393112, Validation R²: -0.03062511335549778\n",
      "Epoch 20400, Loss: 0.00197980715893209, Validation R²: -0.06889990557746528\n",
      "Epoch 20500, Loss: 0.0020107035525143147, Validation R²: 0.009744596137733041\n",
      "Epoch 20600, Loss: 0.001966903917491436, Validation R²: -0.02277583537160255\n",
      "Epoch 20700, Loss: 0.01207429077476263, Validation R²: -6.390670973016476\n",
      "Epoch 20800, Loss: 0.0019953898154199123, Validation R²: -0.032928149255330164\n",
      "Epoch 20900, Loss: 0.0019623120315372944, Validation R²: -0.024452410292673976\n",
      "Epoch 21000, Loss: 0.001957173692062497, Validation R²: -0.059260266395422034\n",
      "Epoch 21100, Loss: 0.0020040590316057205, Validation R²: -0.11407686013822027\n",
      "Epoch 21200, Loss: 0.0019474538275972009, Validation R²: -0.0243247903488919\n",
      "Epoch 21300, Loss: 0.0019582281820476055, Validation R²: 0.02699481422340355\n",
      "Epoch 21400, Loss: 0.005523316562175751, Validation R²: -3.0874799782577407\n",
      "Epoch 21500, Loss: 0.0019388779764994979, Validation R²: -0.024094646231122674\n",
      "Epoch 21600, Loss: 0.0019417491275817156, Validation R²: -0.06293629137830581\n",
      "Epoch 21700, Loss: 0.004438931122422218, Validation R²: 0.10922957071463824\n",
      "Epoch 21800, Loss: 0.0019281546119600534, Validation R²: -0.025355550151606954\n",
      "Epoch 21900, Loss: 0.001992961158975959, Validation R²: 0.09232646258177335\n",
      "Epoch 22000, Loss: 0.0019220702815800905, Validation R²: -0.027250950996453138\n",
      "Epoch 22100, Loss: 0.002030890202149749, Validation R²: 0.05016507708739215\n",
      "Epoch 22200, Loss: 0.0019106200197711587, Validation R²: -0.021666792749388986\n",
      "Epoch 22300, Loss: 0.001974973361939192, Validation R²: 0.05505088909248257\n",
      "Epoch 22400, Loss: 0.0019114682218059897, Validation R²: -0.022845080657987404\n",
      "Epoch 22500, Loss: 0.002614321419969201, Validation R²: 0.09920197672530762\n",
      "Epoch 22600, Loss: 0.0058077247813344, Validation R²: 0.07467692923491998\n",
      "Epoch 22700, Loss: 0.0019093138398602605, Validation R²: -0.02851375203237483\n",
      "Epoch 22800, Loss: 0.0018940218724310398, Validation R²: -0.014541646751448312\n",
      "Epoch 22900, Loss: 0.001907152822241187, Validation R²: -0.017116904921947507\n",
      "Epoch 23000, Loss: 0.0018870338099077344, Validation R²: -0.018003740274332047\n",
      "Epoch 23100, Loss: 0.0019009216921404004, Validation R²: -0.06093463122289933\n",
      "Epoch 23200, Loss: 0.0018828161992132664, Validation R²: -0.018608519608063867\n",
      "Epoch 23300, Loss: 0.0018929854268208146, Validation R²: -0.021243958440044786\n",
      "Epoch 23400, Loss: 0.002195276552811265, Validation R²: -0.6034532934153072\n",
      "Epoch 23500, Loss: 0.0018765527056530118, Validation R²: -0.014948651904575172\n",
      "Epoch 23600, Loss: 0.0019474775763228536, Validation R²: -0.1327907541729687\n",
      "Epoch 23700, Loss: 0.0018749535083770752, Validation R²: -0.025486319914666433\n",
      "Epoch 23800, Loss: 0.0019407826475799084, Validation R²: -1.4635166327472309\n",
      "Epoch 23900, Loss: 0.0018731430172920227, Validation R²: -0.0324862466853979\n",
      "Epoch 24000, Loss: 0.0018600351177155972, Validation R²: -0.016224816636863704\n",
      "Epoch 24100, Loss: 0.0018691294826567173, Validation R²: -0.045486472140709555\n",
      "Epoch 24200, Loss: 0.0018809149041771889, Validation R²: -0.14109338802161853\n",
      "Epoch 24300, Loss: 0.0018558994634076953, Validation R²: -0.03223099305858801\n",
      "Epoch 24400, Loss: 0.0018703605746850371, Validation R²: 0.014812230810789528\n",
      "Epoch 24500, Loss: 0.0018492433009669185, Validation R²: -0.024261066195711223\n",
      "Epoch 24600, Loss: 0.0018993106205016375, Validation R²: -0.1020697493336693\n",
      "Epoch 24700, Loss: 0.001850977074354887, Validation R²: -0.02463398770024372\n",
      "Epoch 24800, Loss: 0.0021803483832627535, Validation R²: 0.07944483280943593\n",
      "Epoch 24900, Loss: 0.0021461565047502518, Validation R²: 0.11604643585117469\n",
      "Epoch 25000, Loss: 0.0018431381322443485, Validation R²: -0.020880598715832033\n",
      "Epoch 25100, Loss: 0.005736720282584429, Validation R²: -1.5091932380810356\n",
      "Epoch 25200, Loss: 0.0018372294725850224, Validation R²: -0.028813887833832874\n",
      "Epoch 25300, Loss: 0.002524382434785366, Validation R²: -0.5549735765500898\n",
      "Epoch 25400, Loss: 0.0018350740429013968, Validation R²: -0.02280204248261053\n",
      "Epoch 25500, Loss: 0.001844866550527513, Validation R²: -0.1320080488575095\n",
      "Epoch 25600, Loss: 0.0018360085086897016, Validation R²: -0.03492791397172157\n",
      "Epoch 25700, Loss: 0.0018246853724122047, Validation R²: -0.020630284426744305\n",
      "Epoch 25800, Loss: 0.0018500769510865211, Validation R²: 0.07220117179974961\n",
      "Epoch 25900, Loss: 0.0018184708897024393, Validation R²: -0.012603094398801362\n",
      "Epoch 26000, Loss: 0.00182921823579818, Validation R²: -0.03917730302795541\n",
      "Epoch 26100, Loss: 0.0018158211605623364, Validation R²: -0.021693903624959487\n",
      "Epoch 26200, Loss: 0.00183621805626899, Validation R²: -0.009979485082825645\n",
      "Epoch 26300, Loss: 0.0018119951710104942, Validation R²: -0.020433871092500944\n",
      "Epoch 26400, Loss: 0.0019342460436746478, Validation R²: 0.18583849926747031\n",
      "Epoch 26500, Loss: 0.0018201656639575958, Validation R²: -0.026130569552233585\n",
      "Epoch 26600, Loss: 0.0018087102798745036, Validation R²: -0.022101418828923025\n",
      "Epoch 26700, Loss: 0.001956823281943798, Validation R²: 0.12362546418505005\n",
      "Epoch 26800, Loss: 0.0018057427369058132, Validation R²: -0.07710730242600183\n",
      "Epoch 26900, Loss: 0.0018059330759570003, Validation R²: -0.020719760841136692\n",
      "Epoch 27000, Loss: 0.0017948054010048509, Validation R²: -0.014818124667000276\n",
      "Epoch 27100, Loss: 0.002172259846702218, Validation R²: -0.07802789741871785\n",
      "Epoch 27200, Loss: 0.001793667790479958, Validation R²: -0.017027560432278266\n",
      "Epoch 27300, Loss: 0.0017895266646519303, Validation R²: 0.020974683017529805\n",
      "Epoch 27400, Loss: 0.0017970914486795664, Validation R²: 0.009089141341845353\n",
      "Epoch 27500, Loss: 0.0017850685399025679, Validation R²: -0.014801163427105912\n",
      "Epoch 27600, Loss: 0.0029537826776504517, Validation R²: -0.007209378968219049\n",
      "Epoch 27700, Loss: 0.0017840396612882614, Validation R²: -0.018060722927213613\n",
      "Epoch 27800, Loss: 0.0017763220239430666, Validation R²: -0.028975337486538688\n",
      "Epoch 27900, Loss: 0.0017847573617473245, Validation R²: -0.02998129509112224\n",
      "Epoch 28000, Loss: 0.0017725656507536769, Validation R²: -0.011111956469071593\n",
      "Epoch 28100, Loss: 0.0017916648648679256, Validation R²: -0.04509575564577806\n",
      "Epoch 28200, Loss: 0.0017720806645229459, Validation R²: -0.013913626872377849\n",
      "Epoch 28300, Loss: 0.002682474674656987, Validation R²: 0.029197735186546447\n",
      "Epoch 28400, Loss: 0.0017721743788570166, Validation R²: -0.016571285025277716\n",
      "Epoch 28500, Loss: 0.0017643407918512821, Validation R²: -0.005971378803657057\n",
      "Epoch 28600, Loss: 0.001772029441781342, Validation R²: -0.04541755988489271\n",
      "Epoch 28700, Loss: 0.0017784010851755738, Validation R²: 0.060729257267633785\n",
      "Epoch 28800, Loss: 0.0017672013491392136, Validation R²: -0.022176431509512318\n",
      "Epoch 28900, Loss: 0.001757462159730494, Validation R²: -0.011050241878983735\n",
      "Epoch 29000, Loss: 0.0017772301798686385, Validation R²: -0.03413500971404493\n",
      "Epoch 29100, Loss: 0.0017567025497555733, Validation R²: -0.012332330240478528\n",
      "Epoch 29200, Loss: 0.001800128840841353, Validation R²: 0.14003537349330852\n",
      "Epoch 29300, Loss: 0.0017559537664055824, Validation R²: -0.011325690382755438\n",
      "Epoch 29400, Loss: 0.0017747149104252458, Validation R²: 0.06869623031526861\n",
      "Epoch 29500, Loss: 0.0017586768371984363, Validation R²: -0.018199186567973147\n",
      "Epoch 29600, Loss: 0.0017487292643636465, Validation R²: -0.011149678323898682\n",
      "Epoch 29700, Loss: 0.0018417927203699946, Validation R²: -0.10189021989256308\n",
      "Epoch 29800, Loss: 0.0017517470987513661, Validation R²: -0.013929463949650334\n",
      "Epoch 29900, Loss: 0.0017445964040234685, Validation R²: -0.011497783850038967\n",
      "Epoch 30000, Loss: 0.001860800082795322, Validation R²: 0.14245928841460087\n",
      "Epoch 30100, Loss: 0.001790858106687665, Validation R²: 0.0025523641430752475\n",
      "Epoch 30200, Loss: 0.0017436707857996225, Validation R²: -0.006919454705411665\n",
      "Epoch 30300, Loss: 0.001737140817567706, Validation R²: -0.01048197360675518\n",
      "Epoch 30400, Loss: 0.0017648983048275113, Validation R²: 0.04025623636751263\n",
      "Epoch 30500, Loss: 0.0017413030145689845, Validation R²: -0.011365976280159451\n",
      "Epoch 30600, Loss: 0.0017349233385175467, Validation R²: -0.008493773654982828\n",
      "Epoch 30700, Loss: 0.002084564184769988, Validation R²: 0.14480621638076474\n",
      "Epoch 30800, Loss: 0.0017629634821787477, Validation R²: -0.008026461881065927\n",
      "Epoch 30900, Loss: 0.001740037463605404, Validation R²: -0.01234824059699946\n",
      "Epoch 31000, Loss: 0.001733406214043498, Validation R²: -0.010580560679986473\n",
      "Epoch 31100, Loss: 0.001728803850710392, Validation R²: 0.012942203665786689\n",
      "Epoch 31200, Loss: 0.0017522175330668688, Validation R²: 0.004371443579914813\n",
      "Epoch 31300, Loss: 0.0017304986249655485, Validation R²: -0.011467189219423801\n",
      "Epoch 31400, Loss: 0.0017248752992600203, Validation R²: 0.00044548134052313504\n",
      "Epoch 31500, Loss: 0.0018149010138586164, Validation R²: -0.04593588019614181\n",
      "Epoch 31600, Loss: 0.0017412492306903005, Validation R²: -0.011303681432847545\n",
      "Epoch 31700, Loss: 0.0017302867490798235, Validation R²: -0.011831186050453635\n",
      "Epoch 31800, Loss: 0.0017244842601940036, Validation R²: -0.008327898193810856\n",
      "Epoch 31900, Loss: 0.002585961017757654, Validation R²: -0.18267255010927408\n",
      "Epoch 32000, Loss: 0.0017222889000549912, Validation R²: -0.00011791065275068568\n",
      "Epoch 32100, Loss: 0.024936988949775696, Validation R²: -12.255568878071918\n",
      "Epoch 32200, Loss: 0.0017770850099623203, Validation R²: 0.023769756579434365\n",
      "Epoch 32300, Loss: 0.0017666073981672525, Validation R²: 0.03238893919885977\n",
      "Epoch 32400, Loss: 0.0017595833633095026, Validation R²: 0.039147226924013845\n",
      "Epoch 32500, Loss: 0.0017541063716635108, Validation R²: 0.041927347462830444\n",
      "Epoch 32600, Loss: 0.0018022207077592611, Validation R²: 0.04400824330223363\n",
      "Epoch 32700, Loss: 0.0017517146188765764, Validation R²: 0.03735247657483287\n",
      "Epoch 32800, Loss: 0.0017662873724475503, Validation R²: 0.07768051199271953\n",
      "Epoch 32900, Loss: 0.0017523476853966713, Validation R²: 0.032605279006098775\n",
      "Epoch 33000, Loss: 0.0017940668622031808, Validation R²: -1.6414300302349951\n",
      "Epoch 33100, Loss: 0.0017547567840665579, Validation R²: 0.0339711054379771\n",
      "Epoch 33200, Loss: 0.0017475284403190017, Validation R²: 0.03514663034855381\n",
      "Epoch 33300, Loss: 0.0032408107072114944, Validation R²: 0.15058876092912\n",
      "Epoch 33400, Loss: 0.001749479561112821, Validation R²: 0.026654742419822797\n",
      "Epoch 33500, Loss: 0.00174184690695256, Validation R²: 0.032876025922581986\n",
      "Epoch 33600, Loss: 0.0017891094321385026, Validation R²: 0.1460275589670036\n",
      "Epoch 33700, Loss: 0.001744653913192451, Validation R²: 0.029382938542758086\n",
      "Epoch 33800, Loss: 0.0017376673640683293, Validation R²: 0.032912196196370425\n",
      "Epoch 33900, Loss: 0.0017856279155239463, Validation R²: 0.0718259420378663\n",
      "Epoch 34000, Loss: 0.0017395762261003256, Validation R²: 0.028213819867448087\n",
      "Epoch 34100, Loss: 0.0017337003955617547, Validation R²: 0.041893108874402896\n",
      "Epoch 34200, Loss: 0.00174558418802917, Validation R²: -0.002392631879780671\n",
      "Epoch 34300, Loss: 0.001734019024297595, Validation R²: 0.03614680246924362\n",
      "Epoch 34400, Loss: 0.0025155707262456417, Validation R²: 0.11598302785314085\n",
      "Epoch 34500, Loss: 0.001736801932565868, Validation R²: 0.027601530636829352\n",
      "Epoch 34600, Loss: 0.0017294947756454349, Validation R²: 0.029446417681003867\n",
      "Epoch 34700, Loss: 0.0018054686952382326, Validation R²: -0.6973268701895334\n",
      "Epoch 34800, Loss: 0.001737489947117865, Validation R²: 0.036200795199205715\n",
      "Epoch 34900, Loss: 0.0017309271497651935, Validation R²: 0.03864152559892986\n",
      "Epoch 35000, Loss: 0.001813689130358398, Validation R²: 0.11779927732687678\n",
      "Epoch 35100, Loss: 0.001731137279421091, Validation R²: 0.029078138319345137\n",
      "Epoch 35200, Loss: 0.005029354244470596, Validation R²: -0.6051923079960044\n",
      "Epoch 35300, Loss: 0.0017263031331822276, Validation R²: 0.028722195324998312\n",
      "Epoch 35400, Loss: 0.0017406889237463474, Validation R²: 0.036123929622244644\n",
      "Epoch 35500, Loss: 0.0017547752941027284, Validation R²: -0.08972041023741673\n",
      "Epoch 35600, Loss: 0.0017209239304065704, Validation R²: 0.024157025923614128\n",
      "Epoch 35700, Loss: 0.0017671064706519246, Validation R²: 0.0304167477424796\n",
      "Epoch 35800, Loss: 0.0017317242454737425, Validation R²: 0.03100664507882611\n",
      "Epoch 35900, Loss: 0.0017254706472158432, Validation R²: 0.03260457991247545\n",
      "Epoch 36000, Loss: 0.001720328233204782, Validation R²: 0.03344269572066172\n",
      "Epoch 36100, Loss: 0.0017158732516691089, Validation R²: 0.03343210502780003\n",
      "Epoch 36200, Loss: 0.001747978967614472, Validation R²: 0.10932539102324346\n",
      "Epoch 36300, Loss: 0.0017297797603532672, Validation R²: -0.03449929798521412\n",
      "Epoch 36400, Loss: 0.0017521996051073074, Validation R²: 0.0036174321018417332\n",
      "Epoch 36500, Loss: 0.0017193179810419679, Validation R²: 0.02600322268567934\n",
      "Epoch 36600, Loss: 0.0017129845218732953, Validation R²: 0.02488549546737273\n",
      "Epoch 36700, Loss: 0.002113322028890252, Validation R²: -0.4040182499634335\n",
      "Epoch 36800, Loss: 0.001717385370284319, Validation R²: -0.02504978047854256\n",
      "Epoch 36900, Loss: 0.0017119371332228184, Validation R²: 0.016396697730681198\n",
      "Epoch 37000, Loss: 0.0017355968011543155, Validation R²: 0.11366581380911722\n",
      "Epoch 37100, Loss: 0.002778486115857959, Validation R²: -1.218555109339447\n",
      "Epoch 37200, Loss: 0.0017151259817183018, Validation R²: 0.0203362795416121\n",
      "Epoch 37300, Loss: 0.0017083882121369243, Validation R²: 0.023125306414884306\n",
      "Epoch 37400, Loss: 0.0017038511577993631, Validation R²: 0.02493726293084164\n",
      "Epoch 37500, Loss: 0.001846739207394421, Validation R²: 0.004723566618551223\n",
      "Epoch 37600, Loss: 0.0017052935436367989, Validation R²: 0.02188444508919185\n",
      "Epoch 37700, Loss: 0.005018067080527544, Validation R²: -0.5925142474165577\n",
      "Epoch 37800, Loss: 0.0017014987533912063, Validation R²: 0.03754801557305809\n",
      "Epoch 37900, Loss: 0.012191430665552616, Validation R²: -0.8900198638007779\n",
      "Epoch 38000, Loss: 0.0017118112882599235, Validation R²: 0.027545160893529763\n",
      "Epoch 38100, Loss: 0.0017023198306560516, Validation R²: 0.01978766718141045\n",
      "Epoch 38200, Loss: 0.0016977768391370773, Validation R²: 0.02405947480071935\n",
      "Epoch 38300, Loss: 0.00172135466709733, Validation R²: -1.1546552815520492\n",
      "Epoch 38400, Loss: 0.0017006963025778532, Validation R²: 0.025838405889900717\n",
      "Epoch 38500, Loss: 0.0016954472521319985, Validation R²: 0.023926406218913843\n",
      "Epoch 38600, Loss: 0.0018321553943678737, Validation R²: -0.2602162379577351\n",
      "Epoch 38700, Loss: 0.0016969218850135803, Validation R²: 0.018709089291573\n",
      "Epoch 38800, Loss: 0.0016985052498057485, Validation R²: 0.060052829949154396\n",
      "Epoch 38900, Loss: 0.0016913888975977898, Validation R²: 0.028929566440498045\n",
      "Epoch 39000, Loss: 0.0017958931857720017, Validation R²: 0.057485109466662854\n",
      "Epoch 39100, Loss: 0.0017027182038873434, Validation R²: 0.022017654674767462\n",
      "Epoch 39200, Loss: 0.001694448059424758, Validation R²: 0.01835701663722722\n",
      "Epoch 39300, Loss: 0.0016901182243600488, Validation R²: 0.021811310654692773\n",
      "Epoch 39400, Loss: 0.0016865306533873081, Validation R²: 0.015766166892794753\n",
      "Epoch 39500, Loss: 0.001687469775788486, Validation R²: 0.00939721029059648\n",
      "Epoch 39600, Loss: 0.001713660778477788, Validation R²: 0.033119812803473425\n",
      "Epoch 39700, Loss: 0.0018857130780816078, Validation R²: 0.10949219135603494\n",
      "Epoch 39800, Loss: 0.00575600378215313, Validation R²: -4.347195419958212\n",
      "Epoch 39900, Loss: 0.001703702611848712, Validation R²: 0.0213656978479988\n",
      "Epoch 40000, Loss: 0.0016911047277972102, Validation R²: 0.014629223114319578\n",
      "Epoch 40100, Loss: 0.0016866280930116773, Validation R²: 0.016119339301609692\n",
      "Epoch 40200, Loss: 0.00168298848439008, Validation R²: 0.017338699786877854\n",
      "Epoch 40300, Loss: 0.0019816826097667217, Validation R²: -0.3993410035362681\n",
      "Epoch 40400, Loss: 0.0016802301397547126, Validation R²: -0.002257893733867311\n",
      "Epoch 40500, Loss: 0.0017281784676015377, Validation R²: 0.013491543229574465\n",
      "Epoch 40600, Loss: 0.0016887284582480788, Validation R²: 0.015226987722972707\n",
      "Epoch 40700, Loss: 0.0016842962941154838, Validation R²: 0.014603209782074633\n",
      "Epoch 40800, Loss: 0.0016807742649689317, Validation R²: 0.015249405360154622\n",
      "Epoch 40900, Loss: 0.0016779074212536216, Validation R²: 0.006171646613376658\n",
      "Epoch 41000, Loss: 0.00458691269159317, Validation R²: -5.1510355288829786\n",
      "Epoch 41100, Loss: 0.0016894842265173793, Validation R²: 0.008476489020936784\n",
      "Epoch 41200, Loss: 0.001681914203800261, Validation R²: 0.009780408950087915\n",
      "Epoch 41300, Loss: 0.0016782119637355208, Validation R²: 0.015024860688326203\n",
      "Epoch 41400, Loss: 0.0016859578900039196, Validation R²: -0.04934033902587731\n",
      "Epoch 41500, Loss: 0.006771134212613106, Validation R²: -1.1422703474192035\n",
      "Epoch 41600, Loss: 0.0016893853899091482, Validation R²: 0.029552009175730642\n",
      "Epoch 41700, Loss: 0.0016796175623312593, Validation R²: 0.01201751769435333\n",
      "Epoch 41800, Loss: 0.0016759325517341495, Validation R²: 0.013983529944235573\n",
      "Epoch 41900, Loss: 0.0016727051697671413, Validation R²: 0.00951099930442778\n",
      "Epoch 42000, Loss: 0.014550582505762577, Validation R²: -2.2575500491109532\n",
      "Epoch 42100, Loss: 0.0016959675122052431, Validation R²: -0.00017173087494715134\n",
      "Epoch 42200, Loss: 0.0016775019466876984, Validation R²: 0.010266653922069269\n",
      "Epoch 42300, Loss: 0.0016734609380364418, Validation R²: 0.01443198007222335\n",
      "Epoch 42400, Loss: 0.00167440390214324, Validation R²: -0.040761578431846024\n",
      "Epoch 42500, Loss: 0.0018224423984065652, Validation R²: -0.4414840259739081\n",
      "Epoch 42600, Loss: 0.001680969726294279, Validation R²: 0.02238396043368973\n",
      "Epoch 42700, Loss: 0.0016730608185753226, Validation R²: 0.012328269889323784\n",
      "Epoch 42800, Loss: 0.0016696277307346463, Validation R²: 0.008722732820430346\n",
      "Epoch 42900, Loss: 0.0019159017829224467, Validation R²: 0.09382831415513615\n",
      "Epoch 43000, Loss: 0.0017007557908073068, Validation R²: -0.11624090061883008\n",
      "Epoch 43100, Loss: 0.0033611266408115625, Validation R²: -1.0534582301919824\n",
      "Epoch 43200, Loss: 0.0017311619594693184, Validation R²: 0.006735514184463942\n",
      "Epoch 43300, Loss: 0.0016823018668219447, Validation R²: 0.008920895161518949\n",
      "Epoch 43400, Loss: 0.0016719925915822387, Validation R²: 0.010217799762912816\n",
      "Epoch 43500, Loss: 0.0016685430891811848, Validation R²: 0.011876349251990326\n",
      "Epoch 43600, Loss: 0.0016654727514833212, Validation R²: 0.01315957325108863\n",
      "Epoch 43700, Loss: 0.002037522615864873, Validation R²: -0.5414848277385471\n",
      "Epoch 43800, Loss: 0.002279705600813031, Validation R²: -0.7682264765102076\n",
      "Epoch 43900, Loss: 0.0022385430056601763, Validation R²: 0.10552798464478641\n",
      "Epoch 44000, Loss: 0.0020420823711901903, Validation R²: -0.7167809297405061\n",
      "Epoch 44100, Loss: 0.0016762574668973684, Validation R²: 0.026807954059409278\n",
      "Epoch 44200, Loss: 0.0016667854506522417, Validation R²: 0.009939601835125766\n",
      "Epoch 44300, Loss: 0.0016635836800560355, Validation R²: 0.01235550520792661\n",
      "Epoch 44400, Loss: 0.001662579015828669, Validation R²: 0.025929717594587287\n",
      "Epoch 44500, Loss: 0.0016734929522499442, Validation R²: -0.04000933889170888\n",
      "Epoch 44600, Loss: 0.0016932651633396745, Validation R²: -0.04010499799183043\n",
      "Epoch 44700, Loss: 0.0016981128137558699, Validation R²: 0.09027949874484598\n",
      "Epoch 44800, Loss: 0.001870481064543128, Validation R²: -7.364549637041659\n",
      "Epoch 44900, Loss: 0.001817577751353383, Validation R²: -0.00793638485616821\n",
      "Epoch 45000, Loss: 0.0017717445734888315, Validation R²: -0.008001093946609528\n",
      "Epoch 45100, Loss: 0.0016922758659347892, Validation R²: 0.00403117261711794\n",
      "Epoch 45200, Loss: 0.0016670445911586285, Validation R²: 0.008103562525334729\n",
      "Epoch 45300, Loss: 0.0016603115946054459, Validation R²: 0.0070459076572946255\n",
      "Epoch 45400, Loss: 0.0016592243919149041, Validation R²: 0.014843597346047233\n",
      "Epoch 45500, Loss: 0.001659479457885027, Validation R²: 0.023865375599557703\n",
      "Epoch 45600, Loss: 0.0016589198494330049, Validation R²: 0.047816495254729086\n",
      "Epoch 45700, Loss: 0.001860156306065619, Validation R²: 0.117623796398175\n",
      "Epoch 45800, Loss: 0.0016858888557180762, Validation R²: 0.034445390255521846\n",
      "Epoch 45900, Loss: 0.0016617638757452369, Validation R²: 0.013623840015787314\n",
      "Epoch 46000, Loss: 0.001658222870901227, Validation R²: 0.010749659030368619\n",
      "Epoch 46100, Loss: 0.0016556954942643642, Validation R²: 0.00799345298288423\n",
      "Epoch 46200, Loss: 0.001653744257055223, Validation R²: -0.0012355926513563098\n",
      "Epoch 46300, Loss: 0.0017843213863670826, Validation R²: 0.14845584351002494\n",
      "Epoch 46400, Loss: 0.0016806158237159252, Validation R²: 0.03276745898588007\n",
      "Epoch 46500, Loss: 0.0016600778326392174, Validation R²: 0.011103809452837843\n",
      "Epoch 46600, Loss: 0.0016568502178415656, Validation R²: 0.009718413417423521\n",
      "Epoch 46700, Loss: 0.0016541560180485249, Validation R²: 0.009669236579923801\n",
      "Epoch 46800, Loss: 0.0016582402167841792, Validation R²: -0.02435856479009324\n",
      "Epoch 46900, Loss: 0.002506802324205637, Validation R²: -0.07484827895431301\n",
      "Epoch 47000, Loss: 0.001701429020613432, Validation R²: 0.032809419720228994\n",
      "Epoch 47100, Loss: 0.0016617464134469628, Validation R²: 0.015194987934393334\n",
      "Epoch 47200, Loss: 0.0016561304219067097, Validation R²: 0.008884763754486436\n",
      "Epoch 47300, Loss: 0.001653284183703363, Validation R²: 0.007899235255744874\n",
      "Epoch 47400, Loss: 0.0016566438134759665, Validation R²: 0.032883474846927774\n",
      "Epoch 47500, Loss: 0.0016571084270253778, Validation R²: -0.012467958809477153\n",
      "Epoch 47600, Loss: 0.00181963003706187, Validation R²: 0.15779577282289758\n",
      "Epoch 47700, Loss: 0.0016585306730121374, Validation R²: 0.01126292150649566\n",
      "Epoch 47800, Loss: 0.0016529334243386984, Validation R²: 0.0033620703243761874\n",
      "Epoch 47900, Loss: 0.0016644272254779935, Validation R²: 0.0516068622030772\n",
      "Epoch 48000, Loss: 0.001652371953241527, Validation R²: 0.04290800210547652\n",
      "Epoch 48100, Loss: 0.0024737841449677944, Validation R²: -0.4305671101098403\n",
      "Epoch 48200, Loss: 0.0017274400452151895, Validation R²: -0.0001328633329884532\n",
      "Epoch 48300, Loss: 0.00167465943377465, Validation R²: -0.001545605921784876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgcn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     15\u001b[0m         val_r2 \u001b[38;5;241m=\u001b[39m test(gcn_model, data, val_mask)\n",
      "Cell \u001b[1;32mIn[101], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, optimizer, criterion, mask)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[mask], data\u001b[38;5;241m.\u001b[39my[mask])\n\u001b[0;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 7\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python Interpreters\\in_Machine_Learning_GPU118\\Lib\\site-packages\\torch\\optim\\adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare the data object\n",
    "data = Data(x=torch.tensor(node_features, dtype=torch.float),\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=labels)\n",
    "\n",
    "# Train GCN\n",
    "gcn_model = GCN(in_channels=2, out_channels=1)\n",
    "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(100000):\n",
    "    loss = train(gcn_model, data, optimizer, criterion, train_mask)\n",
    "    if epoch % 100 == 0:\n",
    "        val_r2 = test(gcn_model, data, val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss}, Validation R²: {val_r2}')\n",
    "\n",
    "# Evaluate GCN\n",
    "test_r2 = test(gcn_model, data, test_mask)\n",
    "print(f'GCN Test R²: {test_r2}')\n",
    "\n",
    "# Train GAT\n",
    "gat_model = GAT(in_channels=2, out_channels=1)\n",
    "optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss = train(gat_model, data, optimizer, criterion, train_mask)\n",
    "    if epoch % 100 == 0:\n",
    "        val_r2 = test(gat_model, data, val_mask)\n",
    "        print(f'Epoch {epoch}, Loss: {loss}, Validation R²: {val_r2}')\n",
    "\n",
    "# Evaluate GAT\n",
    "test_r2 = test(gat_model, data, test_mask)\n",
    "print(f'GAT Test R²: {test_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

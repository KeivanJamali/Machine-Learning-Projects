{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-12T15:55:45.694422600Z",
     "start_time": "2023-09-12T15:55:42.586127600Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ML\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4356dc58b94f4ee1a41edeffe3dc1906"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1a167fe8df045c0a5885a82cc1a35e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_doc, test_doc = [], []\n",
    "for rand in tqdm(range(10)):\n",
    "    val_result, test_result, data_nums = [], [], []\n",
    "    for iteration in tqdm(range(9)):\n",
    "        repeat_results = []\n",
    "        best = -1000\n",
    "        for repeat in (range(1)):\n",
    "            temp = 0\n",
    "            folder = f\"prepared_data/prepared_data-{rand + 1}/Scaled/Chicago_Regional/{int((iteration + 1) * 10)}\"\n",
    "            miss = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "            data = ML.DataLoader_Me(folder, miss[iteration], batch_size=512, device=\"cpu\")\n",
    "            train, val, test = data.train, data.val, data.test\n",
    "\n",
    "            input_size = 3\n",
    "            hidden_units = 8\n",
    "            num_layer = 2\n",
    "            output_size = 1\n",
    "            epochs = 500\n",
    "            batch_size = 32\n",
    "            # learning_rate = np.random.choice(np.arange(0.0001, 0.0011, 0.0001))\n",
    "            learning_rate = 0.00001\n",
    "\n",
    "            model = ML.FlowPredict(input_size, hidden_units, output_size, lambda_value=0.01)\n",
    "            model, [count_epoch, loss_values, val_loss_values] = ML.train_model(model, train,\n",
    "                                                                                val, epochs, learning_rate)\n",
    "            [val_rmse, val_mae, val_r2], data_val = ML.evaluate_model(model, val)\n",
    "            [test_rmse, test_mae, test_r2], data_test = ML.test_model(model, test)\n",
    "            if best < test_r2 or repeat == 99:\n",
    "                # best = test_r2\n",
    "                best_list = [[model, [count_epoch, loss_values, val_loss_values]],\n",
    "                             [[val_rmse, val_mae, val_r2], data_val], [[test_rmse, test_mae, test_r2], data_test],\n",
    "                             [{\"input_size\": [input_size], \"output_size\": [output_size], \"hidden_units\": [hidden_units],\n",
    "                               \"num_hidden_layer\": [num_layer], \"epochs\": [epochs], \"batch_size\": [batch_size],\n",
    "                               \"learning_rate\": [learning_rate], \"optimizer\": [\"Adam\"], \"loss\": [\"MSE\"],\n",
    "                               \"activation\": [\"ReLU\"]}]]\n",
    "                # break\n",
    "\n",
    "        model, [count_epoch, loss_values, val_loss_values] = best_list[0]\n",
    "        [val_rmse, val_mae, val_r2], data_val = best_list[1]\n",
    "        [test_rmse, test_mae, test_r2], data_test = best_list[2]\n",
    "        model_hyperparameter = pd.DataFrame(best_list[3][0])\n",
    "\n",
    "        val_result.append([np.array(val_rmse), np.array(val_mae), val_r2])\n",
    "        test_result.append([np.array(test_rmse), np.array(test_mae), test_r2])\n",
    "\n",
    "        print(f\"R2 is in{rand + 1}/10 and {iteration + 1}/9 == {test_r2}\")\n",
    "        ML.plot_fn(data_test, save=True, show=False, model=f\"Chicago_Regional{rand}_{iteration}\",\n",
    "                   bins=np.arange(-0.001, 0.0011, 0.0001))\n",
    "\n",
    "        if not os.path.exists(f\"data/Result{rand + 1}/Chicago_Regional_data\"):\n",
    "            os.makedirs(f\"data/Result{rand + 1}/Chicago_Regional_data\")\n",
    "        model_hyperparameter.to_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/HyperParameters{iteration+1}_NN_model.csv\")\n",
    "        data_test = np.array(data_test)\n",
    "        if not os.path.exists(f\"data/Result{rand + 1}/Chicago_Regional_data/data_NN_model.csv\"):\n",
    "            data_test = pd.DataFrame({\"Predict1\": data_test[0].squeeze(), \"Real1\": data_test[1].squeeze()})\n",
    "            data_test.to_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/data_NN_model.csv\")\n",
    "        else:\n",
    "            data_last = pd.read_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/data_NN_model.csv\")\n",
    "            data_last = data_last.iloc[:, 1:]\n",
    "            data_last[f\"Predict{iteration + 1}\"] = data_test[0].squeeze()\n",
    "            data_last[f\"Real{iteration + 1}\"] = data_test[1].squeeze()\n",
    "            data_last.to_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/data_NN_model.csv\")\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            # plt.clf()\n",
    "            # plt.plot(count_epoch[5:], loss_values[5:], c=\"b\", label=\"Train\")\n",
    "            # plt.plot(count_epoch[5:], val_loss_values[5:], c=\"r\", label=\"val\")\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            if not os.path.exists(\"Models/Chicago_Regional\"):\n",
    "                os.makedirs(\"Models/Chicago_Regional\")\n",
    "            torch.save(model, f\"Models/Chicago_Regional/Chicago_Regional{rand}_{iteration}_model_nn.pth\")\n",
    "\n",
    "    if not os.path.exists(f\"data/Result{rand + 1}/Chicago_Regional_data/NN_model.csv\"):\n",
    "        test_result = pd.DataFrame(test_result, columns=[\"RMSE\", \"MAE\", \"R^2\"])\n",
    "        test_result.to_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/NN_model.csv\")\n",
    "    else:\n",
    "        data_last = pd.read_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/NN_model.csv\")\n",
    "        data_last = data_last.iloc[:, 1:]\n",
    "        test_result = pd.DataFrame(test_result, columns=[\"RMSE\", \"MAE\", \"R^2\"])\n",
    "        test_result = pd.concat([test_result, data_last], ignore_index=True)\n",
    "        test_result.to_csv(f\"data/Result{rand + 1}/Chicago_Regional_data/NN_model.csv\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-12T15:55:56.765063800Z"
    }
   },
   "id": "377a8b7e41a8a9c2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90fca4002f1e42ba996b6ba9ea8b9f5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d1cd1cef0bb47a7a6e8e3a1cabd4fce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "214342ab9ed548b88ff9e5182b417fa5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30df4bfabf0145fbb3847f3c3284655f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54a47c48b38e4931b98fec03441184f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b68aaf2f3db84a5fbbdf3aecf399442a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab03f159e9954862ace358f734583bc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "466be7e2deda429ba182473ff97a4d60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bc1d20db9bb4d5ca4e56875b2e88fc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5155ad97b1a844669a6ae48c6c8b7ec9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc250c79353d40aea611656a2bcd99d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import LinearRegression as Ll\n",
    "\n",
    "r2 = []\n",
    "for rand in tqdm(range(10)):\n",
    "    # print(f\"we are going to {rand + 1} itter #########################################################################\")\n",
    "    all_r2 = []\n",
    "    one = [0, 1, 2]\n",
    "    two = [3, 4, 5]\n",
    "    three = [7, 8]\n",
    "    for iterr in tqdm(range(9)):\n",
    "        folder = f\"prepared_data/prepared_data-{rand + 1}/Scaled/Chicago_Regional/{int((iterr + 1) * 10)}\"\n",
    "        miss = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = Ll.load(folder, miss[iterr])\n",
    "        model = Ll.reg(x_train, y_train)\n",
    "        r = Ll.testit(model, x_val, y_val)\n",
    "        r2.append(r)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T11:33:53.644566400Z",
     "start_time": "2023-09-09T11:26:28.021233700Z"
    }
   },
   "id": "559212b15c1d29ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

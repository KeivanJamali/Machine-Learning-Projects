{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:13:44.736485600Z",
     "start_time": "2023-12-27T07:13:44.681966600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4f52610c90bd7cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.162621500Z",
     "start_time": "2023-12-24T18:08:04.056028300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class LOS_Classification_V0(nn.Module):\n",
    "    def __init__(self, in_put, hidden_units, out_put):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_put, hidden_units)\n",
    "        self.layer_2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.layer_3 = nn.Linear(hidden_units, out_put)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b1b906b0f18a47ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.316983100Z",
     "start_time": "2023-12-24T18:08:04.166627500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data_setup\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "luzern_data = data_setup.Dataloader()\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path,\n",
    "                                                                                   city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8ee2a61426703426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.448168900Z",
     "start_time": "2023-12-24T18:08:04.322935900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOS_Classification_V0(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (layer_3): Linear(in_features=32, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "\n",
    "model0 = LOS_Classification_V0(INPUT_SHAPE, HIDDEN_UNITS, OUTPUT_SHAPE)\n",
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6739deee2b7363d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.551677800Z",
     "start_time": "2023-12-24T18:08:04.439587600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LOS_Classification_V0                    [1, 6]                    --\n",
       "├─Linear: 1-1                            [1, 32]                   224\n",
       "├─ReLU: 1-2                              [1, 32]                   --\n",
       "├─Linear: 1-3                            [1, 32]                   1,056\n",
       "├─ReLU: 1-4                              [1, 32]                   --\n",
       "├─Linear: 1-5                            [1, 6]                    198\n",
       "==========================================================================================\n",
       "Total params: 1,478\n",
       "Trainable params: 1,478\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model0, input_size=[1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e4a4743201b1838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:15:03.590090200Z",
     "start_time": "2023-12-24T18:15:03.480256600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: str) -> tuple[float, float]:\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_logit = model(X)\n",
    "        loss = loss_fn(y_logit, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_logit, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_logit)\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def val_step(model: torch.nn.Module,\n",
    "             dataloader: torch.utils.data.DataLoader,\n",
    "             loss_fn: torch.nn.Module,\n",
    "             device: str) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_logit = model(X)\n",
    "            val_loss += loss_fn(y_logit, y).item()\n",
    "            val_pred_labels = y_logit.argmax(dim=1)\n",
    "            val_acc += ((val_pred_labels == y).sum().item() / len(y_logit))\n",
    "\n",
    "    val_loss /= len(dataloader)\n",
    "    val_acc /= len(dataloader)\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "50f4493ece2facf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:15:04.981362800Z",
     "start_time": "2023-12-24T18:15:04.873979200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          val_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int = 32,\n",
    "          device: str = \"cpu\") -> dict[str, list]:\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": []}\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        val_loss, val_acc = val_step(model=model,\n",
    "                                     dataloader=val_dataloader,\n",
    "                                     loss_fn=loss_fn,\n",
    "                                     device=device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch} | train: Loss {train_loss:.6f} Accuracy {train_acc:.2f} | validation: Loss {val_loss:.6f} Accuracy {val_acc:.2f}\")\n",
    "\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3aefa6ffdddcb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:01.685815200Z",
     "start_time": "2023-12-24T18:13:44.509299500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ffeb35a66b48a5a57852a1ef59fe32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 7.770748 Accuracy 0.51 | validation: Loss 1.463997 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.401297 Accuracy 0.51 | validation: Loss 1.371067 Accuracy 0.51\n",
      "Epoch 2 | train: Loss 1.341635 Accuracy 0.54 | validation: Loss 1.315855 Accuracy 0.58\n",
      "Epoch 3 | train: Loss 1.281819 Accuracy 0.57 | validation: Loss 1.244994 Accuracy 0.58\n",
      "Epoch 4 | train: Loss 1.193157 Accuracy 0.60 | validation: Loss 1.165906 Accuracy 0.58\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "num_epochs = 5\n",
    "\n",
    "model0 = LOS_Classification_V0(INPUT_SHAPE, HIDDEN_UNITS, OUTPUT_SHAPE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(),\n",
    "                             lr=0.0001)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model0_results = train(model=model0,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       epochs=num_epochs,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f26e6d08bf6fe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T19:20:35.906702500Z",
     "start_time": "2023-12-24T19:07:44.848355900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f37cd68e984d7893d007cf41eda6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 7.770748 Accuracy 0.51 | validation: Loss 1.463997 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.401297 Accuracy 0.51 | validation: Loss 1.371067 Accuracy 0.51\n",
      "Epoch 2 | train: Loss 1.341635 Accuracy 0.54 | validation: Loss 1.315855 Accuracy 0.58\n",
      "Epoch 3 | train: Loss 1.281819 Accuracy 0.57 | validation: Loss 1.244994 Accuracy 0.58\n",
      "Epoch 4 | train: Loss 1.193157 Accuracy 0.60 | validation: Loss 1.165906 Accuracy 0.58\n",
      "Epoch 5 | train: Loss 1.137688 Accuracy 0.60 | validation: Loss 1.110927 Accuracy 0.63\n",
      "Epoch 6 | train: Loss 1.096668 Accuracy 0.62 | validation: Loss 1.072906 Accuracy 0.61\n",
      "Epoch 7 | train: Loss 1.058621 Accuracy 0.62 | validation: Loss 1.042243 Accuracy 0.63\n",
      "Epoch 8 | train: Loss 1.024245 Accuracy 0.63 | validation: Loss 1.014664 Accuracy 0.64\n",
      "Epoch 9 | train: Loss 1.010744 Accuracy 0.62 | validation: Loss 0.990566 Accuracy 0.64\n",
      "Epoch 10 | train: Loss 0.991309 Accuracy 0.63 | validation: Loss 0.989238 Accuracy 0.64\n",
      "Epoch 11 | train: Loss 0.980363 Accuracy 0.63 | validation: Loss 0.973587 Accuracy 0.64\n",
      "Epoch 12 | train: Loss 0.967430 Accuracy 0.64 | validation: Loss 0.962147 Accuracy 0.64\n",
      "Epoch 13 | train: Loss 0.954461 Accuracy 0.64 | validation: Loss 0.950874 Accuracy 0.64\n",
      "Epoch 14 | train: Loss 0.944159 Accuracy 0.64 | validation: Loss 0.947094 Accuracy 0.60\n",
      "Epoch 15 | train: Loss 0.931363 Accuracy 0.65 | validation: Loss 0.932474 Accuracy 0.63\n",
      "Epoch 16 | train: Loss 0.924713 Accuracy 0.64 | validation: Loss 0.922856 Accuracy 0.65\n",
      "Epoch 17 | train: Loss 0.921893 Accuracy 0.64 | validation: Loss 0.903907 Accuracy 0.65\n",
      "Epoch 18 | train: Loss 0.903587 Accuracy 0.65 | validation: Loss 0.903019 Accuracy 0.66\n",
      "Epoch 19 | train: Loss 0.894463 Accuracy 0.65 | validation: Loss 0.891470 Accuracy 0.65\n",
      "Epoch 20 | train: Loss 0.888241 Accuracy 0.66 | validation: Loss 0.892052 Accuracy 0.64\n",
      "Epoch 21 | train: Loss 0.878801 Accuracy 0.65 | validation: Loss 0.890870 Accuracy 0.62\n",
      "Epoch 22 | train: Loss 0.873351 Accuracy 0.66 | validation: Loss 0.871126 Accuracy 0.66\n",
      "Epoch 23 | train: Loss 0.867357 Accuracy 0.66 | validation: Loss 0.889601 Accuracy 0.62\n",
      "Epoch 24 | train: Loss 0.855807 Accuracy 0.66 | validation: Loss 0.864696 Accuracy 0.65\n",
      "Epoch 25 | train: Loss 0.852079 Accuracy 0.66 | validation: Loss 0.852106 Accuracy 0.67\n",
      "Epoch 26 | train: Loss 0.847461 Accuracy 0.66 | validation: Loss 0.868153 Accuracy 0.62\n",
      "Epoch 27 | train: Loss 0.842560 Accuracy 0.66 | validation: Loss 0.842749 Accuracy 0.66\n",
      "Epoch 28 | train: Loss 0.830981 Accuracy 0.67 | validation: Loss 0.840609 Accuracy 0.68\n",
      "Epoch 29 | train: Loss 0.828695 Accuracy 0.67 | validation: Loss 0.829810 Accuracy 0.66\n",
      "Epoch 30 | train: Loss 0.818988 Accuracy 0.68 | validation: Loss 0.824037 Accuracy 0.68\n",
      "Epoch 31 | train: Loss 0.814818 Accuracy 0.67 | validation: Loss 0.814565 Accuracy 0.68\n",
      "Epoch 32 | train: Loss 0.806863 Accuracy 0.68 | validation: Loss 0.818178 Accuracy 0.66\n",
      "Epoch 33 | train: Loss 0.805819 Accuracy 0.68 | validation: Loss 0.803347 Accuracy 0.69\n",
      "Epoch 34 | train: Loss 0.793926 Accuracy 0.69 | validation: Loss 0.799545 Accuracy 0.70\n",
      "Epoch 35 | train: Loss 0.787310 Accuracy 0.68 | validation: Loss 0.795609 Accuracy 0.70\n",
      "Epoch 36 | train: Loss 0.783704 Accuracy 0.68 | validation: Loss 0.785752 Accuracy 0.70\n",
      "Epoch 37 | train: Loss 0.780884 Accuracy 0.69 | validation: Loss 0.791324 Accuracy 0.69\n",
      "Epoch 38 | train: Loss 0.775238 Accuracy 0.69 | validation: Loss 0.787314 Accuracy 0.66\n",
      "Epoch 39 | train: Loss 0.768607 Accuracy 0.69 | validation: Loss 0.779149 Accuracy 0.67\n",
      "Epoch 40 | train: Loss 0.765579 Accuracy 0.70 | validation: Loss 0.772937 Accuracy 0.69\n",
      "Epoch 41 | train: Loss 0.756578 Accuracy 0.70 | validation: Loss 0.759977 Accuracy 0.71\n",
      "Epoch 42 | train: Loss 0.754385 Accuracy 0.70 | validation: Loss 0.757895 Accuracy 0.70\n",
      "Epoch 43 | train: Loss 0.746630 Accuracy 0.70 | validation: Loss 0.762511 Accuracy 0.68\n",
      "Epoch 44 | train: Loss 0.742982 Accuracy 0.71 | validation: Loss 0.755394 Accuracy 0.68\n",
      "Epoch 45 | train: Loss 0.737420 Accuracy 0.70 | validation: Loss 0.752400 Accuracy 0.68\n",
      "Epoch 46 | train: Loss 0.737618 Accuracy 0.70 | validation: Loss 0.740232 Accuracy 0.72\n",
      "Epoch 47 | train: Loss 0.726321 Accuracy 0.71 | validation: Loss 0.733530 Accuracy 0.72\n",
      "Epoch 48 | train: Loss 0.720792 Accuracy 0.71 | validation: Loss 0.727859 Accuracy 0.73\n",
      "Epoch 49 | train: Loss 0.719869 Accuracy 0.72 | validation: Loss 0.723642 Accuracy 0.73\n",
      "Epoch 50 | train: Loss 0.715293 Accuracy 0.72 | validation: Loss 0.727003 Accuracy 0.73\n",
      "Epoch 51 | train: Loss 0.711958 Accuracy 0.72 | validation: Loss 0.719967 Accuracy 0.72\n",
      "Epoch 52 | train: Loss 0.704912 Accuracy 0.72 | validation: Loss 0.722807 Accuracy 0.69\n",
      "Epoch 53 | train: Loss 0.699707 Accuracy 0.72 | validation: Loss 0.709715 Accuracy 0.73\n",
      "Epoch 54 | train: Loss 0.701183 Accuracy 0.72 | validation: Loss 0.698311 Accuracy 0.74\n",
      "Epoch 55 | train: Loss 0.692638 Accuracy 0.72 | validation: Loss 0.700265 Accuracy 0.74\n",
      "Epoch 56 | train: Loss 0.688808 Accuracy 0.73 | validation: Loss 0.696568 Accuracy 0.73\n",
      "Epoch 57 | train: Loss 0.687337 Accuracy 0.73 | validation: Loss 0.695952 Accuracy 0.75\n",
      "Epoch 58 | train: Loss 0.680272 Accuracy 0.73 | validation: Loss 0.697558 Accuracy 0.73\n",
      "Epoch 59 | train: Loss 0.678162 Accuracy 0.73 | validation: Loss 0.688365 Accuracy 0.71\n",
      "Epoch 60 | train: Loss 0.674192 Accuracy 0.73 | validation: Loss 0.676991 Accuracy 0.75\n",
      "Epoch 61 | train: Loss 0.667833 Accuracy 0.74 | validation: Loss 0.698862 Accuracy 0.70\n",
      "Epoch 62 | train: Loss 0.662572 Accuracy 0.74 | validation: Loss 0.675026 Accuracy 0.72\n",
      "Epoch 63 | train: Loss 0.659208 Accuracy 0.75 | validation: Loss 0.666871 Accuracy 0.76\n",
      "Epoch 64 | train: Loss 0.653192 Accuracy 0.75 | validation: Loss 0.657345 Accuracy 0.77\n",
      "Epoch 65 | train: Loss 0.647470 Accuracy 0.75 | validation: Loss 0.660546 Accuracy 0.75\n",
      "Epoch 66 | train: Loss 0.646440 Accuracy 0.75 | validation: Loss 0.654243 Accuracy 0.76\n",
      "Epoch 67 | train: Loss 0.646800 Accuracy 0.74 | validation: Loss 0.652966 Accuracy 0.76\n",
      "Epoch 68 | train: Loss 0.638284 Accuracy 0.75 | validation: Loss 0.664863 Accuracy 0.77\n",
      "Epoch 69 | train: Loss 0.634886 Accuracy 0.76 | validation: Loss 0.635528 Accuracy 0.76\n",
      "Epoch 70 | train: Loss 0.629202 Accuracy 0.76 | validation: Loss 0.649982 Accuracy 0.74\n",
      "Epoch 71 | train: Loss 0.628105 Accuracy 0.76 | validation: Loss 0.632560 Accuracy 0.78\n",
      "Epoch 72 | train: Loss 0.623127 Accuracy 0.76 | validation: Loss 0.627361 Accuracy 0.77\n",
      "Epoch 73 | train: Loss 0.619127 Accuracy 0.76 | validation: Loss 0.616061 Accuracy 0.78\n",
      "Epoch 74 | train: Loss 0.614265 Accuracy 0.76 | validation: Loss 0.627991 Accuracy 0.79\n",
      "Epoch 75 | train: Loss 0.611225 Accuracy 0.77 | validation: Loss 0.616467 Accuracy 0.77\n",
      "Epoch 76 | train: Loss 0.603866 Accuracy 0.77 | validation: Loss 0.679849 Accuracy 0.77\n",
      "Epoch 77 | train: Loss 0.607190 Accuracy 0.76 | validation: Loss 0.607421 Accuracy 0.77\n",
      "Epoch 78 | train: Loss 0.600754 Accuracy 0.77 | validation: Loss 0.611144 Accuracy 0.75\n",
      "Epoch 79 | train: Loss 0.594555 Accuracy 0.78 | validation: Loss 0.620293 Accuracy 0.75\n",
      "Epoch 80 | train: Loss 0.592735 Accuracy 0.78 | validation: Loss 0.592101 Accuracy 0.79\n",
      "Epoch 81 | train: Loss 0.587043 Accuracy 0.78 | validation: Loss 0.596168 Accuracy 0.80\n",
      "Epoch 82 | train: Loss 0.582139 Accuracy 0.78 | validation: Loss 0.589731 Accuracy 0.80\n",
      "Epoch 83 | train: Loss 0.578419 Accuracy 0.78 | validation: Loss 0.579975 Accuracy 0.80\n",
      "Epoch 84 | train: Loss 0.575213 Accuracy 0.79 | validation: Loss 0.586623 Accuracy 0.77\n",
      "Epoch 85 | train: Loss 0.573347 Accuracy 0.78 | validation: Loss 0.572913 Accuracy 0.80\n",
      "Epoch 86 | train: Loss 0.567625 Accuracy 0.78 | validation: Loss 0.569855 Accuracy 0.80\n",
      "Epoch 87 | train: Loss 0.567611 Accuracy 0.78 | validation: Loss 0.570562 Accuracy 0.79\n",
      "Epoch 88 | train: Loss 0.562606 Accuracy 0.79 | validation: Loss 0.584584 Accuracy 0.76\n",
      "Epoch 89 | train: Loss 0.561974 Accuracy 0.79 | validation: Loss 0.567529 Accuracy 0.79\n",
      "Epoch 90 | train: Loss 0.554004 Accuracy 0.79 | validation: Loss 0.558342 Accuracy 0.81\n",
      "Epoch 91 | train: Loss 0.551858 Accuracy 0.80 | validation: Loss 0.554501 Accuracy 0.80\n",
      "Epoch 92 | train: Loss 0.545720 Accuracy 0.79 | validation: Loss 0.562098 Accuracy 0.80\n",
      "Epoch 93 | train: Loss 0.546528 Accuracy 0.79 | validation: Loss 0.552496 Accuracy 0.82\n",
      "Epoch 94 | train: Loss 0.541834 Accuracy 0.80 | validation: Loss 0.565578 Accuracy 0.79\n",
      "Epoch 95 | train: Loss 0.544433 Accuracy 0.80 | validation: Loss 0.543707 Accuracy 0.82\n",
      "Epoch 96 | train: Loss 0.538126 Accuracy 0.80 | validation: Loss 0.543214 Accuracy 0.80\n",
      "Epoch 97 | train: Loss 0.536824 Accuracy 0.80 | validation: Loss 0.549271 Accuracy 0.80\n",
      "Epoch 98 | train: Loss 0.532085 Accuracy 0.80 | validation: Loss 0.554491 Accuracy 0.81\n",
      "Epoch 99 | train: Loss 0.527861 Accuracy 0.80 | validation: Loss 0.537508 Accuracy 0.83\n",
      "Epoch 100 | train: Loss 0.528462 Accuracy 0.80 | validation: Loss 0.530742 Accuracy 0.81\n",
      "Epoch 101 | train: Loss 0.523833 Accuracy 0.80 | validation: Loss 0.531885 Accuracy 0.81\n",
      "Epoch 102 | train: Loss 0.524451 Accuracy 0.80 | validation: Loss 0.532755 Accuracy 0.83\n",
      "Epoch 103 | train: Loss 0.517215 Accuracy 0.80 | validation: Loss 0.523418 Accuracy 0.83\n",
      "Epoch 104 | train: Loss 0.516947 Accuracy 0.80 | validation: Loss 0.520120 Accuracy 0.82\n",
      "Epoch 105 | train: Loss 0.512698 Accuracy 0.81 | validation: Loss 0.521333 Accuracy 0.84\n",
      "Epoch 106 | train: Loss 0.506155 Accuracy 0.82 | validation: Loss 0.516057 Accuracy 0.82\n",
      "Epoch 107 | train: Loss 0.505722 Accuracy 0.81 | validation: Loss 0.520029 Accuracy 0.82\n",
      "Epoch 108 | train: Loss 0.502788 Accuracy 0.82 | validation: Loss 0.512856 Accuracy 0.82\n",
      "Epoch 109 | train: Loss 0.504817 Accuracy 0.81 | validation: Loss 0.500713 Accuracy 0.84\n",
      "Epoch 110 | train: Loss 0.500524 Accuracy 0.81 | validation: Loss 0.537016 Accuracy 0.78\n",
      "Epoch 111 | train: Loss 0.498246 Accuracy 0.81 | validation: Loss 0.502912 Accuracy 0.84\n",
      "Epoch 112 | train: Loss 0.494976 Accuracy 0.82 | validation: Loss 0.513809 Accuracy 0.79\n",
      "Epoch 113 | train: Loss 0.497342 Accuracy 0.81 | validation: Loss 0.514945 Accuracy 0.81\n",
      "Epoch 114 | train: Loss 0.491713 Accuracy 0.82 | validation: Loss 0.503188 Accuracy 0.83\n",
      "Epoch 115 | train: Loss 0.486018 Accuracy 0.82 | validation: Loss 0.504558 Accuracy 0.79\n",
      "Epoch 116 | train: Loss 0.487373 Accuracy 0.82 | validation: Loss 0.496496 Accuracy 0.82\n",
      "Epoch 117 | train: Loss 0.484922 Accuracy 0.82 | validation: Loss 0.495053 Accuracy 0.81\n",
      "Epoch 118 | train: Loss 0.485716 Accuracy 0.82 | validation: Loss 0.491333 Accuracy 0.82\n",
      "Epoch 119 | train: Loss 0.477677 Accuracy 0.82 | validation: Loss 0.500013 Accuracy 0.81\n",
      "Epoch 120 | train: Loss 0.477340 Accuracy 0.82 | validation: Loss 0.486932 Accuracy 0.82\n",
      "Epoch 121 | train: Loss 0.475626 Accuracy 0.83 | validation: Loss 0.480615 Accuracy 0.84\n",
      "Epoch 122 | train: Loss 0.474442 Accuracy 0.82 | validation: Loss 0.486063 Accuracy 0.80\n",
      "Epoch 123 | train: Loss 0.471689 Accuracy 0.82 | validation: Loss 0.480748 Accuracy 0.85\n",
      "Epoch 124 | train: Loss 0.468587 Accuracy 0.83 | validation: Loss 0.492085 Accuracy 0.81\n",
      "Epoch 125 | train: Loss 0.465093 Accuracy 0.83 | validation: Loss 0.473344 Accuracy 0.82\n",
      "Epoch 126 | train: Loss 0.466044 Accuracy 0.83 | validation: Loss 0.472774 Accuracy 0.82\n",
      "Epoch 127 | train: Loss 0.460097 Accuracy 0.83 | validation: Loss 0.474118 Accuracy 0.86\n",
      "Epoch 128 | train: Loss 0.462574 Accuracy 0.83 | validation: Loss 0.487741 Accuracy 0.81\n",
      "Epoch 129 | train: Loss 0.462879 Accuracy 0.83 | validation: Loss 0.466325 Accuracy 0.84\n",
      "Epoch 130 | train: Loss 0.455076 Accuracy 0.83 | validation: Loss 0.474711 Accuracy 0.84\n",
      "Epoch 131 | train: Loss 0.451570 Accuracy 0.83 | validation: Loss 0.477230 Accuracy 0.80\n",
      "Epoch 132 | train: Loss 0.453679 Accuracy 0.83 | validation: Loss 0.457543 Accuracy 0.83\n",
      "Epoch 133 | train: Loss 0.448984 Accuracy 0.83 | validation: Loss 0.457155 Accuracy 0.84\n",
      "Epoch 134 | train: Loss 0.448344 Accuracy 0.83 | validation: Loss 0.469272 Accuracy 0.82\n",
      "Epoch 135 | train: Loss 0.446569 Accuracy 0.84 | validation: Loss 0.454110 Accuracy 0.83\n",
      "Epoch 136 | train: Loss 0.449638 Accuracy 0.83 | validation: Loss 0.446409 Accuracy 0.84\n",
      "Epoch 137 | train: Loss 0.440898 Accuracy 0.83 | validation: Loss 0.454255 Accuracy 0.84\n",
      "Epoch 138 | train: Loss 0.435917 Accuracy 0.85 | validation: Loss 0.465914 Accuracy 0.83\n",
      "Epoch 139 | train: Loss 0.438036 Accuracy 0.84 | validation: Loss 0.443309 Accuracy 0.84\n",
      "Epoch 140 | train: Loss 0.437185 Accuracy 0.84 | validation: Loss 0.442749 Accuracy 0.84\n",
      "Epoch 141 | train: Loss 0.434688 Accuracy 0.85 | validation: Loss 0.443494 Accuracy 0.82\n",
      "Epoch 142 | train: Loss 0.437726 Accuracy 0.84 | validation: Loss 0.441629 Accuracy 0.83\n",
      "Epoch 143 | train: Loss 0.430795 Accuracy 0.85 | validation: Loss 0.443103 Accuracy 0.84\n",
      "Epoch 144 | train: Loss 0.432675 Accuracy 0.84 | validation: Loss 0.433754 Accuracy 0.86\n",
      "Epoch 145 | train: Loss 0.429997 Accuracy 0.84 | validation: Loss 0.455517 Accuracy 0.83\n",
      "Epoch 146 | train: Loss 0.420509 Accuracy 0.85 | validation: Loss 0.428323 Accuracy 0.86\n",
      "Epoch 147 | train: Loss 0.424068 Accuracy 0.85 | validation: Loss 0.424805 Accuracy 0.86\n",
      "Epoch 148 | train: Loss 0.423103 Accuracy 0.85 | validation: Loss 0.426771 Accuracy 0.84\n",
      "Epoch 149 | train: Loss 0.421092 Accuracy 0.85 | validation: Loss 0.423263 Accuracy 0.84\n",
      "Epoch 150 | train: Loss 0.416928 Accuracy 0.85 | validation: Loss 0.432876 Accuracy 0.84\n",
      "Epoch 151 | train: Loss 0.419922 Accuracy 0.85 | validation: Loss 0.436764 Accuracy 0.84\n",
      "Epoch 152 | train: Loss 0.415029 Accuracy 0.85 | validation: Loss 0.422672 Accuracy 0.83\n",
      "Epoch 153 | train: Loss 0.421162 Accuracy 0.85 | validation: Loss 0.428838 Accuracy 0.84\n",
      "Epoch 154 | train: Loss 0.411587 Accuracy 0.85 | validation: Loss 0.423902 Accuracy 0.85\n",
      "Epoch 155 | train: Loss 0.410195 Accuracy 0.85 | validation: Loss 0.417422 Accuracy 0.87\n",
      "Epoch 156 | train: Loss 0.406899 Accuracy 0.86 | validation: Loss 0.412521 Accuracy 0.86\n",
      "Epoch 157 | train: Loss 0.407120 Accuracy 0.86 | validation: Loss 0.411075 Accuracy 0.84\n",
      "Epoch 158 | train: Loss 0.400906 Accuracy 0.86 | validation: Loss 0.406766 Accuracy 0.87\n",
      "Epoch 159 | train: Loss 0.406483 Accuracy 0.85 | validation: Loss 0.409017 Accuracy 0.86\n",
      "Epoch 160 | train: Loss 0.401239 Accuracy 0.87 | validation: Loss 0.406618 Accuracy 0.88\n",
      "Epoch 161 | train: Loss 0.401735 Accuracy 0.86 | validation: Loss 0.405226 Accuracy 0.85\n",
      "Epoch 162 | train: Loss 0.399014 Accuracy 0.86 | validation: Loss 0.407007 Accuracy 0.88\n",
      "Epoch 163 | train: Loss 0.396915 Accuracy 0.86 | validation: Loss 0.398108 Accuracy 0.86\n",
      "Epoch 164 | train: Loss 0.395926 Accuracy 0.86 | validation: Loss 0.401902 Accuracy 0.88\n",
      "Epoch 165 | train: Loss 0.392796 Accuracy 0.87 | validation: Loss 0.398523 Accuracy 0.88\n",
      "Epoch 166 | train: Loss 0.394632 Accuracy 0.86 | validation: Loss 0.392342 Accuracy 0.86\n",
      "Epoch 167 | train: Loss 0.388450 Accuracy 0.87 | validation: Loss 0.393166 Accuracy 0.86\n",
      "Epoch 168 | train: Loss 0.388460 Accuracy 0.87 | validation: Loss 0.392684 Accuracy 0.85\n",
      "Epoch 169 | train: Loss 0.385769 Accuracy 0.87 | validation: Loss 0.385049 Accuracy 0.87\n",
      "Epoch 170 | train: Loss 0.382767 Accuracy 0.87 | validation: Loss 0.388387 Accuracy 0.86\n",
      "Epoch 171 | train: Loss 0.381710 Accuracy 0.86 | validation: Loss 0.412501 Accuracy 0.86\n",
      "Epoch 172 | train: Loss 0.381592 Accuracy 0.87 | validation: Loss 0.394585 Accuracy 0.87\n",
      "Epoch 173 | train: Loss 0.380422 Accuracy 0.87 | validation: Loss 0.389696 Accuracy 0.88\n",
      "Epoch 174 | train: Loss 0.380729 Accuracy 0.86 | validation: Loss 0.388517 Accuracy 0.85\n",
      "Epoch 175 | train: Loss 0.375394 Accuracy 0.87 | validation: Loss 0.384511 Accuracy 0.87\n",
      "Epoch 176 | train: Loss 0.378823 Accuracy 0.87 | validation: Loss 0.396211 Accuracy 0.87\n",
      "Epoch 177 | train: Loss 0.371371 Accuracy 0.88 | validation: Loss 0.374928 Accuracy 0.89\n",
      "Epoch 178 | train: Loss 0.375616 Accuracy 0.87 | validation: Loss 0.386345 Accuracy 0.86\n",
      "Epoch 179 | train: Loss 0.378481 Accuracy 0.87 | validation: Loss 0.382247 Accuracy 0.87\n",
      "Epoch 180 | train: Loss 0.377036 Accuracy 0.87 | validation: Loss 0.385251 Accuracy 0.86\n",
      "Epoch 181 | train: Loss 0.372210 Accuracy 0.87 | validation: Loss 0.383151 Accuracy 0.86\n",
      "Epoch 182 | train: Loss 0.366490 Accuracy 0.87 | validation: Loss 0.370280 Accuracy 0.87\n",
      "Epoch 183 | train: Loss 0.368609 Accuracy 0.87 | validation: Loss 0.374418 Accuracy 0.86\n",
      "Epoch 184 | train: Loss 0.365448 Accuracy 0.87 | validation: Loss 0.368496 Accuracy 0.87\n",
      "Epoch 185 | train: Loss 0.363412 Accuracy 0.88 | validation: Loss 0.382710 Accuracy 0.86\n",
      "Epoch 186 | train: Loss 0.363884 Accuracy 0.87 | validation: Loss 0.383940 Accuracy 0.87\n",
      "Epoch 187 | train: Loss 0.357921 Accuracy 0.88 | validation: Loss 0.368488 Accuracy 0.87\n",
      "Epoch 188 | train: Loss 0.360943 Accuracy 0.88 | validation: Loss 0.367824 Accuracy 0.88\n",
      "Epoch 189 | train: Loss 0.356092 Accuracy 0.88 | validation: Loss 0.357405 Accuracy 0.88\n",
      "Epoch 190 | train: Loss 0.360234 Accuracy 0.87 | validation: Loss 0.362458 Accuracy 0.87\n",
      "Epoch 191 | train: Loss 0.359251 Accuracy 0.87 | validation: Loss 0.356921 Accuracy 0.88\n",
      "Epoch 192 | train: Loss 0.353327 Accuracy 0.88 | validation: Loss 0.358972 Accuracy 0.88\n",
      "Epoch 193 | train: Loss 0.354483 Accuracy 0.88 | validation: Loss 0.363803 Accuracy 0.88\n",
      "Epoch 194 | train: Loss 0.349414 Accuracy 0.88 | validation: Loss 0.361482 Accuracy 0.87\n",
      "Epoch 195 | train: Loss 0.350001 Accuracy 0.88 | validation: Loss 0.352461 Accuracy 0.89\n",
      "Epoch 196 | train: Loss 0.352416 Accuracy 0.88 | validation: Loss 0.349933 Accuracy 0.89\n",
      "Epoch 197 | train: Loss 0.347184 Accuracy 0.88 | validation: Loss 0.361707 Accuracy 0.86\n",
      "Epoch 198 | train: Loss 0.345992 Accuracy 0.88 | validation: Loss 0.354419 Accuracy 0.87\n",
      "Epoch 199 | train: Loss 0.346362 Accuracy 0.88 | validation: Loss 0.370631 Accuracy 0.86\n",
      "Epoch 200 | train: Loss 0.346107 Accuracy 0.88 | validation: Loss 0.345049 Accuracy 0.89\n",
      "Epoch 201 | train: Loss 0.343118 Accuracy 0.88 | validation: Loss 0.394559 Accuracy 0.84\n",
      "Epoch 202 | train: Loss 0.344664 Accuracy 0.88 | validation: Loss 0.378604 Accuracy 0.86\n",
      "Epoch 203 | train: Loss 0.347415 Accuracy 0.88 | validation: Loss 0.346566 Accuracy 0.88\n",
      "Epoch 204 | train: Loss 0.338261 Accuracy 0.88 | validation: Loss 0.348213 Accuracy 0.88\n",
      "Epoch 205 | train: Loss 0.336130 Accuracy 0.88 | validation: Loss 0.349492 Accuracy 0.86\n",
      "Epoch 206 | train: Loss 0.335462 Accuracy 0.88 | validation: Loss 0.344729 Accuracy 0.89\n",
      "Epoch 207 | train: Loss 0.336181 Accuracy 0.88 | validation: Loss 0.352053 Accuracy 0.87\n",
      "Epoch 208 | train: Loss 0.331266 Accuracy 0.89 | validation: Loss 0.343900 Accuracy 0.88\n",
      "Epoch 209 | train: Loss 0.332342 Accuracy 0.89 | validation: Loss 0.356737 Accuracy 0.87\n",
      "Epoch 210 | train: Loss 0.334392 Accuracy 0.88 | validation: Loss 0.345622 Accuracy 0.87\n",
      "Epoch 211 | train: Loss 0.332287 Accuracy 0.89 | validation: Loss 0.341389 Accuracy 0.87\n",
      "Epoch 212 | train: Loss 0.328317 Accuracy 0.89 | validation: Loss 0.339043 Accuracy 0.87\n",
      "Epoch 213 | train: Loss 0.328341 Accuracy 0.88 | validation: Loss 0.338837 Accuracy 0.87\n",
      "Epoch 214 | train: Loss 0.328864 Accuracy 0.88 | validation: Loss 0.330155 Accuracy 0.88\n",
      "Epoch 215 | train: Loss 0.325545 Accuracy 0.89 | validation: Loss 0.329603 Accuracy 0.89\n",
      "Epoch 216 | train: Loss 0.324789 Accuracy 0.89 | validation: Loss 0.327159 Accuracy 0.88\n",
      "Epoch 217 | train: Loss 0.325475 Accuracy 0.89 | validation: Loss 0.343422 Accuracy 0.88\n",
      "Epoch 218 | train: Loss 0.322257 Accuracy 0.89 | validation: Loss 0.346967 Accuracy 0.87\n",
      "Epoch 219 | train: Loss 0.321889 Accuracy 0.89 | validation: Loss 0.332222 Accuracy 0.88\n",
      "Epoch 220 | train: Loss 0.319267 Accuracy 0.88 | validation: Loss 0.327717 Accuracy 0.89\n",
      "Epoch 221 | train: Loss 0.321842 Accuracy 0.89 | validation: Loss 0.341397 Accuracy 0.88\n",
      "Epoch 222 | train: Loss 0.318900 Accuracy 0.89 | validation: Loss 0.326056 Accuracy 0.88\n",
      "Epoch 223 | train: Loss 0.318535 Accuracy 0.89 | validation: Loss 0.332342 Accuracy 0.89\n",
      "Epoch 224 | train: Loss 0.317381 Accuracy 0.89 | validation: Loss 0.317346 Accuracy 0.89\n",
      "Epoch 225 | train: Loss 0.312445 Accuracy 0.89 | validation: Loss 0.313868 Accuracy 0.90\n",
      "Epoch 226 | train: Loss 0.315829 Accuracy 0.89 | validation: Loss 0.345417 Accuracy 0.87\n",
      "Epoch 227 | train: Loss 0.314513 Accuracy 0.89 | validation: Loss 0.338560 Accuracy 0.85\n",
      "Epoch 228 | train: Loss 0.312808 Accuracy 0.89 | validation: Loss 0.319744 Accuracy 0.90\n",
      "Epoch 229 | train: Loss 0.313076 Accuracy 0.89 | validation: Loss 0.314789 Accuracy 0.89\n",
      "Epoch 230 | train: Loss 0.310763 Accuracy 0.89 | validation: Loss 0.308993 Accuracy 0.90\n",
      "Epoch 231 | train: Loss 0.309371 Accuracy 0.89 | validation: Loss 0.322061 Accuracy 0.89\n",
      "Epoch 232 | train: Loss 0.309068 Accuracy 0.89 | validation: Loss 0.318790 Accuracy 0.89\n",
      "Epoch 233 | train: Loss 0.308645 Accuracy 0.89 | validation: Loss 0.305059 Accuracy 0.91\n",
      "Epoch 234 | train: Loss 0.307304 Accuracy 0.89 | validation: Loss 0.321795 Accuracy 0.90\n",
      "Epoch 235 | train: Loss 0.304562 Accuracy 0.89 | validation: Loss 0.311868 Accuracy 0.89\n",
      "Epoch 236 | train: Loss 0.304523 Accuracy 0.89 | validation: Loss 0.321460 Accuracy 0.88\n",
      "Epoch 237 | train: Loss 0.302625 Accuracy 0.90 | validation: Loss 0.308588 Accuracy 0.88\n",
      "Epoch 238 | train: Loss 0.299344 Accuracy 0.90 | validation: Loss 0.305332 Accuracy 0.90\n",
      "Epoch 239 | train: Loss 0.305674 Accuracy 0.89 | validation: Loss 0.303903 Accuracy 0.90\n",
      "Epoch 240 | train: Loss 0.305932 Accuracy 0.89 | validation: Loss 0.301926 Accuracy 0.89\n",
      "Epoch 241 | train: Loss 0.297966 Accuracy 0.90 | validation: Loss 0.307889 Accuracy 0.89\n",
      "Epoch 242 | train: Loss 0.306947 Accuracy 0.89 | validation: Loss 0.302777 Accuracy 0.91\n",
      "Epoch 243 | train: Loss 0.299167 Accuracy 0.89 | validation: Loss 0.303311 Accuracy 0.90\n",
      "Epoch 244 | train: Loss 0.292272 Accuracy 0.90 | validation: Loss 0.304009 Accuracy 0.91\n",
      "Epoch 245 | train: Loss 0.296277 Accuracy 0.90 | validation: Loss 0.328856 Accuracy 0.87\n",
      "Epoch 246 | train: Loss 0.295577 Accuracy 0.89 | validation: Loss 0.298420 Accuracy 0.89\n",
      "Epoch 247 | train: Loss 0.289695 Accuracy 0.90 | validation: Loss 0.319914 Accuracy 0.89\n",
      "Epoch 248 | train: Loss 0.297698 Accuracy 0.89 | validation: Loss 0.330386 Accuracy 0.88\n",
      "Epoch 249 | train: Loss 0.298616 Accuracy 0.89 | validation: Loss 0.340968 Accuracy 0.87\n",
      "Epoch 250 | train: Loss 0.293636 Accuracy 0.90 | validation: Loss 0.315843 Accuracy 0.89\n",
      "Epoch 251 | train: Loss 0.287530 Accuracy 0.90 | validation: Loss 0.300059 Accuracy 0.90\n",
      "Epoch 252 | train: Loss 0.295828 Accuracy 0.89 | validation: Loss 0.302871 Accuracy 0.89\n",
      "Epoch 253 | train: Loss 0.291552 Accuracy 0.89 | validation: Loss 0.294455 Accuracy 0.89\n",
      "Epoch 254 | train: Loss 0.287242 Accuracy 0.90 | validation: Loss 0.287701 Accuracy 0.90\n",
      "Epoch 255 | train: Loss 0.288039 Accuracy 0.90 | validation: Loss 0.306954 Accuracy 0.89\n",
      "Epoch 256 | train: Loss 0.286583 Accuracy 0.90 | validation: Loss 0.301925 Accuracy 0.91\n",
      "Epoch 257 | train: Loss 0.285949 Accuracy 0.90 | validation: Loss 0.295007 Accuracy 0.89\n",
      "Epoch 258 | train: Loss 0.284516 Accuracy 0.90 | validation: Loss 0.283078 Accuracy 0.92\n",
      "Epoch 259 | train: Loss 0.281560 Accuracy 0.90 | validation: Loss 0.282741 Accuracy 0.92\n",
      "Epoch 260 | train: Loss 0.286303 Accuracy 0.90 | validation: Loss 0.286794 Accuracy 0.90\n",
      "Epoch 261 | train: Loss 0.285046 Accuracy 0.90 | validation: Loss 0.289760 Accuracy 0.90\n",
      "Epoch 262 | train: Loss 0.281884 Accuracy 0.90 | validation: Loss 0.282280 Accuracy 0.91\n",
      "Epoch 263 | train: Loss 0.275429 Accuracy 0.90 | validation: Loss 0.298413 Accuracy 0.89\n",
      "Epoch 264 | train: Loss 0.281696 Accuracy 0.90 | validation: Loss 0.275151 Accuracy 0.92\n",
      "Epoch 265 | train: Loss 0.277532 Accuracy 0.90 | validation: Loss 0.283007 Accuracy 0.90\n",
      "Epoch 266 | train: Loss 0.275489 Accuracy 0.90 | validation: Loss 0.296941 Accuracy 0.88\n",
      "Epoch 267 | train: Loss 0.276857 Accuracy 0.90 | validation: Loss 0.284111 Accuracy 0.90\n",
      "Epoch 268 | train: Loss 0.278191 Accuracy 0.90 | validation: Loss 0.283592 Accuracy 0.90\n",
      "Epoch 269 | train: Loss 0.274152 Accuracy 0.90 | validation: Loss 0.285690 Accuracy 0.89\n",
      "Epoch 270 | train: Loss 0.280634 Accuracy 0.89 | validation: Loss 0.309551 Accuracy 0.87\n",
      "Epoch 271 | train: Loss 0.275176 Accuracy 0.90 | validation: Loss 0.291976 Accuracy 0.89\n",
      "Epoch 272 | train: Loss 0.273847 Accuracy 0.90 | validation: Loss 0.316400 Accuracy 0.88\n",
      "Epoch 273 | train: Loss 0.275850 Accuracy 0.90 | validation: Loss 0.284383 Accuracy 0.90\n",
      "Epoch 274 | train: Loss 0.268953 Accuracy 0.91 | validation: Loss 0.277572 Accuracy 0.90\n",
      "Early_Stop_at_ 274 Epoch\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "model0 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(), lr=0.0001)\n",
    "\n",
    "model0_results = engine.train(model=model0,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              early_stop_patience=10,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127ac94d7bb26bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T19:48:00.955527500Z",
     "start_time": "2023-12-24T19:46:58.741558900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] create SummaryWriter saving to runs\\2023-12-24-23\\luzern\\Neural_Net\\20epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db023c0739d4fe9a19f2854c38892c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 7.770748 Accuracy 0.51 | validation: Loss 1.463997 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.399654 Accuracy 0.52 | validation: Loss 1.359263 Accuracy 0.52\n",
      "Epoch 2 | train: Loss 1.339121 Accuracy 0.55 | validation: Loss 1.321238 Accuracy 0.51\n",
      "Epoch 3 | train: Loss 1.281425 Accuracy 0.57 | validation: Loss 1.238373 Accuracy 0.56\n",
      "Epoch 4 | train: Loss 1.193089 Accuracy 0.61 | validation: Loss 1.167704 Accuracy 0.61\n",
      "Epoch 5 | train: Loss 1.130246 Accuracy 0.62 | validation: Loss 1.107890 Accuracy 0.62\n",
      "Epoch 6 | train: Loss 1.096060 Accuracy 0.61 | validation: Loss 1.086527 Accuracy 0.62\n",
      "Epoch 7 | train: Loss 1.060004 Accuracy 0.62 | validation: Loss 1.040833 Accuracy 0.62\n",
      "Epoch 8 | train: Loss 1.027882 Accuracy 0.62 | validation: Loss 1.006603 Accuracy 0.64\n",
      "Epoch 9 | train: Loss 1.004187 Accuracy 0.63 | validation: Loss 0.994309 Accuracy 0.64\n",
      "Epoch 10 | train: Loss 0.989944 Accuracy 0.63 | validation: Loss 0.994836 Accuracy 0.63\n",
      "Epoch 11 | train: Loss 0.980709 Accuracy 0.63 | validation: Loss 0.971572 Accuracy 0.61\n",
      "Epoch 12 | train: Loss 0.968566 Accuracy 0.64 | validation: Loss 0.970568 Accuracy 0.61\n",
      "Epoch 13 | train: Loss 0.954615 Accuracy 0.63 | validation: Loss 0.945129 Accuracy 0.64\n",
      "Epoch 14 | train: Loss 0.943479 Accuracy 0.64 | validation: Loss 0.949176 Accuracy 0.66\n",
      "Epoch 15 | train: Loss 0.932791 Accuracy 0.65 | validation: Loss 0.929461 Accuracy 0.64\n",
      "Epoch 16 | train: Loss 0.923877 Accuracy 0.64 | validation: Loss 0.916025 Accuracy 0.64\n",
      "Epoch 17 | train: Loss 0.913651 Accuracy 0.65 | validation: Loss 0.917875 Accuracy 0.64\n",
      "Epoch 18 | train: Loss 0.912577 Accuracy 0.64 | validation: Loss 0.931566 Accuracy 0.61\n",
      "Epoch 19 | train: Loss 0.895737 Accuracy 0.66 | validation: Loss 0.905442 Accuracy 0.64\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "model1 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model1.parameters(), lr=0.0001)\n",
    "\n",
    "model1_results = engine.train(model=model1,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              experiment_name=\"luzern\",\n",
    "                              model_name=\"Neural_Net\",\n",
    "                              early_stop_patience=None,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571334e71b9628e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] create SummaryWriter saving to runs\\2023-12-24-23\\luzern_V0\\Neural_Net\\500epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fd25e04e8340ed80baa927e0593071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 3.876857 Accuracy 0.30 | validation: Loss 1.556792 Accuracy 0.36\n",
      "Epoch 1 | train: Loss 1.414394 Accuracy 0.45 | validation: Loss 1.381815 Accuracy 0.45\n",
      "Epoch 2 | train: Loss 1.348989 Accuracy 0.48 | validation: Loss 1.321669 Accuracy 0.51\n",
      "Epoch 3 | train: Loss 1.300869 Accuracy 0.53 | validation: Loss 1.280636 Accuracy 0.55\n",
      "Epoch 4 | train: Loss 1.261051 Accuracy 0.55 | validation: Loss 1.241374 Accuracy 0.56\n",
      "Epoch 5 | train: Loss 1.228816 Accuracy 0.57 | validation: Loss 1.220952 Accuracy 0.56\n",
      "Epoch 6 | train: Loss 1.193593 Accuracy 0.59 | validation: Loss 1.178762 Accuracy 0.60\n",
      "Epoch 7 | train: Loss 1.168743 Accuracy 0.60 | validation: Loss 1.160066 Accuracy 0.57\n",
      "Epoch 8 | train: Loss 1.136830 Accuracy 0.60 | validation: Loss 1.115764 Accuracy 0.62\n",
      "Epoch 9 | train: Loss 1.107547 Accuracy 0.62 | validation: Loss 1.092079 Accuracy 0.62\n",
      "Epoch 10 | train: Loss 1.083820 Accuracy 0.62 | validation: Loss 1.058507 Accuracy 0.61\n",
      "Epoch 11 | train: Loss 1.062855 Accuracy 0.62 | validation: Loss 1.046916 Accuracy 0.63\n",
      "Epoch 12 | train: Loss 1.044801 Accuracy 0.63 | validation: Loss 1.048737 Accuracy 0.62\n",
      "Epoch 13 | train: Loss 1.038858 Accuracy 0.62 | validation: Loss 1.038911 Accuracy 0.61\n",
      "Epoch 14 | train: Loss 1.023367 Accuracy 0.63 | validation: Loss 1.015831 Accuracy 0.62\n",
      "Epoch 15 | train: Loss 1.017173 Accuracy 0.64 | validation: Loss 0.998556 Accuracy 0.65\n",
      "Epoch 16 | train: Loss 1.003399 Accuracy 0.64 | validation: Loss 0.987078 Accuracy 0.65\n",
      "Epoch 17 | train: Loss 0.997764 Accuracy 0.64 | validation: Loss 0.999785 Accuracy 0.63\n",
      "Epoch 18 | train: Loss 0.998883 Accuracy 0.63 | validation: Loss 1.016878 Accuracy 0.62\n",
      "Epoch 19 | train: Loss 0.985047 Accuracy 0.64 | validation: Loss 0.972405 Accuracy 0.64\n",
      "Epoch 20 | train: Loss 0.974064 Accuracy 0.64 | validation: Loss 0.963166 Accuracy 0.63\n",
      "Epoch 21 | train: Loss 0.968803 Accuracy 0.64 | validation: Loss 0.971102 Accuracy 0.64\n",
      "Epoch 22 | train: Loss 0.963336 Accuracy 0.64 | validation: Loss 0.949803 Accuracy 0.65\n",
      "Epoch 23 | train: Loss 0.956807 Accuracy 0.64 | validation: Loss 0.976924 Accuracy 0.60\n",
      "Epoch 24 | train: Loss 0.947555 Accuracy 0.64 | validation: Loss 0.938279 Accuracy 0.65\n",
      "Epoch 25 | train: Loss 0.938958 Accuracy 0.65 | validation: Loss 0.941757 Accuracy 0.65\n",
      "Epoch 26 | train: Loss 0.930285 Accuracy 0.66 | validation: Loss 0.948416 Accuracy 0.65\n",
      "Epoch 27 | train: Loss 0.926858 Accuracy 0.65 | validation: Loss 0.953349 Accuracy 0.61\n",
      "Epoch 28 | train: Loss 0.926055 Accuracy 0.65 | validation: Loss 0.918128 Accuracy 0.65\n",
      "Epoch 29 | train: Loss 0.913901 Accuracy 0.66 | validation: Loss 0.899385 Accuracy 0.68\n",
      "Epoch 30 | train: Loss 0.908351 Accuracy 0.66 | validation: Loss 0.904092 Accuracy 0.65\n",
      "Epoch 31 | train: Loss 0.915568 Accuracy 0.64 | validation: Loss 0.909365 Accuracy 0.64\n",
      "Epoch 32 | train: Loss 0.903635 Accuracy 0.66 | validation: Loss 0.891791 Accuracy 0.66\n",
      "Epoch 33 | train: Loss 0.891461 Accuracy 0.66 | validation: Loss 0.883303 Accuracy 0.66\n",
      "Epoch 34 | train: Loss 0.886497 Accuracy 0.66 | validation: Loss 0.871794 Accuracy 0.67\n",
      "Epoch 35 | train: Loss 0.883316 Accuracy 0.66 | validation: Loss 0.882102 Accuracy 0.66\n",
      "Epoch 36 | train: Loss 0.885194 Accuracy 0.66 | validation: Loss 0.871692 Accuracy 0.65\n",
      "Epoch 37 | train: Loss 0.872252 Accuracy 0.67 | validation: Loss 0.879507 Accuracy 0.65\n",
      "Epoch 38 | train: Loss 0.865721 Accuracy 0.67 | validation: Loss 0.854662 Accuracy 0.68\n",
      "Epoch 39 | train: Loss 0.863849 Accuracy 0.67 | validation: Loss 0.852232 Accuracy 0.66\n",
      "Epoch 40 | train: Loss 0.853739 Accuracy 0.67 | validation: Loss 0.850874 Accuracy 0.68\n",
      "Epoch 41 | train: Loss 0.853240 Accuracy 0.67 | validation: Loss 0.867724 Accuracy 0.66\n",
      "Epoch 42 | train: Loss 0.846486 Accuracy 0.67 | validation: Loss 0.838688 Accuracy 0.67\n",
      "Epoch 43 | train: Loss 0.839194 Accuracy 0.68 | validation: Loss 0.835264 Accuracy 0.70\n",
      "Epoch 44 | train: Loss 0.836983 Accuracy 0.68 | validation: Loss 0.831703 Accuracy 0.67\n",
      "Epoch 45 | train: Loss 0.833620 Accuracy 0.68 | validation: Loss 0.818513 Accuracy 0.67\n",
      "Epoch 46 | train: Loss 0.832059 Accuracy 0.67 | validation: Loss 0.823759 Accuracy 0.69\n",
      "Epoch 47 | train: Loss 0.819347 Accuracy 0.68 | validation: Loss 0.838575 Accuracy 0.66\n",
      "Epoch 48 | train: Loss 0.821003 Accuracy 0.68 | validation: Loss 0.819700 Accuracy 0.70\n",
      "Epoch 49 | train: Loss 0.813097 Accuracy 0.68 | validation: Loss 0.800263 Accuracy 0.69\n",
      "Epoch 50 | train: Loss 0.804085 Accuracy 0.69 | validation: Loss 0.804919 Accuracy 0.67\n",
      "Epoch 51 | train: Loss 0.804133 Accuracy 0.69 | validation: Loss 0.798528 Accuracy 0.68\n",
      "Epoch 52 | train: Loss 0.794143 Accuracy 0.70 | validation: Loss 0.795558 Accuracy 0.71\n",
      "Epoch 53 | train: Loss 0.796435 Accuracy 0.68 | validation: Loss 0.809574 Accuracy 0.69\n",
      "Epoch 54 | train: Loss 0.789829 Accuracy 0.70 | validation: Loss 0.787223 Accuracy 0.68\n",
      "Epoch 55 | train: Loss 0.784643 Accuracy 0.70 | validation: Loss 0.781530 Accuracy 0.69\n",
      "Epoch 56 | train: Loss 0.777227 Accuracy 0.70 | validation: Loss 0.780031 Accuracy 0.69\n",
      "Epoch 57 | train: Loss 0.778327 Accuracy 0.70 | validation: Loss 0.796154 Accuracy 0.67\n",
      "Epoch 58 | train: Loss 0.777127 Accuracy 0.70 | validation: Loss 0.756710 Accuracy 0.72\n",
      "Epoch 59 | train: Loss 0.770429 Accuracy 0.70 | validation: Loss 0.768300 Accuracy 0.69\n",
      "Epoch 60 | train: Loss 0.765768 Accuracy 0.70 | validation: Loss 0.779893 Accuracy 0.68\n",
      "Epoch 61 | train: Loss 0.764207 Accuracy 0.71 | validation: Loss 0.766008 Accuracy 0.72\n",
      "Epoch 62 | train: Loss 0.761226 Accuracy 0.71 | validation: Loss 0.763152 Accuracy 0.71\n",
      "Epoch 63 | train: Loss 0.755245 Accuracy 0.71 | validation: Loss 0.749535 Accuracy 0.71\n",
      "Epoch 64 | train: Loss 0.749767 Accuracy 0.72 | validation: Loss 0.766685 Accuracy 0.69\n",
      "Epoch 65 | train: Loss 0.747193 Accuracy 0.71 | validation: Loss 0.750288 Accuracy 0.73\n",
      "Epoch 66 | train: Loss 0.752152 Accuracy 0.71 | validation: Loss 0.753567 Accuracy 0.72\n",
      "Epoch 67 | train: Loss 0.741941 Accuracy 0.72 | validation: Loss 0.747510 Accuracy 0.70\n",
      "Epoch 68 | train: Loss 0.735749 Accuracy 0.72 | validation: Loss 0.742711 Accuracy 0.71\n",
      "Epoch 69 | train: Loss 0.733350 Accuracy 0.72 | validation: Loss 0.754609 Accuracy 0.69\n",
      "Epoch 70 | train: Loss 0.732582 Accuracy 0.72 | validation: Loss 0.725551 Accuracy 0.73\n",
      "Epoch 71 | train: Loss 0.724374 Accuracy 0.72 | validation: Loss 0.722148 Accuracy 0.76\n",
      "Epoch 72 | train: Loss 0.727232 Accuracy 0.72 | validation: Loss 0.719122 Accuracy 0.74\n",
      "Epoch 73 | train: Loss 0.721936 Accuracy 0.72 | validation: Loss 0.753216 Accuracy 0.65\n",
      "Epoch 74 | train: Loss 0.719548 Accuracy 0.72 | validation: Loss 0.700901 Accuracy 0.76\n",
      "Epoch 75 | train: Loss 0.716251 Accuracy 0.72 | validation: Loss 0.722545 Accuracy 0.75\n",
      "Epoch 76 | train: Loss 0.713376 Accuracy 0.73 | validation: Loss 0.706243 Accuracy 0.76\n",
      "Epoch 77 | train: Loss 0.709264 Accuracy 0.74 | validation: Loss 0.711191 Accuracy 0.75\n",
      "Epoch 78 | train: Loss 0.702974 Accuracy 0.73 | validation: Loss 0.712643 Accuracy 0.75\n",
      "Epoch 79 | train: Loss 0.701102 Accuracy 0.74 | validation: Loss 0.701851 Accuracy 0.74\n",
      "Epoch 80 | train: Loss 0.697767 Accuracy 0.73 | validation: Loss 0.688841 Accuracy 0.76\n",
      "Epoch 81 | train: Loss 0.691316 Accuracy 0.75 | validation: Loss 0.704740 Accuracy 0.74\n",
      "Epoch 82 | train: Loss 0.694950 Accuracy 0.74 | validation: Loss 0.689122 Accuracy 0.75\n",
      "Epoch 83 | train: Loss 0.687552 Accuracy 0.75 | validation: Loss 0.686768 Accuracy 0.76\n",
      "Epoch 84 | train: Loss 0.686291 Accuracy 0.75 | validation: Loss 0.732790 Accuracy 0.71\n",
      "Epoch 85 | train: Loss 0.686685 Accuracy 0.75 | validation: Loss 0.684288 Accuracy 0.77\n",
      "Epoch 86 | train: Loss 0.681148 Accuracy 0.75 | validation: Loss 0.682708 Accuracy 0.74\n",
      "Epoch 87 | train: Loss 0.678964 Accuracy 0.74 | validation: Loss 0.683181 Accuracy 0.73\n",
      "Epoch 88 | train: Loss 0.681279 Accuracy 0.73 | validation: Loss 0.677932 Accuracy 0.74\n",
      "Epoch 89 | train: Loss 0.672783 Accuracy 0.75 | validation: Loss 0.675664 Accuracy 0.75\n",
      "Epoch 90 | train: Loss 0.667347 Accuracy 0.76 | validation: Loss 0.687195 Accuracy 0.70\n",
      "Epoch 91 | train: Loss 0.664437 Accuracy 0.75 | validation: Loss 0.657746 Accuracy 0.78\n",
      "Epoch 92 | train: Loss 0.665532 Accuracy 0.75 | validation: Loss 0.667544 Accuracy 0.77\n",
      "Epoch 93 | train: Loss 0.660161 Accuracy 0.76 | validation: Loss 0.645864 Accuracy 0.77\n",
      "Epoch 94 | train: Loss 0.657122 Accuracy 0.76 | validation: Loss 0.646694 Accuracy 0.77\n",
      "Epoch 95 | train: Loss 0.654480 Accuracy 0.76 | validation: Loss 0.653338 Accuracy 0.79\n",
      "Epoch 96 | train: Loss 0.658514 Accuracy 0.75 | validation: Loss 0.664294 Accuracy 0.75\n",
      "Epoch 97 | train: Loss 0.653782 Accuracy 0.76 | validation: Loss 0.657365 Accuracy 0.76\n",
      "Epoch 98 | train: Loss 0.642961 Accuracy 0.77 | validation: Loss 0.654390 Accuracy 0.76\n",
      "Epoch 99 | train: Loss 0.646816 Accuracy 0.76 | validation: Loss 0.664026 Accuracy 0.75\n",
      "Epoch 100 | train: Loss 0.646487 Accuracy 0.76 | validation: Loss 0.648201 Accuracy 0.76\n",
      "Epoch 101 | train: Loss 0.646464 Accuracy 0.75 | validation: Loss 0.649728 Accuracy 0.76\n",
      "Epoch 102 | train: Loss 0.635170 Accuracy 0.77 | validation: Loss 0.637824 Accuracy 0.78\n",
      "Epoch 103 | train: Loss 0.635979 Accuracy 0.76 | validation: Loss 0.656215 Accuracy 0.72\n",
      "Epoch 104 | train: Loss 0.636629 Accuracy 0.77 | validation: Loss 0.651254 Accuracy 0.79\n",
      "Epoch 105 | train: Loss 0.630462 Accuracy 0.77 | validation: Loss 0.628421 Accuracy 0.78\n",
      "Epoch 106 | train: Loss 0.627345 Accuracy 0.76 | validation: Loss 0.629246 Accuracy 0.76\n",
      "Epoch 107 | train: Loss 0.629422 Accuracy 0.76 | validation: Loss 0.629884 Accuracy 0.80\n",
      "Epoch 108 | train: Loss 0.620346 Accuracy 0.77 | validation: Loss 0.641356 Accuracy 0.74\n",
      "Epoch 109 | train: Loss 0.635749 Accuracy 0.75 | validation: Loss 0.628272 Accuracy 0.78\n",
      "Epoch 110 | train: Loss 0.620146 Accuracy 0.78 | validation: Loss 0.612100 Accuracy 0.79\n",
      "Epoch 111 | train: Loss 0.624378 Accuracy 0.76 | validation: Loss 0.620567 Accuracy 0.78\n",
      "Epoch 112 | train: Loss 0.619766 Accuracy 0.78 | validation: Loss 0.638530 Accuracy 0.74\n",
      "Epoch 113 | train: Loss 0.613302 Accuracy 0.78 | validation: Loss 0.619498 Accuracy 0.79\n",
      "Epoch 114 | train: Loss 0.610501 Accuracy 0.78 | validation: Loss 0.611159 Accuracy 0.80\n",
      "Epoch 115 | train: Loss 0.612861 Accuracy 0.78 | validation: Loss 0.618526 Accuracy 0.77\n",
      "Epoch 116 | train: Loss 0.604897 Accuracy 0.78 | validation: Loss 0.624833 Accuracy 0.77\n",
      "Epoch 117 | train: Loss 0.605969 Accuracy 0.77 | validation: Loss 0.616669 Accuracy 0.78\n",
      "Epoch 118 | train: Loss 0.605491 Accuracy 0.78 | validation: Loss 0.594265 Accuracy 0.80\n",
      "Epoch 119 | train: Loss 0.599829 Accuracy 0.78 | validation: Loss 0.596876 Accuracy 0.79\n",
      "Epoch 120 | train: Loss 0.597653 Accuracy 0.78 | validation: Loss 0.600102 Accuracy 0.81\n",
      "Epoch 121 | train: Loss 0.601574 Accuracy 0.78 | validation: Loss 0.614659 Accuracy 0.76\n",
      "Epoch 122 | train: Loss 0.605864 Accuracy 0.77 | validation: Loss 0.598636 Accuracy 0.80\n",
      "Epoch 123 | train: Loss 0.590119 Accuracy 0.78 | validation: Loss 0.594487 Accuracy 0.80\n",
      "Epoch 124 | train: Loss 0.596045 Accuracy 0.77 | validation: Loss 0.593750 Accuracy 0.78\n",
      "Epoch 125 | train: Loss 0.598978 Accuracy 0.77 | validation: Loss 0.597842 Accuracy 0.79\n",
      "Epoch 126 | train: Loss 0.589481 Accuracy 0.79 | validation: Loss 0.593768 Accuracy 0.78\n",
      "Epoch 127 | train: Loss 0.595952 Accuracy 0.77 | validation: Loss 0.609406 Accuracy 0.77\n",
      "Epoch 128 | train: Loss 0.589791 Accuracy 0.78 | validation: Loss 0.587081 Accuracy 0.77\n",
      "Epoch 129 | train: Loss 0.582494 Accuracy 0.78 | validation: Loss 0.588813 Accuracy 0.81\n",
      "Epoch 130 | train: Loss 0.584903 Accuracy 0.78 | validation: Loss 0.598993 Accuracy 0.77\n",
      "Epoch 131 | train: Loss 0.584467 Accuracy 0.78 | validation: Loss 0.586681 Accuracy 0.79\n",
      "Epoch 132 | train: Loss 0.574981 Accuracy 0.79 | validation: Loss 0.576108 Accuracy 0.80\n",
      "Epoch 133 | train: Loss 0.577362 Accuracy 0.79 | validation: Loss 0.584653 Accuracy 0.78\n",
      "Epoch 134 | train: Loss 0.574473 Accuracy 0.79 | validation: Loss 0.574494 Accuracy 0.80\n",
      "Epoch 135 | train: Loss 0.569991 Accuracy 0.79 | validation: Loss 0.582216 Accuracy 0.78\n",
      "Epoch 136 | train: Loss 0.574292 Accuracy 0.78 | validation: Loss 0.568434 Accuracy 0.81\n",
      "Epoch 137 | train: Loss 0.568316 Accuracy 0.79 | validation: Loss 0.561066 Accuracy 0.81\n",
      "Epoch 138 | train: Loss 0.566213 Accuracy 0.79 | validation: Loss 0.569791 Accuracy 0.80\n",
      "Epoch 139 | train: Loss 0.566197 Accuracy 0.79 | validation: Loss 0.574908 Accuracy 0.80\n",
      "Epoch 140 | train: Loss 0.565214 Accuracy 0.80 | validation: Loss 0.584645 Accuracy 0.82\n",
      "Epoch 141 | train: Loss 0.570590 Accuracy 0.79 | validation: Loss 0.569212 Accuracy 0.78\n",
      "Epoch 142 | train: Loss 0.559909 Accuracy 0.79 | validation: Loss 0.575304 Accuracy 0.78\n",
      "Epoch 143 | train: Loss 0.566931 Accuracy 0.79 | validation: Loss 0.560939 Accuracy 0.78\n",
      "Epoch 144 | train: Loss 0.566210 Accuracy 0.78 | validation: Loss 0.560600 Accuracy 0.83\n",
      "Epoch 145 | train: Loss 0.553338 Accuracy 0.79 | validation: Loss 0.560845 Accuracy 0.82\n",
      "Epoch 146 | train: Loss 0.557336 Accuracy 0.79 | validation: Loss 0.542617 Accuracy 0.81\n",
      "Epoch 147 | train: Loss 0.557706 Accuracy 0.79 | validation: Loss 0.553489 Accuracy 0.80\n",
      "Epoch 148 | train: Loss 0.553510 Accuracy 0.80 | validation: Loss 0.563933 Accuracy 0.77\n",
      "Epoch 149 | train: Loss 0.560614 Accuracy 0.79 | validation: Loss 0.549716 Accuracy 0.82\n",
      "Epoch 150 | train: Loss 0.553221 Accuracy 0.80 | validation: Loss 0.549645 Accuracy 0.82\n",
      "Epoch 151 | train: Loss 0.546723 Accuracy 0.80 | validation: Loss 0.542049 Accuracy 0.80\n",
      "Epoch 152 | train: Loss 0.547338 Accuracy 0.80 | validation: Loss 0.550931 Accuracy 0.81\n",
      "Epoch 153 | train: Loss 0.545608 Accuracy 0.80 | validation: Loss 0.557314 Accuracy 0.79\n",
      "Epoch 154 | train: Loss 0.548116 Accuracy 0.80 | validation: Loss 0.540777 Accuracy 0.83\n",
      "Epoch 155 | train: Loss 0.546136 Accuracy 0.80 | validation: Loss 0.534333 Accuracy 0.81\n",
      "Epoch 156 | train: Loss 0.540134 Accuracy 0.81 | validation: Loss 0.558433 Accuracy 0.81\n",
      "Epoch 157 | train: Loss 0.538810 Accuracy 0.80 | validation: Loss 0.543211 Accuracy 0.81\n",
      "Epoch 158 | train: Loss 0.539479 Accuracy 0.80 | validation: Loss 0.532284 Accuracy 0.81\n",
      "Epoch 159 | train: Loss 0.546068 Accuracy 0.80 | validation: Loss 0.548399 Accuracy 0.78\n",
      "Epoch 160 | train: Loss 0.529508 Accuracy 0.80 | validation: Loss 0.539572 Accuracy 0.82\n",
      "Epoch 161 | train: Loss 0.535770 Accuracy 0.80 | validation: Loss 0.537576 Accuracy 0.82\n",
      "Epoch 162 | train: Loss 0.547680 Accuracy 0.78 | validation: Loss 0.522326 Accuracy 0.84\n",
      "Epoch 163 | train: Loss 0.530235 Accuracy 0.81 | validation: Loss 0.536501 Accuracy 0.81\n",
      "Epoch 164 | train: Loss 0.531006 Accuracy 0.80 | validation: Loss 0.546448 Accuracy 0.80\n",
      "Epoch 165 | train: Loss 0.533567 Accuracy 0.80 | validation: Loss 0.536857 Accuracy 0.82\n",
      "Epoch 166 | train: Loss 0.528929 Accuracy 0.80 | validation: Loss 0.533889 Accuracy 0.78\n",
      "Epoch 167 | train: Loss 0.531454 Accuracy 0.80 | validation: Loss 0.577330 Accuracy 0.78\n",
      "Epoch 168 | train: Loss 0.529309 Accuracy 0.80 | validation: Loss 0.527561 Accuracy 0.79\n",
      "Epoch 169 | train: Loss 0.523729 Accuracy 0.80 | validation: Loss 0.521427 Accuracy 0.82\n",
      "Epoch 170 | train: Loss 0.529360 Accuracy 0.79 | validation: Loss 0.555471 Accuracy 0.78\n",
      "Epoch 171 | train: Loss 0.520781 Accuracy 0.80 | validation: Loss 0.523488 Accuracy 0.82\n",
      "Epoch 172 | train: Loss 0.516027 Accuracy 0.81 | validation: Loss 0.526994 Accuracy 0.82\n",
      "Epoch 173 | train: Loss 0.518697 Accuracy 0.81 | validation: Loss 0.524148 Accuracy 0.79\n",
      "Epoch 174 | train: Loss 0.515152 Accuracy 0.81 | validation: Loss 0.537655 Accuracy 0.80\n",
      "Epoch 175 | train: Loss 0.516724 Accuracy 0.81 | validation: Loss 0.513977 Accuracy 0.84\n",
      "Epoch 176 | train: Loss 0.513186 Accuracy 0.81 | validation: Loss 0.508234 Accuracy 0.82\n",
      "Epoch 177 | train: Loss 0.507881 Accuracy 0.82 | validation: Loss 0.520914 Accuracy 0.83\n",
      "Epoch 178 | train: Loss 0.513082 Accuracy 0.81 | validation: Loss 0.514346 Accuracy 0.82\n",
      "Epoch 179 | train: Loss 0.510593 Accuracy 0.81 | validation: Loss 0.509185 Accuracy 0.81\n",
      "Epoch 180 | train: Loss 0.510358 Accuracy 0.81 | validation: Loss 0.531511 Accuracy 0.79\n",
      "Epoch 181 | train: Loss 0.513395 Accuracy 0.81 | validation: Loss 0.511702 Accuracy 0.82\n",
      "Epoch 182 | train: Loss 0.505347 Accuracy 0.81 | validation: Loss 0.507245 Accuracy 0.81\n",
      "Epoch 183 | train: Loss 0.501801 Accuracy 0.81 | validation: Loss 0.507465 Accuracy 0.82\n",
      "Epoch 184 | train: Loss 0.514079 Accuracy 0.81 | validation: Loss 0.532715 Accuracy 0.83\n",
      "Epoch 185 | train: Loss 0.505860 Accuracy 0.81 | validation: Loss 0.525184 Accuracy 0.78\n",
      "Epoch 186 | train: Loss 0.497676 Accuracy 0.82 | validation: Loss 0.499593 Accuracy 0.81\n",
      "Epoch 187 | train: Loss 0.502486 Accuracy 0.81 | validation: Loss 0.503648 Accuracy 0.82\n",
      "Epoch 188 | train: Loss 0.496238 Accuracy 0.82 | validation: Loss 0.496644 Accuracy 0.81\n",
      "Epoch 189 | train: Loss 0.493861 Accuracy 0.82 | validation: Loss 0.512343 Accuracy 0.80\n",
      "Epoch 190 | train: Loss 0.500257 Accuracy 0.81 | validation: Loss 0.513316 Accuracy 0.81\n",
      "Epoch 191 | train: Loss 0.507905 Accuracy 0.81 | validation: Loss 0.499336 Accuracy 0.82\n",
      "Epoch 192 | train: Loss 0.493338 Accuracy 0.81 | validation: Loss 0.496239 Accuracy 0.82\n",
      "Epoch 193 | train: Loss 0.494130 Accuracy 0.82 | validation: Loss 0.485308 Accuracy 0.83\n",
      "Epoch 194 | train: Loss 0.493995 Accuracy 0.82 | validation: Loss 0.491163 Accuracy 0.82\n",
      "Epoch 195 | train: Loss 0.490995 Accuracy 0.82 | validation: Loss 0.517994 Accuracy 0.82\n",
      "Epoch 196 | train: Loss 0.489574 Accuracy 0.82 | validation: Loss 0.493461 Accuracy 0.83\n",
      "Epoch 197 | train: Loss 0.485136 Accuracy 0.83 | validation: Loss 0.485817 Accuracy 0.83\n",
      "Epoch 198 | train: Loss 0.486841 Accuracy 0.82 | validation: Loss 0.504700 Accuracy 0.81\n",
      "Epoch 199 | train: Loss 0.484320 Accuracy 0.82 | validation: Loss 0.488035 Accuracy 0.83\n",
      "Epoch 200 | train: Loss 0.484633 Accuracy 0.82 | validation: Loss 0.500698 Accuracy 0.81\n",
      "Epoch 201 | train: Loss 0.482665 Accuracy 0.82 | validation: Loss 0.491975 Accuracy 0.82\n",
      "Epoch 202 | train: Loss 0.481769 Accuracy 0.82 | validation: Loss 0.497959 Accuracy 0.82\n",
      "Epoch 203 | train: Loss 0.481643 Accuracy 0.82 | validation: Loss 0.481069 Accuracy 0.84\n",
      "Epoch 204 | train: Loss 0.479913 Accuracy 0.82 | validation: Loss 0.476447 Accuracy 0.82\n",
      "Epoch 205 | train: Loss 0.477136 Accuracy 0.82 | validation: Loss 0.493809 Accuracy 0.81\n",
      "Epoch 206 | train: Loss 0.487068 Accuracy 0.82 | validation: Loss 0.483933 Accuracy 0.82\n",
      "Epoch 207 | train: Loss 0.479150 Accuracy 0.82 | validation: Loss 0.507463 Accuracy 0.82\n",
      "Epoch 208 | train: Loss 0.475051 Accuracy 0.83 | validation: Loss 0.488260 Accuracy 0.82\n",
      "Epoch 209 | train: Loss 0.476779 Accuracy 0.82 | validation: Loss 0.481935 Accuracy 0.83\n",
      "Epoch 210 | train: Loss 0.471338 Accuracy 0.83 | validation: Loss 0.497093 Accuracy 0.80\n",
      "Epoch 211 | train: Loss 0.482666 Accuracy 0.82 | validation: Loss 0.478631 Accuracy 0.82\n",
      "Epoch 212 | train: Loss 0.471045 Accuracy 0.83 | validation: Loss 0.489042 Accuracy 0.81\n",
      "Epoch 213 | train: Loss 0.473675 Accuracy 0.83 | validation: Loss 0.495508 Accuracy 0.83\n",
      "Epoch 214 | train: Loss 0.468488 Accuracy 0.82 | validation: Loss 0.465372 Accuracy 0.84\n",
      "Epoch 215 | train: Loss 0.475025 Accuracy 0.82 | validation: Loss 0.478132 Accuracy 0.82\n",
      "Epoch 216 | train: Loss 0.472137 Accuracy 0.83 | validation: Loss 0.481392 Accuracy 0.82\n",
      "Epoch 217 | train: Loss 0.467033 Accuracy 0.82 | validation: Loss 0.475186 Accuracy 0.83\n",
      "Epoch 218 | train: Loss 0.459596 Accuracy 0.83 | validation: Loss 0.457357 Accuracy 0.85\n",
      "Epoch 219 | train: Loss 0.462971 Accuracy 0.83 | validation: Loss 0.467424 Accuracy 0.84\n",
      "Epoch 220 | train: Loss 0.460296 Accuracy 0.83 | validation: Loss 0.477873 Accuracy 0.85\n",
      "Epoch 221 | train: Loss 0.463470 Accuracy 0.82 | validation: Loss 0.455908 Accuracy 0.84\n",
      "Epoch 222 | train: Loss 0.459026 Accuracy 0.83 | validation: Loss 0.475051 Accuracy 0.84\n",
      "Epoch 223 | train: Loss 0.461819 Accuracy 0.82 | validation: Loss 0.472450 Accuracy 0.82\n",
      "Epoch 224 | train: Loss 0.458219 Accuracy 0.83 | validation: Loss 0.477870 Accuracy 0.81\n",
      "Epoch 225 | train: Loss 0.455569 Accuracy 0.83 | validation: Loss 0.459916 Accuracy 0.82\n",
      "Epoch 226 | train: Loss 0.454668 Accuracy 0.83 | validation: Loss 0.468357 Accuracy 0.83\n",
      "Epoch 227 | train: Loss 0.450451 Accuracy 0.83 | validation: Loss 0.453486 Accuracy 0.83\n",
      "Epoch 228 | train: Loss 0.455448 Accuracy 0.84 | validation: Loss 0.457068 Accuracy 0.84\n",
      "Epoch 229 | train: Loss 0.449002 Accuracy 0.83 | validation: Loss 0.458369 Accuracy 0.86\n",
      "Epoch 230 | train: Loss 0.447093 Accuracy 0.84 | validation: Loss 0.460631 Accuracy 0.82\n",
      "Epoch 231 | train: Loss 0.450496 Accuracy 0.83 | validation: Loss 0.470006 Accuracy 0.83\n",
      "Epoch 232 | train: Loss 0.447876 Accuracy 0.83 | validation: Loss 0.459381 Accuracy 0.82\n",
      "Epoch 233 | train: Loss 0.448592 Accuracy 0.83 | validation: Loss 0.465113 Accuracy 0.82\n",
      "Epoch 234 | train: Loss 0.449650 Accuracy 0.83 | validation: Loss 0.456711 Accuracy 0.83\n",
      "Epoch 235 | train: Loss 0.447995 Accuracy 0.83 | validation: Loss 0.461432 Accuracy 0.84\n",
      "Epoch 236 | train: Loss 0.442230 Accuracy 0.84 | validation: Loss 0.473912 Accuracy 0.82\n",
      "Epoch 237 | train: Loss 0.446989 Accuracy 0.83 | validation: Loss 0.471231 Accuracy 0.87\n",
      "Epoch 238 | train: Loss 0.446072 Accuracy 0.83 | validation: Loss 0.448221 Accuracy 0.84\n",
      "Epoch 239 | train: Loss 0.438979 Accuracy 0.84 | validation: Loss 0.461107 Accuracy 0.81\n",
      "Epoch 240 | train: Loss 0.439702 Accuracy 0.83 | validation: Loss 0.456908 Accuracy 0.86\n",
      "Epoch 241 | train: Loss 0.441613 Accuracy 0.83 | validation: Loss 0.469887 Accuracy 0.83\n",
      "Epoch 242 | train: Loss 0.442256 Accuracy 0.84 | validation: Loss 0.446394 Accuracy 0.85\n",
      "Epoch 243 | train: Loss 0.436401 Accuracy 0.84 | validation: Loss 0.454656 Accuracy 0.84\n",
      "Epoch 244 | train: Loss 0.442894 Accuracy 0.84 | validation: Loss 0.456801 Accuracy 0.82\n",
      "Epoch 245 | train: Loss 0.434683 Accuracy 0.84 | validation: Loss 0.443398 Accuracy 0.84\n",
      "Epoch 246 | train: Loss 0.442639 Accuracy 0.83 | validation: Loss 0.457485 Accuracy 0.82\n",
      "Epoch 247 | train: Loss 0.439129 Accuracy 0.83 | validation: Loss 0.470922 Accuracy 0.86\n",
      "Epoch 248 | train: Loss 0.434747 Accuracy 0.84 | validation: Loss 0.441882 Accuracy 0.84\n",
      "Epoch 249 | train: Loss 0.429824 Accuracy 0.85 | validation: Loss 0.435025 Accuracy 0.86\n",
      "Epoch 250 | train: Loss 0.427895 Accuracy 0.84 | validation: Loss 0.435420 Accuracy 0.83\n",
      "Epoch 251 | train: Loss 0.429735 Accuracy 0.84 | validation: Loss 0.454213 Accuracy 0.83\n",
      "Epoch 252 | train: Loss 0.430750 Accuracy 0.84 | validation: Loss 0.436626 Accuracy 0.83\n",
      "Epoch 253 | train: Loss 0.436970 Accuracy 0.84 | validation: Loss 0.453225 Accuracy 0.82\n",
      "Epoch 254 | train: Loss 0.427826 Accuracy 0.84 | validation: Loss 0.441459 Accuracy 0.85\n",
      "Epoch 255 | train: Loss 0.427550 Accuracy 0.84 | validation: Loss 0.421903 Accuracy 0.85\n",
      "Epoch 256 | train: Loss 0.429519 Accuracy 0.84 | validation: Loss 0.433019 Accuracy 0.85\n",
      "Epoch 257 | train: Loss 0.427692 Accuracy 0.84 | validation: Loss 0.456020 Accuracy 0.86\n",
      "Epoch 258 | train: Loss 0.424741 Accuracy 0.84 | validation: Loss 0.423590 Accuracy 0.85\n",
      "Epoch 259 | train: Loss 0.432344 Accuracy 0.83 | validation: Loss 0.425798 Accuracy 0.85\n",
      "Epoch 260 | train: Loss 0.416039 Accuracy 0.85 | validation: Loss 0.423349 Accuracy 0.83\n",
      "Epoch 261 | train: Loss 0.419291 Accuracy 0.85 | validation: Loss 0.435529 Accuracy 0.82\n",
      "Epoch 262 | train: Loss 0.421626 Accuracy 0.85 | validation: Loss 0.434507 Accuracy 0.83\n",
      "Epoch 263 | train: Loss 0.420314 Accuracy 0.85 | validation: Loss 0.444446 Accuracy 0.81\n",
      "Epoch 264 | train: Loss 0.416011 Accuracy 0.85 | validation: Loss 0.433524 Accuracy 0.83\n",
      "Epoch 265 | train: Loss 0.416526 Accuracy 0.85 | validation: Loss 0.426985 Accuracy 0.84\n",
      "Epoch 266 | train: Loss 0.420744 Accuracy 0.85 | validation: Loss 0.434394 Accuracy 0.88\n",
      "Epoch 267 | train: Loss 0.410445 Accuracy 0.85 | validation: Loss 0.429094 Accuracy 0.84\n",
      "Epoch 268 | train: Loss 0.415858 Accuracy 0.84 | validation: Loss 0.426070 Accuracy 0.84\n",
      "Epoch 269 | train: Loss 0.415293 Accuracy 0.84 | validation: Loss 0.410667 Accuracy 0.85\n",
      "Epoch 270 | train: Loss 0.409160 Accuracy 0.85 | validation: Loss 0.417274 Accuracy 0.85\n",
      "Epoch 271 | train: Loss 0.408942 Accuracy 0.85 | validation: Loss 0.427676 Accuracy 0.84\n",
      "Epoch 272 | train: Loss 0.414947 Accuracy 0.84 | validation: Loss 0.425766 Accuracy 0.82\n",
      "Epoch 273 | train: Loss 0.411931 Accuracy 0.84 | validation: Loss 0.443831 Accuracy 0.88\n",
      "Epoch 274 | train: Loss 0.412458 Accuracy 0.85 | validation: Loss 0.429625 Accuracy 0.84\n",
      "Epoch 275 | train: Loss 0.406896 Accuracy 0.85 | validation: Loss 0.404431 Accuracy 0.85\n",
      "Epoch 276 | train: Loss 0.407827 Accuracy 0.85 | validation: Loss 0.423471 Accuracy 0.86\n",
      "Epoch 277 | train: Loss 0.404761 Accuracy 0.86 | validation: Loss 0.407138 Accuracy 0.86\n",
      "Epoch 278 | train: Loss 0.401307 Accuracy 0.86 | validation: Loss 0.415773 Accuracy 0.85\n",
      "Epoch 279 | train: Loss 0.407095 Accuracy 0.85 | validation: Loss 0.419084 Accuracy 0.87\n",
      "Epoch 280 | train: Loss 0.402213 Accuracy 0.85 | validation: Loss 0.407342 Accuracy 0.84\n",
      "Epoch 281 | train: Loss 0.402560 Accuracy 0.85 | validation: Loss 0.416428 Accuracy 0.84\n",
      "Epoch 282 | train: Loss 0.407969 Accuracy 0.85 | validation: Loss 0.427185 Accuracy 0.88\n",
      "Epoch 283 | train: Loss 0.405319 Accuracy 0.85 | validation: Loss 0.420288 Accuracy 0.83\n",
      "Epoch 284 | train: Loss 0.402932 Accuracy 0.86 | validation: Loss 0.423297 Accuracy 0.83\n",
      "Epoch 285 | train: Loss 0.408100 Accuracy 0.84 | validation: Loss 0.411729 Accuracy 0.82\n",
      "Epoch 286 | train: Loss 0.399192 Accuracy 0.86 | validation: Loss 0.426927 Accuracy 0.86\n",
      "Epoch 287 | train: Loss 0.395388 Accuracy 0.85 | validation: Loss 0.403877 Accuracy 0.86\n",
      "Epoch 288 | train: Loss 0.397675 Accuracy 0.85 | validation: Loss 0.418959 Accuracy 0.85\n",
      "Epoch 289 | train: Loss 0.399035 Accuracy 0.85 | validation: Loss 0.417372 Accuracy 0.85\n",
      "Epoch 290 | train: Loss 0.393190 Accuracy 0.85 | validation: Loss 0.402837 Accuracy 0.85\n",
      "Epoch 291 | train: Loss 0.397482 Accuracy 0.85 | validation: Loss 0.397579 Accuracy 0.85\n",
      "Epoch 292 | train: Loss 0.398037 Accuracy 0.86 | validation: Loss 0.389716 Accuracy 0.85\n",
      "Epoch 293 | train: Loss 0.396653 Accuracy 0.85 | validation: Loss 0.395936 Accuracy 0.89\n",
      "Epoch 294 | train: Loss 0.390752 Accuracy 0.86 | validation: Loss 0.409296 Accuracy 0.83\n",
      "Epoch 295 | train: Loss 0.393327 Accuracy 0.86 | validation: Loss 0.400784 Accuracy 0.85\n",
      "Epoch 296 | train: Loss 0.393216 Accuracy 0.85 | validation: Loss 0.387454 Accuracy 0.86\n",
      "Epoch 297 | train: Loss 0.395323 Accuracy 0.85 | validation: Loss 0.400982 Accuracy 0.86\n",
      "Epoch 298 | train: Loss 0.390534 Accuracy 0.86 | validation: Loss 0.401133 Accuracy 0.85\n",
      "Epoch 299 | train: Loss 0.389887 Accuracy 0.85 | validation: Loss 0.395867 Accuracy 0.85\n",
      "Epoch 300 | train: Loss 0.382583 Accuracy 0.86 | validation: Loss 0.412248 Accuracy 0.85\n",
      "Epoch 301 | train: Loss 0.394702 Accuracy 0.85 | validation: Loss 0.426713 Accuracy 0.84\n",
      "Epoch 302 | train: Loss 0.390076 Accuracy 0.86 | validation: Loss 0.395019 Accuracy 0.85\n",
      "Epoch 303 | train: Loss 0.384939 Accuracy 0.86 | validation: Loss 0.423664 Accuracy 0.87\n",
      "Epoch 304 | train: Loss 0.381896 Accuracy 0.86 | validation: Loss 0.404326 Accuracy 0.86\n",
      "Epoch 305 | train: Loss 0.385961 Accuracy 0.87 | validation: Loss 0.394187 Accuracy 0.83\n",
      "Epoch 306 | train: Loss 0.384219 Accuracy 0.86 | validation: Loss 0.394993 Accuracy 0.85\n",
      "Epoch 307 | train: Loss 0.381943 Accuracy 0.86 | validation: Loss 0.393982 Accuracy 0.87\n",
      "Epoch 308 | train: Loss 0.386233 Accuracy 0.85 | validation: Loss 0.390528 Accuracy 0.88\n",
      "Epoch 309 | train: Loss 0.388363 Accuracy 0.86 | validation: Loss 0.413931 Accuracy 0.86\n",
      "Epoch 310 | train: Loss 0.380593 Accuracy 0.86 | validation: Loss 0.380099 Accuracy 0.87\n",
      "Epoch 311 | train: Loss 0.387188 Accuracy 0.86 | validation: Loss 0.432098 Accuracy 0.82\n",
      "Epoch 312 | train: Loss 0.389226 Accuracy 0.85 | validation: Loss 0.386532 Accuracy 0.86\n",
      "Epoch 313 | train: Loss 0.379508 Accuracy 0.86 | validation: Loss 0.422166 Accuracy 0.82\n",
      "Epoch 314 | train: Loss 0.378598 Accuracy 0.87 | validation: Loss 0.391648 Accuracy 0.89\n",
      "Epoch 315 | train: Loss 0.372008 Accuracy 0.87 | validation: Loss 0.404270 Accuracy 0.83\n",
      "Epoch 316 | train: Loss 0.376475 Accuracy 0.87 | validation: Loss 0.398416 Accuracy 0.86\n",
      "Epoch 317 | train: Loss 0.381071 Accuracy 0.86 | validation: Loss 0.411545 Accuracy 0.86\n",
      "Epoch 318 | train: Loss 0.380454 Accuracy 0.86 | validation: Loss 0.385813 Accuracy 0.86\n",
      "Epoch 319 | train: Loss 0.371850 Accuracy 0.87 | validation: Loss 0.391995 Accuracy 0.87\n",
      "Epoch 320 | train: Loss 0.376229 Accuracy 0.87 | validation: Loss 0.390098 Accuracy 0.86\n",
      "Epoch 321 | train: Loss 0.373309 Accuracy 0.87 | validation: Loss 0.369520 Accuracy 0.87\n",
      "Epoch 322 | train: Loss 0.373030 Accuracy 0.87 | validation: Loss 0.383560 Accuracy 0.88\n",
      "Epoch 323 | train: Loss 0.371136 Accuracy 0.87 | validation: Loss 0.391653 Accuracy 0.84\n",
      "Epoch 324 | train: Loss 0.370657 Accuracy 0.87 | validation: Loss 0.393648 Accuracy 0.87\n",
      "Epoch 325 | train: Loss 0.380465 Accuracy 0.86 | validation: Loss 0.379057 Accuracy 0.87\n",
      "Epoch 326 | train: Loss 0.367521 Accuracy 0.87 | validation: Loss 0.374936 Accuracy 0.88\n",
      "Epoch 327 | train: Loss 0.363043 Accuracy 0.88 | validation: Loss 0.389578 Accuracy 0.87\n",
      "Epoch 328 | train: Loss 0.364005 Accuracy 0.87 | validation: Loss 0.360187 Accuracy 0.87\n",
      "Epoch 329 | train: Loss 0.366397 Accuracy 0.87 | validation: Loss 0.390497 Accuracy 0.89\n",
      "Epoch 330 | train: Loss 0.366622 Accuracy 0.87 | validation: Loss 0.377852 Accuracy 0.88\n",
      "Epoch 331 | train: Loss 0.362638 Accuracy 0.87 | validation: Loss 0.380254 Accuracy 0.89\n",
      "Epoch 332 | train: Loss 0.363765 Accuracy 0.87 | validation: Loss 0.381837 Accuracy 0.85\n",
      "Epoch 333 | train: Loss 0.363681 Accuracy 0.87 | validation: Loss 0.372095 Accuracy 0.87\n",
      "Epoch 334 | train: Loss 0.369364 Accuracy 0.86 | validation: Loss 0.377585 Accuracy 0.88\n",
      "Epoch 335 | train: Loss 0.366228 Accuracy 0.87 | validation: Loss 0.405283 Accuracy 0.83\n",
      "Epoch 336 | train: Loss 0.362982 Accuracy 0.87 | validation: Loss 0.381436 Accuracy 0.87\n",
      "Epoch 337 | train: Loss 0.360981 Accuracy 0.87 | validation: Loss 0.390022 Accuracy 0.89\n",
      "Epoch 338 | train: Loss 0.359323 Accuracy 0.88 | validation: Loss 0.368752 Accuracy 0.87\n",
      "Epoch 339 | train: Loss 0.356510 Accuracy 0.88 | validation: Loss 0.379735 Accuracy 0.83\n",
      "Epoch 340 | train: Loss 0.359385 Accuracy 0.87 | validation: Loss 0.372847 Accuracy 0.89\n",
      "Epoch 341 | train: Loss 0.359923 Accuracy 0.88 | validation: Loss 0.371016 Accuracy 0.86\n",
      "Epoch 342 | train: Loss 0.362745 Accuracy 0.87 | validation: Loss 0.381110 Accuracy 0.85\n",
      "Epoch 343 | train: Loss 0.354292 Accuracy 0.88 | validation: Loss 0.376980 Accuracy 0.87\n",
      "Epoch 344 | train: Loss 0.359003 Accuracy 0.87 | validation: Loss 0.368805 Accuracy 0.88\n",
      "Epoch 345 | train: Loss 0.355823 Accuracy 0.88 | validation: Loss 0.362151 Accuracy 0.88\n",
      "Epoch 346 | train: Loss 0.351414 Accuracy 0.88 | validation: Loss 0.360087 Accuracy 0.88\n",
      "Epoch 347 | train: Loss 0.353339 Accuracy 0.88 | validation: Loss 0.360578 Accuracy 0.89\n",
      "Epoch 348 | train: Loss 0.353296 Accuracy 0.88 | validation: Loss 0.382916 Accuracy 0.88\n",
      "Epoch 349 | train: Loss 0.356811 Accuracy 0.88 | validation: Loss 0.365386 Accuracy 0.89\n",
      "Epoch 350 | train: Loss 0.353218 Accuracy 0.88 | validation: Loss 0.356854 Accuracy 0.87\n",
      "Epoch 351 | train: Loss 0.349487 Accuracy 0.88 | validation: Loss 0.369411 Accuracy 0.87\n",
      "Epoch 352 | train: Loss 0.348185 Accuracy 0.88 | validation: Loss 0.363216 Accuracy 0.86\n",
      "Epoch 353 | train: Loss 0.349991 Accuracy 0.88 | validation: Loss 0.374305 Accuracy 0.88\n",
      "Epoch 354 | train: Loss 0.360325 Accuracy 0.87 | validation: Loss 0.370115 Accuracy 0.85\n",
      "Epoch 355 | train: Loss 0.355086 Accuracy 0.87 | validation: Loss 0.362095 Accuracy 0.88\n",
      "Epoch 356 | train: Loss 0.344491 Accuracy 0.89 | validation: Loss 0.362925 Accuracy 0.86\n",
      "Epoch 357 | train: Loss 0.361240 Accuracy 0.86 | validation: Loss 0.383236 Accuracy 0.86\n",
      "Epoch 358 | train: Loss 0.349581 Accuracy 0.88 | validation: Loss 0.355216 Accuracy 0.86\n",
      "Epoch 359 | train: Loss 0.348765 Accuracy 0.88 | validation: Loss 0.352507 Accuracy 0.89\n",
      "Epoch 360 | train: Loss 0.347513 Accuracy 0.88 | validation: Loss 0.362023 Accuracy 0.89\n",
      "Epoch 361 | train: Loss 0.342819 Accuracy 0.89 | validation: Loss 0.364287 Accuracy 0.86\n",
      "Epoch 362 | train: Loss 0.350808 Accuracy 0.87 | validation: Loss 0.359104 Accuracy 0.86\n",
      "Epoch 363 | train: Loss 0.341101 Accuracy 0.88 | validation: Loss 0.368592 Accuracy 0.85\n",
      "Epoch 364 | train: Loss 0.340927 Accuracy 0.89 | validation: Loss 0.353081 Accuracy 0.88\n",
      "Epoch 365 | train: Loss 0.341823 Accuracy 0.88 | validation: Loss 0.334309 Accuracy 0.89\n",
      "Epoch 366 | train: Loss 0.339523 Accuracy 0.89 | validation: Loss 0.358035 Accuracy 0.88\n",
      "Epoch 367 | train: Loss 0.343888 Accuracy 0.88 | validation: Loss 0.372297 Accuracy 0.85\n",
      "Epoch 368 | train: Loss 0.338806 Accuracy 0.89 | validation: Loss 0.353362 Accuracy 0.88\n",
      "Epoch 369 | train: Loss 0.344362 Accuracy 0.88 | validation: Loss 0.350729 Accuracy 0.88\n",
      "Epoch 370 | train: Loss 0.337832 Accuracy 0.88 | validation: Loss 0.341705 Accuracy 0.89\n",
      "Epoch 371 | train: Loss 0.339669 Accuracy 0.88 | validation: Loss 0.346622 Accuracy 0.86\n",
      "Epoch 372 | train: Loss 0.346457 Accuracy 0.87 | validation: Loss 0.359593 Accuracy 0.86\n",
      "Epoch 373 | train: Loss 0.341744 Accuracy 0.88 | validation: Loss 0.358116 Accuracy 0.89\n",
      "Epoch 374 | train: Loss 0.335907 Accuracy 0.89 | validation: Loss 0.367474 Accuracy 0.88\n",
      "Epoch 375 | train: Loss 0.342765 Accuracy 0.88 | validation: Loss 0.345153 Accuracy 0.87\n",
      "Epoch 376 | train: Loss 0.340100 Accuracy 0.88 | validation: Loss 0.365792 Accuracy 0.86\n",
      "Epoch 377 | train: Loss 0.336362 Accuracy 0.88 | validation: Loss 0.344845 Accuracy 0.88\n",
      "Epoch 378 | train: Loss 0.340003 Accuracy 0.88 | validation: Loss 0.353541 Accuracy 0.86\n",
      "Epoch 379 | train: Loss 0.337375 Accuracy 0.88 | validation: Loss 0.351032 Accuracy 0.88\n",
      "Epoch 380 | train: Loss 0.329608 Accuracy 0.89 | validation: Loss 0.348727 Accuracy 0.88\n",
      "Epoch 381 | train: Loss 0.332740 Accuracy 0.88 | validation: Loss 0.352436 Accuracy 0.86\n",
      "Epoch 382 | train: Loss 0.332379 Accuracy 0.89 | validation: Loss 0.367340 Accuracy 0.88\n",
      "Epoch 383 | train: Loss 0.337355 Accuracy 0.88 | validation: Loss 0.356447 Accuracy 0.86\n",
      "Epoch 384 | train: Loss 0.329821 Accuracy 0.89 | validation: Loss 0.338244 Accuracy 0.87\n",
      "Epoch 385 | train: Loss 0.328935 Accuracy 0.89 | validation: Loss 0.351309 Accuracy 0.88\n",
      "Epoch 386 | train: Loss 0.331284 Accuracy 0.89 | validation: Loss 0.337432 Accuracy 0.89\n",
      "Epoch 387 | train: Loss 0.324538 Accuracy 0.90 | validation: Loss 0.334163 Accuracy 0.89\n",
      "Epoch 388 | train: Loss 0.327117 Accuracy 0.89 | validation: Loss 0.361366 Accuracy 0.87\n",
      "Epoch 389 | train: Loss 0.331484 Accuracy 0.89 | validation: Loss 0.350924 Accuracy 0.86\n",
      "Epoch 390 | train: Loss 0.326325 Accuracy 0.89 | validation: Loss 0.336955 Accuracy 0.88\n",
      "Epoch 391 | train: Loss 0.331434 Accuracy 0.89 | validation: Loss 0.372662 Accuracy 0.85\n",
      "Epoch 392 | train: Loss 0.331321 Accuracy 0.88 | validation: Loss 0.341223 Accuracy 0.88\n",
      "Epoch 393 | train: Loss 0.325720 Accuracy 0.89 | validation: Loss 0.361055 Accuracy 0.86\n",
      "Epoch 394 | train: Loss 0.333115 Accuracy 0.88 | validation: Loss 0.339474 Accuracy 0.89\n",
      "Epoch 395 | train: Loss 0.323668 Accuracy 0.89 | validation: Loss 0.326315 Accuracy 0.89\n",
      "Epoch 396 | train: Loss 0.322043 Accuracy 0.89 | validation: Loss 0.337658 Accuracy 0.88\n",
      "Epoch 397 | train: Loss 0.323389 Accuracy 0.89 | validation: Loss 0.349499 Accuracy 0.87\n",
      "Epoch 398 | train: Loss 0.320697 Accuracy 0.89 | validation: Loss 0.337713 Accuracy 0.90\n",
      "Epoch 399 | train: Loss 0.318953 Accuracy 0.90 | validation: Loss 0.338048 Accuracy 0.90\n",
      "Epoch 400 | train: Loss 0.320639 Accuracy 0.89 | validation: Loss 0.330259 Accuracy 0.91\n",
      "Epoch 401 | train: Loss 0.320962 Accuracy 0.89 | validation: Loss 0.363299 Accuracy 0.88\n",
      "Epoch 402 | train: Loss 0.321257 Accuracy 0.89 | validation: Loss 0.318480 Accuracy 0.90\n",
      "Epoch 403 | train: Loss 0.317501 Accuracy 0.90 | validation: Loss 0.333804 Accuracy 0.89\n",
      "Epoch 404 | train: Loss 0.318668 Accuracy 0.89 | validation: Loss 0.335197 Accuracy 0.89\n",
      "Epoch 405 | train: Loss 0.318515 Accuracy 0.89 | validation: Loss 0.328694 Accuracy 0.89\n",
      "Epoch 406 | train: Loss 0.325219 Accuracy 0.88 | validation: Loss 0.329573 Accuracy 0.86\n",
      "Epoch 407 | train: Loss 0.326599 Accuracy 0.88 | validation: Loss 0.338451 Accuracy 0.89\n",
      "Epoch 408 | train: Loss 0.315853 Accuracy 0.90 | validation: Loss 0.329145 Accuracy 0.88\n",
      "Epoch 409 | train: Loss 0.317247 Accuracy 0.89 | validation: Loss 0.340590 Accuracy 0.86\n",
      "Epoch 410 | train: Loss 0.315025 Accuracy 0.89 | validation: Loss 0.316317 Accuracy 0.91\n",
      "Epoch 411 | train: Loss 0.316893 Accuracy 0.89 | validation: Loss 0.339316 Accuracy 0.88\n",
      "Epoch 412 | train: Loss 0.317002 Accuracy 0.89 | validation: Loss 0.332895 Accuracy 0.90\n",
      "Epoch 413 | train: Loss 0.312344 Accuracy 0.90 | validation: Loss 0.326286 Accuracy 0.89\n",
      "Epoch 414 | train: Loss 0.320296 Accuracy 0.89 | validation: Loss 0.327544 Accuracy 0.88\n",
      "Epoch 415 | train: Loss 0.312306 Accuracy 0.90 | validation: Loss 0.325874 Accuracy 0.88\n",
      "Epoch 416 | train: Loss 0.312480 Accuracy 0.90 | validation: Loss 0.323316 Accuracy 0.90\n",
      "Epoch 417 | train: Loss 0.314197 Accuracy 0.89 | validation: Loss 0.318424 Accuracy 0.90\n",
      "Epoch 418 | train: Loss 0.309456 Accuracy 0.90 | validation: Loss 0.322396 Accuracy 0.89\n",
      "Epoch 419 | train: Loss 0.312280 Accuracy 0.89 | validation: Loss 0.316345 Accuracy 0.91\n",
      "Epoch 420 | train: Loss 0.308935 Accuracy 0.90 | validation: Loss 0.324743 Accuracy 0.88\n",
      "Epoch 421 | train: Loss 0.309175 Accuracy 0.89 | validation: Loss 0.325778 Accuracy 0.90\n",
      "Epoch 422 | train: Loss 0.307057 Accuracy 0.90 | validation: Loss 0.318695 Accuracy 0.90\n",
      "Epoch 423 | train: Loss 0.308295 Accuracy 0.89 | validation: Loss 0.319816 Accuracy 0.90\n",
      "Epoch 424 | train: Loss 0.307178 Accuracy 0.90 | validation: Loss 0.315683 Accuracy 0.90\n",
      "Epoch 425 | train: Loss 0.307001 Accuracy 0.90 | validation: Loss 0.323023 Accuracy 0.89\n",
      "Epoch 426 | train: Loss 0.307044 Accuracy 0.90 | validation: Loss 0.313703 Accuracy 0.90\n",
      "Epoch 427 | train: Loss 0.304122 Accuracy 0.90 | validation: Loss 0.320702 Accuracy 0.87\n",
      "Epoch 428 | train: Loss 0.304181 Accuracy 0.89 | validation: Loss 0.327488 Accuracy 0.90\n",
      "Epoch 429 | train: Loss 0.305882 Accuracy 0.90 | validation: Loss 0.323480 Accuracy 0.89\n",
      "Epoch 430 | train: Loss 0.317121 Accuracy 0.88 | validation: Loss 0.329654 Accuracy 0.89\n",
      "Epoch 431 | train: Loss 0.306019 Accuracy 0.90 | validation: Loss 0.307158 Accuracy 0.89\n",
      "Epoch 432 | train: Loss 0.306320 Accuracy 0.90 | validation: Loss 0.318063 Accuracy 0.91\n",
      "Epoch 433 | train: Loss 0.300305 Accuracy 0.90 | validation: Loss 0.317378 Accuracy 0.90\n",
      "Epoch 434 | train: Loss 0.313195 Accuracy 0.89 | validation: Loss 0.313308 Accuracy 0.88\n",
      "Epoch 435 | train: Loss 0.303777 Accuracy 0.90 | validation: Loss 0.309907 Accuracy 0.88\n",
      "Epoch 436 | train: Loss 0.299833 Accuracy 0.90 | validation: Loss 0.317018 Accuracy 0.89\n",
      "Epoch 437 | train: Loss 0.301600 Accuracy 0.90 | validation: Loss 0.308644 Accuracy 0.89\n",
      "Epoch 438 | train: Loss 0.304716 Accuracy 0.89 | validation: Loss 0.331446 Accuracy 0.87\n",
      "Epoch 439 | train: Loss 0.304208 Accuracy 0.90 | validation: Loss 0.336195 Accuracy 0.88\n",
      "Epoch 440 | train: Loss 0.300829 Accuracy 0.90 | validation: Loss 0.315870 Accuracy 0.87\n",
      "Epoch 441 | train: Loss 0.306152 Accuracy 0.89 | validation: Loss 0.301378 Accuracy 0.90\n",
      "Epoch 442 | train: Loss 0.296648 Accuracy 0.91 | validation: Loss 0.313164 Accuracy 0.89\n",
      "Epoch 443 | train: Loss 0.296865 Accuracy 0.90 | validation: Loss 0.326421 Accuracy 0.91\n",
      "Epoch 444 | train: Loss 0.305931 Accuracy 0.89 | validation: Loss 0.307842 Accuracy 0.89\n",
      "Epoch 445 | train: Loss 0.299859 Accuracy 0.90 | validation: Loss 0.308675 Accuracy 0.89\n",
      "Epoch 446 | train: Loss 0.298590 Accuracy 0.89 | validation: Loss 0.322601 Accuracy 0.86\n",
      "Epoch 447 | train: Loss 0.296099 Accuracy 0.90 | validation: Loss 0.325266 Accuracy 0.87\n",
      "Epoch 448 | train: Loss 0.300591 Accuracy 0.89 | validation: Loss 0.292652 Accuracy 0.89\n",
      "Epoch 449 | train: Loss 0.295626 Accuracy 0.90 | validation: Loss 0.306191 Accuracy 0.89\n",
      "Epoch 450 | train: Loss 0.305961 Accuracy 0.89 | validation: Loss 0.303071 Accuracy 0.90\n",
      "Epoch 451 | train: Loss 0.293796 Accuracy 0.90 | validation: Loss 0.316047 Accuracy 0.89\n",
      "Epoch 452 | train: Loss 0.298980 Accuracy 0.90 | validation: Loss 0.311758 Accuracy 0.90\n",
      "Epoch 453 | train: Loss 0.293256 Accuracy 0.90 | validation: Loss 0.302811 Accuracy 0.88\n",
      "Epoch 454 | train: Loss 0.296951 Accuracy 0.90 | validation: Loss 0.315373 Accuracy 0.88\n",
      "Epoch 455 | train: Loss 0.297860 Accuracy 0.89 | validation: Loss 0.309602 Accuracy 0.89\n",
      "Epoch 456 | train: Loss 0.294657 Accuracy 0.90 | validation: Loss 0.302858 Accuracy 0.88\n",
      "Epoch 457 | train: Loss 0.291144 Accuracy 0.90 | validation: Loss 0.292110 Accuracy 0.91\n",
      "Epoch 458 | train: Loss 0.294247 Accuracy 0.90 | validation: Loss 0.301317 Accuracy 0.89\n",
      "Epoch 459 | train: Loss 0.296115 Accuracy 0.90 | validation: Loss 0.318676 Accuracy 0.88\n",
      "Epoch 460 | train: Loss 0.289175 Accuracy 0.90 | validation: Loss 0.297138 Accuracy 0.90\n",
      "Epoch 461 | train: Loss 0.292788 Accuracy 0.90 | validation: Loss 0.299802 Accuracy 0.90\n",
      "Epoch 462 | train: Loss 0.290032 Accuracy 0.90 | validation: Loss 0.300264 Accuracy 0.90\n",
      "Epoch 463 | train: Loss 0.292402 Accuracy 0.90 | validation: Loss 0.287675 Accuracy 0.91\n",
      "Epoch 464 | train: Loss 0.291480 Accuracy 0.90 | validation: Loss 0.311190 Accuracy 0.90\n",
      "Epoch 465 | train: Loss 0.289734 Accuracy 0.90 | validation: Loss 0.291192 Accuracy 0.90\n",
      "Epoch 466 | train: Loss 0.294657 Accuracy 0.90 | validation: Loss 0.300228 Accuracy 0.90\n",
      "Epoch 467 | train: Loss 0.289173 Accuracy 0.90 | validation: Loss 0.302356 Accuracy 0.89\n",
      "Epoch 468 | train: Loss 0.286798 Accuracy 0.90 | validation: Loss 0.295459 Accuracy 0.90\n",
      "Epoch 469 | train: Loss 0.286752 Accuracy 0.91 | validation: Loss 0.292430 Accuracy 0.91\n",
      "Epoch 470 | train: Loss 0.282088 Accuracy 0.91 | validation: Loss 0.289563 Accuracy 0.89\n",
      "Epoch 471 | train: Loss 0.283446 Accuracy 0.91 | validation: Loss 0.306040 Accuracy 0.90\n",
      "Epoch 472 | train: Loss 0.283319 Accuracy 0.90 | validation: Loss 0.292110 Accuracy 0.91\n",
      "Epoch 473 | train: Loss 0.283665 Accuracy 0.90 | validation: Loss 0.302198 Accuracy 0.91\n",
      "Epoch 474 | train: Loss 0.285953 Accuracy 0.90 | validation: Loss 0.294802 Accuracy 0.90\n",
      "Epoch 475 | train: Loss 0.282168 Accuracy 0.91 | validation: Loss 0.281627 Accuracy 0.90\n",
      "Epoch 476 | train: Loss 0.282568 Accuracy 0.91 | validation: Loss 0.313187 Accuracy 0.90\n",
      "Epoch 477 | train: Loss 0.280521 Accuracy 0.91 | validation: Loss 0.294269 Accuracy 0.89\n",
      "Epoch 478 | train: Loss 0.287417 Accuracy 0.90 | validation: Loss 0.293212 Accuracy 0.90\n",
      "Epoch 479 | train: Loss 0.287185 Accuracy 0.90 | validation: Loss 0.299618 Accuracy 0.88\n",
      "Epoch 480 | train: Loss 0.285205 Accuracy 0.90 | validation: Loss 0.305926 Accuracy 0.87\n",
      "Epoch 481 | train: Loss 0.286180 Accuracy 0.90 | validation: Loss 0.311348 Accuracy 0.89\n",
      "Epoch 482 | train: Loss 0.281109 Accuracy 0.91 | validation: Loss 0.301519 Accuracy 0.88\n",
      "Epoch 483 | train: Loss 0.283010 Accuracy 0.90 | validation: Loss 0.291230 Accuracy 0.91\n",
      "Epoch 484 | train: Loss 0.283706 Accuracy 0.90 | validation: Loss 0.284230 Accuracy 0.91\n",
      "Epoch 485 | train: Loss 0.278229 Accuracy 0.91 | validation: Loss 0.276053 Accuracy 0.92\n",
      "Epoch 486 | train: Loss 0.275250 Accuracy 0.91 | validation: Loss 0.304937 Accuracy 0.89\n",
      "Epoch 487 | train: Loss 0.284783 Accuracy 0.90 | validation: Loss 0.293126 Accuracy 0.91\n",
      "Epoch 488 | train: Loss 0.287056 Accuracy 0.89 | validation: Loss 0.308824 Accuracy 0.90\n",
      "Epoch 489 | train: Loss 0.278159 Accuracy 0.91 | validation: Loss 0.286328 Accuracy 0.91\n",
      "Epoch 490 | train: Loss 0.280893 Accuracy 0.90 | validation: Loss 0.297495 Accuracy 0.89\n",
      "Epoch 491 | train: Loss 0.280397 Accuracy 0.91 | validation: Loss 0.298302 Accuracy 0.90\n",
      "Epoch 492 | train: Loss 0.278539 Accuracy 0.91 | validation: Loss 0.293577 Accuracy 0.88\n",
      "Epoch 493 | train: Loss 0.277550 Accuracy 0.91 | validation: Loss 0.287248 Accuracy 0.90\n",
      "Epoch 494 | train: Loss 0.272915 Accuracy 0.91 | validation: Loss 0.284018 Accuracy 0.89\n",
      "Epoch 495 | train: Loss 0.274768 Accuracy 0.91 | validation: Loss 0.281464 Accuracy 0.90\n",
      "Epoch 496 | train: Loss 0.275804 Accuracy 0.90 | validation: Loss 0.278781 Accuracy 0.91\n",
      "Epoch 497 | train: Loss 0.272075 Accuracy 0.91 | validation: Loss 0.284430 Accuracy 0.89\n",
      "Epoch 498 | train: Loss 0.276774 Accuracy 0.90 | validation: Loss 0.278878 Accuracy 0.89\n",
      "Epoch 499 | train: Loss 0.269654 Accuracy 0.91 | validation: Loss 0.283072 Accuracy 0.90\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 128\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 64\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "model0 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(), lr=0.0001)\n",
    "\n",
    "model0_results = engine.train(model=model0,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              experiment_name=\"luzern_V0\",\n",
    "                              model_name=\"Neural_Net\",\n",
    "                              early_stop_patience=None,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff43e18c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T08:10:54.909783400Z",
     "start_time": "2023-12-27T08:10:03.030855600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] create SummaryWriter saving to runs\\2023-12-27-11\\luzern_V0\\Neural_Net\\1000epoch\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c545974eaf4a4dccbbb5a4203d5d65ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 1.321947 Accuracy 0.54 | validation: Loss 1.269491 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.266974 Accuracy 0.54 | validation: Loss 1.249635 Accuracy 0.52\n",
      "Epoch 2 | train: Loss 1.266196 Accuracy 0.54 | validation: Loss 1.265443 Accuracy 0.53\n",
      "Epoch 3 | train: Loss 1.259466 Accuracy 0.54 | validation: Loss 1.256212 Accuracy 0.53\n",
      "Epoch 4 | train: Loss 1.259040 Accuracy 0.54 | validation: Loss 1.255107 Accuracy 0.53\n",
      "Epoch 5 | train: Loss 1.255311 Accuracy 0.54 | validation: Loss 1.257348 Accuracy 0.53\n",
      "Epoch 6 | train: Loss 1.255088 Accuracy 0.54 | validation: Loss 1.253634 Accuracy 0.53\n",
      "Epoch 7 | train: Loss 1.253385 Accuracy 0.54 | validation: Loss 1.241413 Accuracy 0.54\n",
      "Epoch 8 | train: Loss 1.253443 Accuracy 0.54 | validation: Loss 1.265193 Accuracy 0.53\n",
      "Epoch 9 | train: Loss 1.250682 Accuracy 0.54 | validation: Loss 1.244783 Accuracy 0.53\n",
      "Epoch 10 | train: Loss 1.249708 Accuracy 0.54 | validation: Loss 1.245226 Accuracy 0.54\n",
      "Epoch 11 | train: Loss 1.256596 Accuracy 0.54 | validation: Loss 1.268606 Accuracy 0.53\n",
      "Epoch 12 | train: Loss 1.256218 Accuracy 0.54 | validation: Loss 1.248603 Accuracy 0.54\n",
      "Epoch 13 | train: Loss 1.247188 Accuracy 0.54 | validation: Loss 1.251292 Accuracy 0.54\n",
      "Epoch 14 | train: Loss 1.246442 Accuracy 0.54 | validation: Loss 1.256048 Accuracy 0.53\n",
      "Epoch 15 | train: Loss 1.248293 Accuracy 0.54 | validation: Loss 1.250326 Accuracy 0.54\n",
      "Epoch 16 | train: Loss 1.247109 Accuracy 0.54 | validation: Loss 1.241886 Accuracy 0.54\n",
      "Epoch 17 | train: Loss 1.243789 Accuracy 0.54 | validation: Loss 1.245073 Accuracy 0.54\n",
      "Early_Stop_at_ 17 Epoch\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 4\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "model1 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model1.parameters(), lr=0.01)\n",
    "\n",
    "model1_results = engine.train(model=model1,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              experiment_name=\"luzern_V0\",\n",
    "                              model_name=\"Neural_Net\",\n",
    "                              early_stop_patience=10,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c945f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T10:03:32.185342Z",
     "start_time": "2023-12-25T10:03:28.391514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--datafolder DATAFOLDER] [--city {luzern}] [--seed SEED]\n",
      "               [-n NEURAL_NETWORK] [--early_stop EARLY_STOP]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --datafolder DATAFOLDER\n",
      "                        Please write the address of the folder which contains\n",
      "                        data.\n",
      "  --city {luzern}       Choose which city are you looking at.\n",
      "  --seed SEED           What is the random you want to model on it?\n",
      "  -n NEURAL_NETWORK, --neural_network NEURAL_NETWORK\n",
      "                        Specify hyper parameters of neural_network in order\n",
      "                        to: hidden_units, epochs, learning_rate\n",
      "  --early_stop EARLY_STOP\n",
      "                        early_stop count?\n"
     ]
    }
   ],
   "source": [
    "!python Going_Modular/main.py --help"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import data_setup\n",
    "from pathlib import Path\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "city = \"luzern\"\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:14:49.940875700Z",
     "start_time": "2023-12-27T07:14:49.663162900Z"
    }
   },
   "id": "8b784812041bf4a0",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(data_path / \"test_data_luzern.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:15:52.808489400Z",
     "start_time": "2023-12-27T07:15:52.703914800Z"
    }
   },
   "id": "d944f7346919abfd",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0      6\n1      4\n2      5\n3      3\n4      4\n      ..\n898    3\n899    4\n900    0\n901    5\n902    4\nName: date, Length: 903, dtype: int32"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n",
    "train_data[\"date\"] = pd.to_datetime(train_data[\"date\"])\n",
    "train_data[\"date\"].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:28:53.746220Z",
     "start_time": "2023-12-27T07:28:53.612857500Z"
    }
   },
   "id": "66a925d1599fa2e0",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data1 = train_data[train_data[\"rainfall\"] > 0]\n",
    "data2 = train_data[train_data[\"rainfall\"] == 0]\n",
    "# \n",
    "# mask1 = [(data1[\"date\"].dt.dayofweek == 0 + data1[\"date\"].dt.hour == 9) == 2]\n",
    "# plt.scatter(data1[mask1][\"date\"], data1[mask1][\"flow\"], c=\"blue\")\n",
    "# \n",
    "# mask2 = [(data2[\"date\"].dt.dayofweek == 0 + data2[\"date\"].dt.hour == 9) == 2]\n",
    "# plt.scatter(data2[mask2][\"date\"], data2[mask2][\"flow\"], c=\"orange\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:44:30.651667100Z",
     "start_time": "2023-12-27T07:44:30.548336500Z"
    }
   },
   "id": "be5bf81a3c48924d",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(364.68060252736575, 312.57799689927344)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mask1 = data1[\"date\"].dt.dayofweek == 4\n",
    "mask2 = data2[\"date\"].dt.dayofweek == 4\n",
    "data1[mask1][\"flow\"].mean(), data2[mask2][\"flow\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:45:46.655746Z",
     "start_time": "2023-12-27T07:45:46.528833700Z"
    }
   },
   "id": "775ef95d8de70cc4",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(296.16657347085015, 291.45334302041874)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[\"flow\"].mean(), data2[\"flow\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:46:07.892611900Z",
     "start_time": "2023-12-27T07:46:07.751681700Z"
    }
   },
   "id": "25cb0ea242b55641",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x1f427d9cb90>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data1 = train_data[train_data[\"rainfall\"] > 0]\n",
    "data2 = train_data[train_data[\"rainfall\"] == 0]\n",
    "plt.scatter(data2[\"rainfall\"], data2[\"flow\"], c=\"orange\")\n",
    "plt.scatter(data1[\"rainfall\"], data1[\"flow\"], c=\"blue\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T07:23:13.513098500Z",
     "start_time": "2023-12-27T07:23:13.237495900Z"
    }
   },
   "id": "fa2e958e401302ff",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c3a013c688d6ccd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

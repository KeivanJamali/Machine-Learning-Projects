{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T19:45:34.868481100Z",
     "start_time": "2023-12-24T19:45:34.732255200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4f52610c90bd7cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.162621500Z",
     "start_time": "2023-12-24T18:08:04.056028300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class LOS_Classification_V0(nn.Module):\n",
    "    def __init__(self, in_put, hidden_units, out_put):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_put, hidden_units)\n",
    "        self.layer_2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.layer_3 = nn.Linear(hidden_units, out_put)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b1b906b0f18a47ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.316983100Z",
     "start_time": "2023-12-24T18:08:04.166627500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data_setup\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "luzern_data = data_setup.Dataloader()\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path,\n",
    "                                                                                   city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8ee2a61426703426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.448168900Z",
     "start_time": "2023-12-24T18:08:04.322935900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOS_Classification_V0(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (layer_3): Linear(in_features=32, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "\n",
    "model0 = LOS_Classification_V0(INPUT_SHAPE, HIDDEN_UNITS, OUTPUT_SHAPE)\n",
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6739deee2b7363d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:08:04.551677800Z",
     "start_time": "2023-12-24T18:08:04.439587600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LOS_Classification_V0                    [1, 6]                    --\n",
       "├─Linear: 1-1                            [1, 32]                   224\n",
       "├─ReLU: 1-2                              [1, 32]                   --\n",
       "├─Linear: 1-3                            [1, 32]                   1,056\n",
       "├─ReLU: 1-4                              [1, 32]                   --\n",
       "├─Linear: 1-5                            [1, 6]                    198\n",
       "==========================================================================================\n",
       "Total params: 1,478\n",
       "Trainable params: 1,478\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model0, input_size=[1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e4a4743201b1838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:15:03.590090200Z",
     "start_time": "2023-12-24T18:15:03.480256600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: str) -> tuple[float, float]:\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_logit = model(X)\n",
    "        loss = loss_fn(y_logit, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_logit, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_logit)\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def val_step(model: torch.nn.Module,\n",
    "             dataloader: torch.utils.data.DataLoader,\n",
    "             loss_fn: torch.nn.Module,\n",
    "             device: str) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_logit = model(X)\n",
    "            val_loss += loss_fn(y_logit, y).item()\n",
    "            val_pred_labels = y_logit.argmax(dim=1)\n",
    "            val_acc += ((val_pred_labels == y).sum().item() / len(y_logit))\n",
    "\n",
    "    val_loss /= len(dataloader)\n",
    "    val_acc /= len(dataloader)\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "50f4493ece2facf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:15:04.981362800Z",
     "start_time": "2023-12-24T18:15:04.873979200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          val_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int = 32,\n",
    "          device: str = \"cpu\") -> dict[str, list]:\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": []}\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        val_loss, val_acc = val_step(model=model,\n",
    "                                     dataloader=val_dataloader,\n",
    "                                     loss_fn=loss_fn,\n",
    "                                     device=device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch} | train: Loss {train_loss:.6f} Accuracy {train_acc:.2f} | validation: Loss {val_loss:.6f} Accuracy {val_acc:.2f}\")\n",
    "\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3aefa6ffdddcb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T18:14:01.685815200Z",
     "start_time": "2023-12-24T18:13:44.509299500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ffeb35a66b48a5a57852a1ef59fe32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 7.770748 Accuracy 0.51 | validation: Loss 1.463997 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.401297 Accuracy 0.51 | validation: Loss 1.371067 Accuracy 0.51\n",
      "Epoch 2 | train: Loss 1.341635 Accuracy 0.54 | validation: Loss 1.315855 Accuracy 0.58\n",
      "Epoch 3 | train: Loss 1.281819 Accuracy 0.57 | validation: Loss 1.244994 Accuracy 0.58\n",
      "Epoch 4 | train: Loss 1.193157 Accuracy 0.60 | validation: Loss 1.165906 Accuracy 0.58\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "num_epochs = 5\n",
    "\n",
    "model0 = LOS_Classification_V0(INPUT_SHAPE, HIDDEN_UNITS, OUTPUT_SHAPE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(),\n",
    "                             lr=0.0001)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model0_results = train(model=model0,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       epochs=num_epochs,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f26e6d08bf6fe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T19:20:35.906702500Z",
     "start_time": "2023-12-24T19:07:44.848355900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f37cd68e984d7893d007cf41eda6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 7.770748 Accuracy 0.51 | validation: Loss 1.463997 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.401297 Accuracy 0.51 | validation: Loss 1.371067 Accuracy 0.51\n",
      "Epoch 2 | train: Loss 1.341635 Accuracy 0.54 | validation: Loss 1.315855 Accuracy 0.58\n",
      "Epoch 3 | train: Loss 1.281819 Accuracy 0.57 | validation: Loss 1.244994 Accuracy 0.58\n",
      "Epoch 4 | train: Loss 1.193157 Accuracy 0.60 | validation: Loss 1.165906 Accuracy 0.58\n",
      "Epoch 5 | train: Loss 1.137688 Accuracy 0.60 | validation: Loss 1.110927 Accuracy 0.63\n",
      "Epoch 6 | train: Loss 1.096668 Accuracy 0.62 | validation: Loss 1.072906 Accuracy 0.61\n",
      "Epoch 7 | train: Loss 1.058621 Accuracy 0.62 | validation: Loss 1.042243 Accuracy 0.63\n",
      "Epoch 8 | train: Loss 1.024245 Accuracy 0.63 | validation: Loss 1.014664 Accuracy 0.64\n",
      "Epoch 9 | train: Loss 1.010744 Accuracy 0.62 | validation: Loss 0.990566 Accuracy 0.64\n",
      "Epoch 10 | train: Loss 0.991309 Accuracy 0.63 | validation: Loss 0.989238 Accuracy 0.64\n",
      "Epoch 11 | train: Loss 0.980363 Accuracy 0.63 | validation: Loss 0.973587 Accuracy 0.64\n",
      "Epoch 12 | train: Loss 0.967430 Accuracy 0.64 | validation: Loss 0.962147 Accuracy 0.64\n",
      "Epoch 13 | train: Loss 0.954461 Accuracy 0.64 | validation: Loss 0.950874 Accuracy 0.64\n",
      "Epoch 14 | train: Loss 0.944159 Accuracy 0.64 | validation: Loss 0.947094 Accuracy 0.60\n",
      "Epoch 15 | train: Loss 0.931363 Accuracy 0.65 | validation: Loss 0.932474 Accuracy 0.63\n",
      "Epoch 16 | train: Loss 0.924713 Accuracy 0.64 | validation: Loss 0.922856 Accuracy 0.65\n",
      "Epoch 17 | train: Loss 0.921893 Accuracy 0.64 | validation: Loss 0.903907 Accuracy 0.65\n",
      "Epoch 18 | train: Loss 0.903587 Accuracy 0.65 | validation: Loss 0.903019 Accuracy 0.66\n",
      "Epoch 19 | train: Loss 0.894463 Accuracy 0.65 | validation: Loss 0.891470 Accuracy 0.65\n",
      "Epoch 20 | train: Loss 0.888241 Accuracy 0.66 | validation: Loss 0.892052 Accuracy 0.64\n",
      "Epoch 21 | train: Loss 0.878801 Accuracy 0.65 | validation: Loss 0.890870 Accuracy 0.62\n",
      "Epoch 22 | train: Loss 0.873351 Accuracy 0.66 | validation: Loss 0.871126 Accuracy 0.66\n",
      "Epoch 23 | train: Loss 0.867357 Accuracy 0.66 | validation: Loss 0.889601 Accuracy 0.62\n",
      "Epoch 24 | train: Loss 0.855807 Accuracy 0.66 | validation: Loss 0.864696 Accuracy 0.65\n",
      "Epoch 25 | train: Loss 0.852079 Accuracy 0.66 | validation: Loss 0.852106 Accuracy 0.67\n",
      "Epoch 26 | train: Loss 0.847461 Accuracy 0.66 | validation: Loss 0.868153 Accuracy 0.62\n",
      "Epoch 27 | train: Loss 0.842560 Accuracy 0.66 | validation: Loss 0.842749 Accuracy 0.66\n",
      "Epoch 28 | train: Loss 0.830981 Accuracy 0.67 | validation: Loss 0.840609 Accuracy 0.68\n",
      "Epoch 29 | train: Loss 0.828695 Accuracy 0.67 | validation: Loss 0.829810 Accuracy 0.66\n",
      "Epoch 30 | train: Loss 0.818988 Accuracy 0.68 | validation: Loss 0.824037 Accuracy 0.68\n",
      "Epoch 31 | train: Loss 0.814818 Accuracy 0.67 | validation: Loss 0.814565 Accuracy 0.68\n",
      "Epoch 32 | train: Loss 0.806863 Accuracy 0.68 | validation: Loss 0.818178 Accuracy 0.66\n",
      "Epoch 33 | train: Loss 0.805819 Accuracy 0.68 | validation: Loss 0.803347 Accuracy 0.69\n",
      "Epoch 34 | train: Loss 0.793926 Accuracy 0.69 | validation: Loss 0.799545 Accuracy 0.70\n",
      "Epoch 35 | train: Loss 0.787310 Accuracy 0.68 | validation: Loss 0.795609 Accuracy 0.70\n",
      "Epoch 36 | train: Loss 0.783704 Accuracy 0.68 | validation: Loss 0.785752 Accuracy 0.70\n",
      "Epoch 37 | train: Loss 0.780884 Accuracy 0.69 | validation: Loss 0.791324 Accuracy 0.69\n",
      "Epoch 38 | train: Loss 0.775238 Accuracy 0.69 | validation: Loss 0.787314 Accuracy 0.66\n",
      "Epoch 39 | train: Loss 0.768607 Accuracy 0.69 | validation: Loss 0.779149 Accuracy 0.67\n",
      "Epoch 40 | train: Loss 0.765579 Accuracy 0.70 | validation: Loss 0.772937 Accuracy 0.69\n",
      "Epoch 41 | train: Loss 0.756578 Accuracy 0.70 | validation: Loss 0.759977 Accuracy 0.71\n",
      "Epoch 42 | train: Loss 0.754385 Accuracy 0.70 | validation: Loss 0.757895 Accuracy 0.70\n",
      "Epoch 43 | train: Loss 0.746630 Accuracy 0.70 | validation: Loss 0.762511 Accuracy 0.68\n",
      "Epoch 44 | train: Loss 0.742982 Accuracy 0.71 | validation: Loss 0.755394 Accuracy 0.68\n",
      "Epoch 45 | train: Loss 0.737420 Accuracy 0.70 | validation: Loss 0.752400 Accuracy 0.68\n",
      "Epoch 46 | train: Loss 0.737618 Accuracy 0.70 | validation: Loss 0.740232 Accuracy 0.72\n",
      "Epoch 47 | train: Loss 0.726321 Accuracy 0.71 | validation: Loss 0.733530 Accuracy 0.72\n",
      "Epoch 48 | train: Loss 0.720792 Accuracy 0.71 | validation: Loss 0.727859 Accuracy 0.73\n",
      "Epoch 49 | train: Loss 0.719869 Accuracy 0.72 | validation: Loss 0.723642 Accuracy 0.73\n",
      "Epoch 50 | train: Loss 0.715293 Accuracy 0.72 | validation: Loss 0.727003 Accuracy 0.73\n",
      "Epoch 51 | train: Loss 0.711958 Accuracy 0.72 | validation: Loss 0.719967 Accuracy 0.72\n",
      "Epoch 52 | train: Loss 0.704912 Accuracy 0.72 | validation: Loss 0.722807 Accuracy 0.69\n",
      "Epoch 53 | train: Loss 0.699707 Accuracy 0.72 | validation: Loss 0.709715 Accuracy 0.73\n",
      "Epoch 54 | train: Loss 0.701183 Accuracy 0.72 | validation: Loss 0.698311 Accuracy 0.74\n",
      "Epoch 55 | train: Loss 0.692638 Accuracy 0.72 | validation: Loss 0.700265 Accuracy 0.74\n",
      "Epoch 56 | train: Loss 0.688808 Accuracy 0.73 | validation: Loss 0.696568 Accuracy 0.73\n",
      "Epoch 57 | train: Loss 0.687337 Accuracy 0.73 | validation: Loss 0.695952 Accuracy 0.75\n",
      "Epoch 58 | train: Loss 0.680272 Accuracy 0.73 | validation: Loss 0.697558 Accuracy 0.73\n",
      "Epoch 59 | train: Loss 0.678162 Accuracy 0.73 | validation: Loss 0.688365 Accuracy 0.71\n",
      "Epoch 60 | train: Loss 0.674192 Accuracy 0.73 | validation: Loss 0.676991 Accuracy 0.75\n",
      "Epoch 61 | train: Loss 0.667833 Accuracy 0.74 | validation: Loss 0.698862 Accuracy 0.70\n",
      "Epoch 62 | train: Loss 0.662572 Accuracy 0.74 | validation: Loss 0.675026 Accuracy 0.72\n",
      "Epoch 63 | train: Loss 0.659208 Accuracy 0.75 | validation: Loss 0.666871 Accuracy 0.76\n",
      "Epoch 64 | train: Loss 0.653192 Accuracy 0.75 | validation: Loss 0.657345 Accuracy 0.77\n",
      "Epoch 65 | train: Loss 0.647470 Accuracy 0.75 | validation: Loss 0.660546 Accuracy 0.75\n",
      "Epoch 66 | train: Loss 0.646440 Accuracy 0.75 | validation: Loss 0.654243 Accuracy 0.76\n",
      "Epoch 67 | train: Loss 0.646800 Accuracy 0.74 | validation: Loss 0.652966 Accuracy 0.76\n",
      "Epoch 68 | train: Loss 0.638284 Accuracy 0.75 | validation: Loss 0.664863 Accuracy 0.77\n",
      "Epoch 69 | train: Loss 0.634886 Accuracy 0.76 | validation: Loss 0.635528 Accuracy 0.76\n",
      "Epoch 70 | train: Loss 0.629202 Accuracy 0.76 | validation: Loss 0.649982 Accuracy 0.74\n",
      "Epoch 71 | train: Loss 0.628105 Accuracy 0.76 | validation: Loss 0.632560 Accuracy 0.78\n",
      "Epoch 72 | train: Loss 0.623127 Accuracy 0.76 | validation: Loss 0.627361 Accuracy 0.77\n",
      "Epoch 73 | train: Loss 0.619127 Accuracy 0.76 | validation: Loss 0.616061 Accuracy 0.78\n",
      "Epoch 74 | train: Loss 0.614265 Accuracy 0.76 | validation: Loss 0.627991 Accuracy 0.79\n",
      "Epoch 75 | train: Loss 0.611225 Accuracy 0.77 | validation: Loss 0.616467 Accuracy 0.77\n",
      "Epoch 76 | train: Loss 0.603866 Accuracy 0.77 | validation: Loss 0.679849 Accuracy 0.77\n",
      "Epoch 77 | train: Loss 0.607190 Accuracy 0.76 | validation: Loss 0.607421 Accuracy 0.77\n",
      "Epoch 78 | train: Loss 0.600754 Accuracy 0.77 | validation: Loss 0.611144 Accuracy 0.75\n",
      "Epoch 79 | train: Loss 0.594555 Accuracy 0.78 | validation: Loss 0.620293 Accuracy 0.75\n",
      "Epoch 80 | train: Loss 0.592735 Accuracy 0.78 | validation: Loss 0.592101 Accuracy 0.79\n",
      "Epoch 81 | train: Loss 0.587043 Accuracy 0.78 | validation: Loss 0.596168 Accuracy 0.80\n",
      "Epoch 82 | train: Loss 0.582139 Accuracy 0.78 | validation: Loss 0.589731 Accuracy 0.80\n",
      "Epoch 83 | train: Loss 0.578419 Accuracy 0.78 | validation: Loss 0.579975 Accuracy 0.80\n",
      "Epoch 84 | train: Loss 0.575213 Accuracy 0.79 | validation: Loss 0.586623 Accuracy 0.77\n",
      "Epoch 85 | train: Loss 0.573347 Accuracy 0.78 | validation: Loss 0.572913 Accuracy 0.80\n",
      "Epoch 86 | train: Loss 0.567625 Accuracy 0.78 | validation: Loss 0.569855 Accuracy 0.80\n",
      "Epoch 87 | train: Loss 0.567611 Accuracy 0.78 | validation: Loss 0.570562 Accuracy 0.79\n",
      "Epoch 88 | train: Loss 0.562606 Accuracy 0.79 | validation: Loss 0.584584 Accuracy 0.76\n",
      "Epoch 89 | train: Loss 0.561974 Accuracy 0.79 | validation: Loss 0.567529 Accuracy 0.79\n",
      "Epoch 90 | train: Loss 0.554004 Accuracy 0.79 | validation: Loss 0.558342 Accuracy 0.81\n",
      "Epoch 91 | train: Loss 0.551858 Accuracy 0.80 | validation: Loss 0.554501 Accuracy 0.80\n",
      "Epoch 92 | train: Loss 0.545720 Accuracy 0.79 | validation: Loss 0.562098 Accuracy 0.80\n",
      "Epoch 93 | train: Loss 0.546528 Accuracy 0.79 | validation: Loss 0.552496 Accuracy 0.82\n",
      "Epoch 94 | train: Loss 0.541834 Accuracy 0.80 | validation: Loss 0.565578 Accuracy 0.79\n",
      "Epoch 95 | train: Loss 0.544433 Accuracy 0.80 | validation: Loss 0.543707 Accuracy 0.82\n",
      "Epoch 96 | train: Loss 0.538126 Accuracy 0.80 | validation: Loss 0.543214 Accuracy 0.80\n",
      "Epoch 97 | train: Loss 0.536824 Accuracy 0.80 | validation: Loss 0.549271 Accuracy 0.80\n",
      "Epoch 98 | train: Loss 0.532085 Accuracy 0.80 | validation: Loss 0.554491 Accuracy 0.81\n",
      "Epoch 99 | train: Loss 0.527861 Accuracy 0.80 | validation: Loss 0.537508 Accuracy 0.83\n",
      "Epoch 100 | train: Loss 0.528462 Accuracy 0.80 | validation: Loss 0.530742 Accuracy 0.81\n",
      "Epoch 101 | train: Loss 0.523833 Accuracy 0.80 | validation: Loss 0.531885 Accuracy 0.81\n",
      "Epoch 102 | train: Loss 0.524451 Accuracy 0.80 | validation: Loss 0.532755 Accuracy 0.83\n",
      "Epoch 103 | train: Loss 0.517215 Accuracy 0.80 | validation: Loss 0.523418 Accuracy 0.83\n",
      "Epoch 104 | train: Loss 0.516947 Accuracy 0.80 | validation: Loss 0.520120 Accuracy 0.82\n",
      "Epoch 105 | train: Loss 0.512698 Accuracy 0.81 | validation: Loss 0.521333 Accuracy 0.84\n",
      "Epoch 106 | train: Loss 0.506155 Accuracy 0.82 | validation: Loss 0.516057 Accuracy 0.82\n",
      "Epoch 107 | train: Loss 0.505722 Accuracy 0.81 | validation: Loss 0.520029 Accuracy 0.82\n",
      "Epoch 108 | train: Loss 0.502788 Accuracy 0.82 | validation: Loss 0.512856 Accuracy 0.82\n",
      "Epoch 109 | train: Loss 0.504817 Accuracy 0.81 | validation: Loss 0.500713 Accuracy 0.84\n",
      "Epoch 110 | train: Loss 0.500524 Accuracy 0.81 | validation: Loss 0.537016 Accuracy 0.78\n",
      "Epoch 111 | train: Loss 0.498246 Accuracy 0.81 | validation: Loss 0.502912 Accuracy 0.84\n",
      "Epoch 112 | train: Loss 0.494976 Accuracy 0.82 | validation: Loss 0.513809 Accuracy 0.79\n",
      "Epoch 113 | train: Loss 0.497342 Accuracy 0.81 | validation: Loss 0.514945 Accuracy 0.81\n",
      "Epoch 114 | train: Loss 0.491713 Accuracy 0.82 | validation: Loss 0.503188 Accuracy 0.83\n",
      "Epoch 115 | train: Loss 0.486018 Accuracy 0.82 | validation: Loss 0.504558 Accuracy 0.79\n",
      "Epoch 116 | train: Loss 0.487373 Accuracy 0.82 | validation: Loss 0.496496 Accuracy 0.82\n",
      "Epoch 117 | train: Loss 0.484922 Accuracy 0.82 | validation: Loss 0.495053 Accuracy 0.81\n",
      "Epoch 118 | train: Loss 0.485716 Accuracy 0.82 | validation: Loss 0.491333 Accuracy 0.82\n",
      "Epoch 119 | train: Loss 0.477677 Accuracy 0.82 | validation: Loss 0.500013 Accuracy 0.81\n",
      "Epoch 120 | train: Loss 0.477340 Accuracy 0.82 | validation: Loss 0.486932 Accuracy 0.82\n",
      "Epoch 121 | train: Loss 0.475626 Accuracy 0.83 | validation: Loss 0.480615 Accuracy 0.84\n",
      "Epoch 122 | train: Loss 0.474442 Accuracy 0.82 | validation: Loss 0.486063 Accuracy 0.80\n",
      "Epoch 123 | train: Loss 0.471689 Accuracy 0.82 | validation: Loss 0.480748 Accuracy 0.85\n",
      "Epoch 124 | train: Loss 0.468587 Accuracy 0.83 | validation: Loss 0.492085 Accuracy 0.81\n",
      "Epoch 125 | train: Loss 0.465093 Accuracy 0.83 | validation: Loss 0.473344 Accuracy 0.82\n",
      "Epoch 126 | train: Loss 0.466044 Accuracy 0.83 | validation: Loss 0.472774 Accuracy 0.82\n",
      "Epoch 127 | train: Loss 0.460097 Accuracy 0.83 | validation: Loss 0.474118 Accuracy 0.86\n",
      "Epoch 128 | train: Loss 0.462574 Accuracy 0.83 | validation: Loss 0.487741 Accuracy 0.81\n",
      "Epoch 129 | train: Loss 0.462879 Accuracy 0.83 | validation: Loss 0.466325 Accuracy 0.84\n",
      "Epoch 130 | train: Loss 0.455076 Accuracy 0.83 | validation: Loss 0.474711 Accuracy 0.84\n",
      "Epoch 131 | train: Loss 0.451570 Accuracy 0.83 | validation: Loss 0.477230 Accuracy 0.80\n",
      "Epoch 132 | train: Loss 0.453679 Accuracy 0.83 | validation: Loss 0.457543 Accuracy 0.83\n",
      "Epoch 133 | train: Loss 0.448984 Accuracy 0.83 | validation: Loss 0.457155 Accuracy 0.84\n",
      "Epoch 134 | train: Loss 0.448344 Accuracy 0.83 | validation: Loss 0.469272 Accuracy 0.82\n",
      "Epoch 135 | train: Loss 0.446569 Accuracy 0.84 | validation: Loss 0.454110 Accuracy 0.83\n",
      "Epoch 136 | train: Loss 0.449638 Accuracy 0.83 | validation: Loss 0.446409 Accuracy 0.84\n",
      "Epoch 137 | train: Loss 0.440898 Accuracy 0.83 | validation: Loss 0.454255 Accuracy 0.84\n",
      "Epoch 138 | train: Loss 0.435917 Accuracy 0.85 | validation: Loss 0.465914 Accuracy 0.83\n",
      "Epoch 139 | train: Loss 0.438036 Accuracy 0.84 | validation: Loss 0.443309 Accuracy 0.84\n",
      "Epoch 140 | train: Loss 0.437185 Accuracy 0.84 | validation: Loss 0.442749 Accuracy 0.84\n",
      "Epoch 141 | train: Loss 0.434688 Accuracy 0.85 | validation: Loss 0.443494 Accuracy 0.82\n",
      "Epoch 142 | train: Loss 0.437726 Accuracy 0.84 | validation: Loss 0.441629 Accuracy 0.83\n",
      "Epoch 143 | train: Loss 0.430795 Accuracy 0.85 | validation: Loss 0.443103 Accuracy 0.84\n",
      "Epoch 144 | train: Loss 0.432675 Accuracy 0.84 | validation: Loss 0.433754 Accuracy 0.86\n",
      "Epoch 145 | train: Loss 0.429997 Accuracy 0.84 | validation: Loss 0.455517 Accuracy 0.83\n",
      "Epoch 146 | train: Loss 0.420509 Accuracy 0.85 | validation: Loss 0.428323 Accuracy 0.86\n",
      "Epoch 147 | train: Loss 0.424068 Accuracy 0.85 | validation: Loss 0.424805 Accuracy 0.86\n",
      "Epoch 148 | train: Loss 0.423103 Accuracy 0.85 | validation: Loss 0.426771 Accuracy 0.84\n",
      "Epoch 149 | train: Loss 0.421092 Accuracy 0.85 | validation: Loss 0.423263 Accuracy 0.84\n",
      "Epoch 150 | train: Loss 0.416928 Accuracy 0.85 | validation: Loss 0.432876 Accuracy 0.84\n",
      "Epoch 151 | train: Loss 0.419922 Accuracy 0.85 | validation: Loss 0.436764 Accuracy 0.84\n",
      "Epoch 152 | train: Loss 0.415029 Accuracy 0.85 | validation: Loss 0.422672 Accuracy 0.83\n",
      "Epoch 153 | train: Loss 0.421162 Accuracy 0.85 | validation: Loss 0.428838 Accuracy 0.84\n",
      "Epoch 154 | train: Loss 0.411587 Accuracy 0.85 | validation: Loss 0.423902 Accuracy 0.85\n",
      "Epoch 155 | train: Loss 0.410195 Accuracy 0.85 | validation: Loss 0.417422 Accuracy 0.87\n",
      "Epoch 156 | train: Loss 0.406899 Accuracy 0.86 | validation: Loss 0.412521 Accuracy 0.86\n",
      "Epoch 157 | train: Loss 0.407120 Accuracy 0.86 | validation: Loss 0.411075 Accuracy 0.84\n",
      "Epoch 158 | train: Loss 0.400906 Accuracy 0.86 | validation: Loss 0.406766 Accuracy 0.87\n",
      "Epoch 159 | train: Loss 0.406483 Accuracy 0.85 | validation: Loss 0.409017 Accuracy 0.86\n",
      "Epoch 160 | train: Loss 0.401239 Accuracy 0.87 | validation: Loss 0.406618 Accuracy 0.88\n",
      "Epoch 161 | train: Loss 0.401735 Accuracy 0.86 | validation: Loss 0.405226 Accuracy 0.85\n",
      "Epoch 162 | train: Loss 0.399014 Accuracy 0.86 | validation: Loss 0.407007 Accuracy 0.88\n",
      "Epoch 163 | train: Loss 0.396915 Accuracy 0.86 | validation: Loss 0.398108 Accuracy 0.86\n",
      "Epoch 164 | train: Loss 0.395926 Accuracy 0.86 | validation: Loss 0.401902 Accuracy 0.88\n",
      "Epoch 165 | train: Loss 0.392796 Accuracy 0.87 | validation: Loss 0.398523 Accuracy 0.88\n",
      "Epoch 166 | train: Loss 0.394632 Accuracy 0.86 | validation: Loss 0.392342 Accuracy 0.86\n",
      "Epoch 167 | train: Loss 0.388450 Accuracy 0.87 | validation: Loss 0.393166 Accuracy 0.86\n",
      "Epoch 168 | train: Loss 0.388460 Accuracy 0.87 | validation: Loss 0.392684 Accuracy 0.85\n",
      "Epoch 169 | train: Loss 0.385769 Accuracy 0.87 | validation: Loss 0.385049 Accuracy 0.87\n",
      "Epoch 170 | train: Loss 0.382767 Accuracy 0.87 | validation: Loss 0.388387 Accuracy 0.86\n",
      "Epoch 171 | train: Loss 0.381710 Accuracy 0.86 | validation: Loss 0.412501 Accuracy 0.86\n",
      "Epoch 172 | train: Loss 0.381592 Accuracy 0.87 | validation: Loss 0.394585 Accuracy 0.87\n",
      "Epoch 173 | train: Loss 0.380422 Accuracy 0.87 | validation: Loss 0.389696 Accuracy 0.88\n",
      "Epoch 174 | train: Loss 0.380729 Accuracy 0.86 | validation: Loss 0.388517 Accuracy 0.85\n",
      "Epoch 175 | train: Loss 0.375394 Accuracy 0.87 | validation: Loss 0.384511 Accuracy 0.87\n",
      "Epoch 176 | train: Loss 0.378823 Accuracy 0.87 | validation: Loss 0.396211 Accuracy 0.87\n",
      "Epoch 177 | train: Loss 0.371371 Accuracy 0.88 | validation: Loss 0.374928 Accuracy 0.89\n",
      "Epoch 178 | train: Loss 0.375616 Accuracy 0.87 | validation: Loss 0.386345 Accuracy 0.86\n",
      "Epoch 179 | train: Loss 0.378481 Accuracy 0.87 | validation: Loss 0.382247 Accuracy 0.87\n",
      "Epoch 180 | train: Loss 0.377036 Accuracy 0.87 | validation: Loss 0.385251 Accuracy 0.86\n",
      "Epoch 181 | train: Loss 0.372210 Accuracy 0.87 | validation: Loss 0.383151 Accuracy 0.86\n",
      "Epoch 182 | train: Loss 0.366490 Accuracy 0.87 | validation: Loss 0.370280 Accuracy 0.87\n",
      "Epoch 183 | train: Loss 0.368609 Accuracy 0.87 | validation: Loss 0.374418 Accuracy 0.86\n",
      "Epoch 184 | train: Loss 0.365448 Accuracy 0.87 | validation: Loss 0.368496 Accuracy 0.87\n",
      "Epoch 185 | train: Loss 0.363412 Accuracy 0.88 | validation: Loss 0.382710 Accuracy 0.86\n",
      "Epoch 186 | train: Loss 0.363884 Accuracy 0.87 | validation: Loss 0.383940 Accuracy 0.87\n",
      "Epoch 187 | train: Loss 0.357921 Accuracy 0.88 | validation: Loss 0.368488 Accuracy 0.87\n",
      "Epoch 188 | train: Loss 0.360943 Accuracy 0.88 | validation: Loss 0.367824 Accuracy 0.88\n",
      "Epoch 189 | train: Loss 0.356092 Accuracy 0.88 | validation: Loss 0.357405 Accuracy 0.88\n",
      "Epoch 190 | train: Loss 0.360234 Accuracy 0.87 | validation: Loss 0.362458 Accuracy 0.87\n",
      "Epoch 191 | train: Loss 0.359251 Accuracy 0.87 | validation: Loss 0.356921 Accuracy 0.88\n",
      "Epoch 192 | train: Loss 0.353327 Accuracy 0.88 | validation: Loss 0.358972 Accuracy 0.88\n",
      "Epoch 193 | train: Loss 0.354483 Accuracy 0.88 | validation: Loss 0.363803 Accuracy 0.88\n",
      "Epoch 194 | train: Loss 0.349414 Accuracy 0.88 | validation: Loss 0.361482 Accuracy 0.87\n",
      "Epoch 195 | train: Loss 0.350001 Accuracy 0.88 | validation: Loss 0.352461 Accuracy 0.89\n",
      "Epoch 196 | train: Loss 0.352416 Accuracy 0.88 | validation: Loss 0.349933 Accuracy 0.89\n",
      "Epoch 197 | train: Loss 0.347184 Accuracy 0.88 | validation: Loss 0.361707 Accuracy 0.86\n",
      "Epoch 198 | train: Loss 0.345992 Accuracy 0.88 | validation: Loss 0.354419 Accuracy 0.87\n",
      "Epoch 199 | train: Loss 0.346362 Accuracy 0.88 | validation: Loss 0.370631 Accuracy 0.86\n",
      "Epoch 200 | train: Loss 0.346107 Accuracy 0.88 | validation: Loss 0.345049 Accuracy 0.89\n",
      "Epoch 201 | train: Loss 0.343118 Accuracy 0.88 | validation: Loss 0.394559 Accuracy 0.84\n",
      "Epoch 202 | train: Loss 0.344664 Accuracy 0.88 | validation: Loss 0.378604 Accuracy 0.86\n",
      "Epoch 203 | train: Loss 0.347415 Accuracy 0.88 | validation: Loss 0.346566 Accuracy 0.88\n",
      "Epoch 204 | train: Loss 0.338261 Accuracy 0.88 | validation: Loss 0.348213 Accuracy 0.88\n",
      "Epoch 205 | train: Loss 0.336130 Accuracy 0.88 | validation: Loss 0.349492 Accuracy 0.86\n",
      "Epoch 206 | train: Loss 0.335462 Accuracy 0.88 | validation: Loss 0.344729 Accuracy 0.89\n",
      "Epoch 207 | train: Loss 0.336181 Accuracy 0.88 | validation: Loss 0.352053 Accuracy 0.87\n",
      "Epoch 208 | train: Loss 0.331266 Accuracy 0.89 | validation: Loss 0.343900 Accuracy 0.88\n",
      "Epoch 209 | train: Loss 0.332342 Accuracy 0.89 | validation: Loss 0.356737 Accuracy 0.87\n",
      "Epoch 210 | train: Loss 0.334392 Accuracy 0.88 | validation: Loss 0.345622 Accuracy 0.87\n",
      "Epoch 211 | train: Loss 0.332287 Accuracy 0.89 | validation: Loss 0.341389 Accuracy 0.87\n",
      "Epoch 212 | train: Loss 0.328317 Accuracy 0.89 | validation: Loss 0.339043 Accuracy 0.87\n",
      "Epoch 213 | train: Loss 0.328341 Accuracy 0.88 | validation: Loss 0.338837 Accuracy 0.87\n",
      "Epoch 214 | train: Loss 0.328864 Accuracy 0.88 | validation: Loss 0.330155 Accuracy 0.88\n",
      "Epoch 215 | train: Loss 0.325545 Accuracy 0.89 | validation: Loss 0.329603 Accuracy 0.89\n",
      "Epoch 216 | train: Loss 0.324789 Accuracy 0.89 | validation: Loss 0.327159 Accuracy 0.88\n",
      "Epoch 217 | train: Loss 0.325475 Accuracy 0.89 | validation: Loss 0.343422 Accuracy 0.88\n",
      "Epoch 218 | train: Loss 0.322257 Accuracy 0.89 | validation: Loss 0.346967 Accuracy 0.87\n",
      "Epoch 219 | train: Loss 0.321889 Accuracy 0.89 | validation: Loss 0.332222 Accuracy 0.88\n",
      "Epoch 220 | train: Loss 0.319267 Accuracy 0.88 | validation: Loss 0.327717 Accuracy 0.89\n",
      "Epoch 221 | train: Loss 0.321842 Accuracy 0.89 | validation: Loss 0.341397 Accuracy 0.88\n",
      "Epoch 222 | train: Loss 0.318900 Accuracy 0.89 | validation: Loss 0.326056 Accuracy 0.88\n",
      "Epoch 223 | train: Loss 0.318535 Accuracy 0.89 | validation: Loss 0.332342 Accuracy 0.89\n",
      "Epoch 224 | train: Loss 0.317381 Accuracy 0.89 | validation: Loss 0.317346 Accuracy 0.89\n",
      "Epoch 225 | train: Loss 0.312445 Accuracy 0.89 | validation: Loss 0.313868 Accuracy 0.90\n",
      "Epoch 226 | train: Loss 0.315829 Accuracy 0.89 | validation: Loss 0.345417 Accuracy 0.87\n",
      "Epoch 227 | train: Loss 0.314513 Accuracy 0.89 | validation: Loss 0.338560 Accuracy 0.85\n",
      "Epoch 228 | train: Loss 0.312808 Accuracy 0.89 | validation: Loss 0.319744 Accuracy 0.90\n",
      "Epoch 229 | train: Loss 0.313076 Accuracy 0.89 | validation: Loss 0.314789 Accuracy 0.89\n",
      "Epoch 230 | train: Loss 0.310763 Accuracy 0.89 | validation: Loss 0.308993 Accuracy 0.90\n",
      "Epoch 231 | train: Loss 0.309371 Accuracy 0.89 | validation: Loss 0.322061 Accuracy 0.89\n",
      "Epoch 232 | train: Loss 0.309068 Accuracy 0.89 | validation: Loss 0.318790 Accuracy 0.89\n",
      "Epoch 233 | train: Loss 0.308645 Accuracy 0.89 | validation: Loss 0.305059 Accuracy 0.91\n",
      "Epoch 234 | train: Loss 0.307304 Accuracy 0.89 | validation: Loss 0.321795 Accuracy 0.90\n",
      "Epoch 235 | train: Loss 0.304562 Accuracy 0.89 | validation: Loss 0.311868 Accuracy 0.89\n",
      "Epoch 236 | train: Loss 0.304523 Accuracy 0.89 | validation: Loss 0.321460 Accuracy 0.88\n",
      "Epoch 237 | train: Loss 0.302625 Accuracy 0.90 | validation: Loss 0.308588 Accuracy 0.88\n",
      "Epoch 238 | train: Loss 0.299344 Accuracy 0.90 | validation: Loss 0.305332 Accuracy 0.90\n",
      "Epoch 239 | train: Loss 0.305674 Accuracy 0.89 | validation: Loss 0.303903 Accuracy 0.90\n",
      "Epoch 240 | train: Loss 0.305932 Accuracy 0.89 | validation: Loss 0.301926 Accuracy 0.89\n",
      "Epoch 241 | train: Loss 0.297966 Accuracy 0.90 | validation: Loss 0.307889 Accuracy 0.89\n",
      "Epoch 242 | train: Loss 0.306947 Accuracy 0.89 | validation: Loss 0.302777 Accuracy 0.91\n",
      "Epoch 243 | train: Loss 0.299167 Accuracy 0.89 | validation: Loss 0.303311 Accuracy 0.90\n",
      "Epoch 244 | train: Loss 0.292272 Accuracy 0.90 | validation: Loss 0.304009 Accuracy 0.91\n",
      "Epoch 245 | train: Loss 0.296277 Accuracy 0.90 | validation: Loss 0.328856 Accuracy 0.87\n",
      "Epoch 246 | train: Loss 0.295577 Accuracy 0.89 | validation: Loss 0.298420 Accuracy 0.89\n",
      "Epoch 247 | train: Loss 0.289695 Accuracy 0.90 | validation: Loss 0.319914 Accuracy 0.89\n",
      "Epoch 248 | train: Loss 0.297698 Accuracy 0.89 | validation: Loss 0.330386 Accuracy 0.88\n",
      "Epoch 249 | train: Loss 0.298616 Accuracy 0.89 | validation: Loss 0.340968 Accuracy 0.87\n",
      "Epoch 250 | train: Loss 0.293636 Accuracy 0.90 | validation: Loss 0.315843 Accuracy 0.89\n",
      "Epoch 251 | train: Loss 0.287530 Accuracy 0.90 | validation: Loss 0.300059 Accuracy 0.90\n",
      "Epoch 252 | train: Loss 0.295828 Accuracy 0.89 | validation: Loss 0.302871 Accuracy 0.89\n",
      "Epoch 253 | train: Loss 0.291552 Accuracy 0.89 | validation: Loss 0.294455 Accuracy 0.89\n",
      "Epoch 254 | train: Loss 0.287242 Accuracy 0.90 | validation: Loss 0.287701 Accuracy 0.90\n",
      "Epoch 255 | train: Loss 0.288039 Accuracy 0.90 | validation: Loss 0.306954 Accuracy 0.89\n",
      "Epoch 256 | train: Loss 0.286583 Accuracy 0.90 | validation: Loss 0.301925 Accuracy 0.91\n",
      "Epoch 257 | train: Loss 0.285949 Accuracy 0.90 | validation: Loss 0.295007 Accuracy 0.89\n",
      "Epoch 258 | train: Loss 0.284516 Accuracy 0.90 | validation: Loss 0.283078 Accuracy 0.92\n",
      "Epoch 259 | train: Loss 0.281560 Accuracy 0.90 | validation: Loss 0.282741 Accuracy 0.92\n",
      "Epoch 260 | train: Loss 0.286303 Accuracy 0.90 | validation: Loss 0.286794 Accuracy 0.90\n",
      "Epoch 261 | train: Loss 0.285046 Accuracy 0.90 | validation: Loss 0.289760 Accuracy 0.90\n",
      "Epoch 262 | train: Loss 0.281884 Accuracy 0.90 | validation: Loss 0.282280 Accuracy 0.91\n",
      "Epoch 263 | train: Loss 0.275429 Accuracy 0.90 | validation: Loss 0.298413 Accuracy 0.89\n",
      "Epoch 264 | train: Loss 0.281696 Accuracy 0.90 | validation: Loss 0.275151 Accuracy 0.92\n",
      "Epoch 265 | train: Loss 0.277532 Accuracy 0.90 | validation: Loss 0.283007 Accuracy 0.90\n",
      "Epoch 266 | train: Loss 0.275489 Accuracy 0.90 | validation: Loss 0.296941 Accuracy 0.88\n",
      "Epoch 267 | train: Loss 0.276857 Accuracy 0.90 | validation: Loss 0.284111 Accuracy 0.90\n",
      "Epoch 268 | train: Loss 0.278191 Accuracy 0.90 | validation: Loss 0.283592 Accuracy 0.90\n",
      "Epoch 269 | train: Loss 0.274152 Accuracy 0.90 | validation: Loss 0.285690 Accuracy 0.89\n",
      "Epoch 270 | train: Loss 0.280634 Accuracy 0.89 | validation: Loss 0.309551 Accuracy 0.87\n",
      "Epoch 271 | train: Loss 0.275176 Accuracy 0.90 | validation: Loss 0.291976 Accuracy 0.89\n",
      "Epoch 272 | train: Loss 0.273847 Accuracy 0.90 | validation: Loss 0.316400 Accuracy 0.88\n",
      "Epoch 273 | train: Loss 0.275850 Accuracy 0.90 | validation: Loss 0.284383 Accuracy 0.90\n",
      "Epoch 274 | train: Loss 0.268953 Accuracy 0.91 | validation: Loss 0.277572 Accuracy 0.90\n",
      "Early_Stop_at_ 274 Epoch\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "model0 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(), lr=0.0001)\n",
    "\n",
    "model0_results = engine.train(model=model0,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              early_stop_patience=10,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127ac94d7bb26bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T19:48:00.955527500Z",
     "start_time": "2023-12-24T19:46:58.741558900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] create SummaryWriter saving to runs\\2023-12-24-23\\luzern\\Neural_Net\\20epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db023c0739d4fe9a19f2854c38892c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 7.770748 Accuracy 0.51 | validation: Loss 1.463997 Accuracy 0.53\n",
      "Epoch 1 | train: Loss 1.399654 Accuracy 0.52 | validation: Loss 1.359263 Accuracy 0.52\n",
      "Epoch 2 | train: Loss 1.339121 Accuracy 0.55 | validation: Loss 1.321238 Accuracy 0.51\n",
      "Epoch 3 | train: Loss 1.281425 Accuracy 0.57 | validation: Loss 1.238373 Accuracy 0.56\n",
      "Epoch 4 | train: Loss 1.193089 Accuracy 0.61 | validation: Loss 1.167704 Accuracy 0.61\n",
      "Epoch 5 | train: Loss 1.130246 Accuracy 0.62 | validation: Loss 1.107890 Accuracy 0.62\n",
      "Epoch 6 | train: Loss 1.096060 Accuracy 0.61 | validation: Loss 1.086527 Accuracy 0.62\n",
      "Epoch 7 | train: Loss 1.060004 Accuracy 0.62 | validation: Loss 1.040833 Accuracy 0.62\n",
      "Epoch 8 | train: Loss 1.027882 Accuracy 0.62 | validation: Loss 1.006603 Accuracy 0.64\n",
      "Epoch 9 | train: Loss 1.004187 Accuracy 0.63 | validation: Loss 0.994309 Accuracy 0.64\n",
      "Epoch 10 | train: Loss 0.989944 Accuracy 0.63 | validation: Loss 0.994836 Accuracy 0.63\n",
      "Epoch 11 | train: Loss 0.980709 Accuracy 0.63 | validation: Loss 0.971572 Accuracy 0.61\n",
      "Epoch 12 | train: Loss 0.968566 Accuracy 0.64 | validation: Loss 0.970568 Accuracy 0.61\n",
      "Epoch 13 | train: Loss 0.954615 Accuracy 0.63 | validation: Loss 0.945129 Accuracy 0.64\n",
      "Epoch 14 | train: Loss 0.943479 Accuracy 0.64 | validation: Loss 0.949176 Accuracy 0.66\n",
      "Epoch 15 | train: Loss 0.932791 Accuracy 0.65 | validation: Loss 0.929461 Accuracy 0.64\n",
      "Epoch 16 | train: Loss 0.923877 Accuracy 0.64 | validation: Loss 0.916025 Accuracy 0.64\n",
      "Epoch 17 | train: Loss 0.913651 Accuracy 0.65 | validation: Loss 0.917875 Accuracy 0.64\n",
      "Epoch 18 | train: Loss 0.912577 Accuracy 0.64 | validation: Loss 0.931566 Accuracy 0.61\n",
      "Epoch 19 | train: Loss 0.895737 Accuracy 0.66 | validation: Loss 0.905442 Accuracy 0.64\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 32\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 32\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "model1 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model1.parameters(), lr=0.0001)\n",
    "\n",
    "model1_results = engine.train(model=model1,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              experiment_name=\"luzern\",\n",
    "                              model_name=\"Neural_Net\",\n",
    "                              early_stop_patience=None,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571334e71b9628e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] create SummaryWriter saving to runs\\2023-12-24-23\\luzern_V0\\Neural_Net\\500epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fd25e04e8340ed80baa927e0593071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 3.876857 Accuracy 0.30 | validation: Loss 1.556792 Accuracy 0.36\n",
      "Epoch 1 | train: Loss 1.414394 Accuracy 0.45 | validation: Loss 1.381815 Accuracy 0.45\n",
      "Epoch 2 | train: Loss 1.348989 Accuracy 0.48 | validation: Loss 1.321669 Accuracy 0.51\n",
      "Epoch 3 | train: Loss 1.300869 Accuracy 0.53 | validation: Loss 1.280636 Accuracy 0.55\n",
      "Epoch 4 | train: Loss 1.261051 Accuracy 0.55 | validation: Loss 1.241374 Accuracy 0.56\n",
      "Epoch 5 | train: Loss 1.228816 Accuracy 0.57 | validation: Loss 1.220952 Accuracy 0.56\n",
      "Epoch 6 | train: Loss 1.193593 Accuracy 0.59 | validation: Loss 1.178762 Accuracy 0.60\n",
      "Epoch 7 | train: Loss 1.168743 Accuracy 0.60 | validation: Loss 1.160066 Accuracy 0.57\n",
      "Epoch 8 | train: Loss 1.136830 Accuracy 0.60 | validation: Loss 1.115764 Accuracy 0.62\n",
      "Epoch 9 | train: Loss 1.107547 Accuracy 0.62 | validation: Loss 1.092079 Accuracy 0.62\n",
      "Epoch 10 | train: Loss 1.083820 Accuracy 0.62 | validation: Loss 1.058507 Accuracy 0.61\n",
      "Epoch 11 | train: Loss 1.062855 Accuracy 0.62 | validation: Loss 1.046916 Accuracy 0.63\n",
      "Epoch 12 | train: Loss 1.044801 Accuracy 0.63 | validation: Loss 1.048737 Accuracy 0.62\n",
      "Epoch 13 | train: Loss 1.038858 Accuracy 0.62 | validation: Loss 1.038911 Accuracy 0.61\n",
      "Epoch 14 | train: Loss 1.023367 Accuracy 0.63 | validation: Loss 1.015831 Accuracy 0.62\n",
      "Epoch 15 | train: Loss 1.017173 Accuracy 0.64 | validation: Loss 0.998556 Accuracy 0.65\n",
      "Epoch 16 | train: Loss 1.003399 Accuracy 0.64 | validation: Loss 0.987078 Accuracy 0.65\n",
      "Epoch 17 | train: Loss 0.997764 Accuracy 0.64 | validation: Loss 0.999785 Accuracy 0.63\n",
      "Epoch 18 | train: Loss 0.998883 Accuracy 0.63 | validation: Loss 1.016878 Accuracy 0.62\n",
      "Epoch 19 | train: Loss 0.985047 Accuracy 0.64 | validation: Loss 0.972405 Accuracy 0.64\n",
      "Epoch 20 | train: Loss 0.974064 Accuracy 0.64 | validation: Loss 0.963166 Accuracy 0.63\n",
      "Epoch 21 | train: Loss 0.968803 Accuracy 0.64 | validation: Loss 0.971102 Accuracy 0.64\n",
      "Epoch 22 | train: Loss 0.963336 Accuracy 0.64 | validation: Loss 0.949803 Accuracy 0.65\n",
      "Epoch 23 | train: Loss 0.956807 Accuracy 0.64 | validation: Loss 0.976924 Accuracy 0.60\n",
      "Epoch 24 | train: Loss 0.947555 Accuracy 0.64 | validation: Loss 0.938279 Accuracy 0.65\n",
      "Epoch 25 | train: Loss 0.938958 Accuracy 0.65 | validation: Loss 0.941757 Accuracy 0.65\n",
      "Epoch 26 | train: Loss 0.930285 Accuracy 0.66 | validation: Loss 0.948416 Accuracy 0.65\n",
      "Epoch 27 | train: Loss 0.926858 Accuracy 0.65 | validation: Loss 0.953349 Accuracy 0.61\n",
      "Epoch 28 | train: Loss 0.926055 Accuracy 0.65 | validation: Loss 0.918128 Accuracy 0.65\n",
      "Epoch 29 | train: Loss 0.913901 Accuracy 0.66 | validation: Loss 0.899385 Accuracy 0.68\n",
      "Epoch 30 | train: Loss 0.908351 Accuracy 0.66 | validation: Loss 0.904092 Accuracy 0.65\n",
      "Epoch 31 | train: Loss 0.915568 Accuracy 0.64 | validation: Loss 0.909365 Accuracy 0.64\n",
      "Epoch 32 | train: Loss 0.903635 Accuracy 0.66 | validation: Loss 0.891791 Accuracy 0.66\n",
      "Epoch 33 | train: Loss 0.891461 Accuracy 0.66 | validation: Loss 0.883303 Accuracy 0.66\n",
      "Epoch 34 | train: Loss 0.886497 Accuracy 0.66 | validation: Loss 0.871794 Accuracy 0.67\n",
      "Epoch 35 | train: Loss 0.883316 Accuracy 0.66 | validation: Loss 0.882102 Accuracy 0.66\n",
      "Epoch 36 | train: Loss 0.885194 Accuracy 0.66 | validation: Loss 0.871692 Accuracy 0.65\n",
      "Epoch 37 | train: Loss 0.872252 Accuracy 0.67 | validation: Loss 0.879507 Accuracy 0.65\n",
      "Epoch 38 | train: Loss 0.865721 Accuracy 0.67 | validation: Loss 0.854662 Accuracy 0.68\n",
      "Epoch 39 | train: Loss 0.863849 Accuracy 0.67 | validation: Loss 0.852232 Accuracy 0.66\n",
      "Epoch 40 | train: Loss 0.853739 Accuracy 0.67 | validation: Loss 0.850874 Accuracy 0.68\n",
      "Epoch 41 | train: Loss 0.853240 Accuracy 0.67 | validation: Loss 0.867724 Accuracy 0.66\n",
      "Epoch 42 | train: Loss 0.846486 Accuracy 0.67 | validation: Loss 0.838688 Accuracy 0.67\n",
      "Epoch 43 | train: Loss 0.839194 Accuracy 0.68 | validation: Loss 0.835264 Accuracy 0.70\n",
      "Epoch 44 | train: Loss 0.836983 Accuracy 0.68 | validation: Loss 0.831703 Accuracy 0.67\n",
      "Epoch 45 | train: Loss 0.833620 Accuracy 0.68 | validation: Loss 0.818513 Accuracy 0.67\n",
      "Epoch 46 | train: Loss 0.832059 Accuracy 0.67 | validation: Loss 0.823759 Accuracy 0.69\n",
      "Epoch 47 | train: Loss 0.819347 Accuracy 0.68 | validation: Loss 0.838575 Accuracy 0.66\n",
      "Epoch 48 | train: Loss 0.821003 Accuracy 0.68 | validation: Loss 0.819700 Accuracy 0.70\n",
      "Epoch 49 | train: Loss 0.813097 Accuracy 0.68 | validation: Loss 0.800263 Accuracy 0.69\n",
      "Epoch 50 | train: Loss 0.804085 Accuracy 0.69 | validation: Loss 0.804919 Accuracy 0.67\n",
      "Epoch 51 | train: Loss 0.804133 Accuracy 0.69 | validation: Loss 0.798528 Accuracy 0.68\n",
      "Epoch 52 | train: Loss 0.794143 Accuracy 0.70 | validation: Loss 0.795558 Accuracy 0.71\n",
      "Epoch 53 | train: Loss 0.796435 Accuracy 0.68 | validation: Loss 0.809574 Accuracy 0.69\n",
      "Epoch 54 | train: Loss 0.789829 Accuracy 0.70 | validation: Loss 0.787223 Accuracy 0.68\n",
      "Epoch 55 | train: Loss 0.784643 Accuracy 0.70 | validation: Loss 0.781530 Accuracy 0.69\n",
      "Epoch 56 | train: Loss 0.777227 Accuracy 0.70 | validation: Loss 0.780031 Accuracy 0.69\n",
      "Epoch 57 | train: Loss 0.778327 Accuracy 0.70 | validation: Loss 0.796154 Accuracy 0.67\n",
      "Epoch 58 | train: Loss 0.777127 Accuracy 0.70 | validation: Loss 0.756710 Accuracy 0.72\n",
      "Epoch 59 | train: Loss 0.770429 Accuracy 0.70 | validation: Loss 0.768300 Accuracy 0.69\n",
      "Epoch 60 | train: Loss 0.765768 Accuracy 0.70 | validation: Loss 0.779893 Accuracy 0.68\n",
      "Epoch 61 | train: Loss 0.764207 Accuracy 0.71 | validation: Loss 0.766008 Accuracy 0.72\n",
      "Epoch 62 | train: Loss 0.761226 Accuracy 0.71 | validation: Loss 0.763152 Accuracy 0.71\n",
      "Epoch 63 | train: Loss 0.755245 Accuracy 0.71 | validation: Loss 0.749535 Accuracy 0.71\n",
      "Epoch 64 | train: Loss 0.749767 Accuracy 0.72 | validation: Loss 0.766685 Accuracy 0.69\n",
      "Epoch 65 | train: Loss 0.747193 Accuracy 0.71 | validation: Loss 0.750288 Accuracy 0.73\n",
      "Epoch 66 | train: Loss 0.752152 Accuracy 0.71 | validation: Loss 0.753567 Accuracy 0.72\n",
      "Epoch 67 | train: Loss 0.741941 Accuracy 0.72 | validation: Loss 0.747510 Accuracy 0.70\n",
      "Epoch 68 | train: Loss 0.735749 Accuracy 0.72 | validation: Loss 0.742711 Accuracy 0.71\n",
      "Epoch 69 | train: Loss 0.733350 Accuracy 0.72 | validation: Loss 0.754609 Accuracy 0.69\n",
      "Epoch 70 | train: Loss 0.732582 Accuracy 0.72 | validation: Loss 0.725551 Accuracy 0.73\n",
      "Epoch 71 | train: Loss 0.724374 Accuracy 0.72 | validation: Loss 0.722148 Accuracy 0.76\n",
      "Epoch 72 | train: Loss 0.727232 Accuracy 0.72 | validation: Loss 0.719122 Accuracy 0.74\n",
      "Epoch 73 | train: Loss 0.721936 Accuracy 0.72 | validation: Loss 0.753216 Accuracy 0.65\n",
      "Epoch 74 | train: Loss 0.719548 Accuracy 0.72 | validation: Loss 0.700901 Accuracy 0.76\n",
      "Epoch 75 | train: Loss 0.716251 Accuracy 0.72 | validation: Loss 0.722545 Accuracy 0.75\n",
      "Epoch 76 | train: Loss 0.713376 Accuracy 0.73 | validation: Loss 0.706243 Accuracy 0.76\n",
      "Epoch 77 | train: Loss 0.709264 Accuracy 0.74 | validation: Loss 0.711191 Accuracy 0.75\n",
      "Epoch 78 | train: Loss 0.702974 Accuracy 0.73 | validation: Loss 0.712643 Accuracy 0.75\n",
      "Epoch 79 | train: Loss 0.701102 Accuracy 0.74 | validation: Loss 0.701851 Accuracy 0.74\n",
      "Epoch 80 | train: Loss 0.697767 Accuracy 0.73 | validation: Loss 0.688841 Accuracy 0.76\n",
      "Epoch 81 | train: Loss 0.691316 Accuracy 0.75 | validation: Loss 0.704740 Accuracy 0.74\n",
      "Epoch 82 | train: Loss 0.694950 Accuracy 0.74 | validation: Loss 0.689122 Accuracy 0.75\n",
      "Epoch 83 | train: Loss 0.687552 Accuracy 0.75 | validation: Loss 0.686768 Accuracy 0.76\n",
      "Epoch 84 | train: Loss 0.686291 Accuracy 0.75 | validation: Loss 0.732790 Accuracy 0.71\n",
      "Epoch 85 | train: Loss 0.686685 Accuracy 0.75 | validation: Loss 0.684288 Accuracy 0.77\n",
      "Epoch 86 | train: Loss 0.681148 Accuracy 0.75 | validation: Loss 0.682708 Accuracy 0.74\n",
      "Epoch 87 | train: Loss 0.678964 Accuracy 0.74 | validation: Loss 0.683181 Accuracy 0.73\n",
      "Epoch 88 | train: Loss 0.681279 Accuracy 0.73 | validation: Loss 0.677932 Accuracy 0.74\n",
      "Epoch 89 | train: Loss 0.672783 Accuracy 0.75 | validation: Loss 0.675664 Accuracy 0.75\n",
      "Epoch 90 | train: Loss 0.667347 Accuracy 0.76 | validation: Loss 0.687195 Accuracy 0.70\n",
      "Epoch 91 | train: Loss 0.664437 Accuracy 0.75 | validation: Loss 0.657746 Accuracy 0.78\n",
      "Epoch 92 | train: Loss 0.665532 Accuracy 0.75 | validation: Loss 0.667544 Accuracy 0.77\n",
      "Epoch 93 | train: Loss 0.660161 Accuracy 0.76 | validation: Loss 0.645864 Accuracy 0.77\n",
      "Epoch 94 | train: Loss 0.657122 Accuracy 0.76 | validation: Loss 0.646694 Accuracy 0.77\n",
      "Epoch 95 | train: Loss 0.654480 Accuracy 0.76 | validation: Loss 0.653338 Accuracy 0.79\n",
      "Epoch 96 | train: Loss 0.658514 Accuracy 0.75 | validation: Loss 0.664294 Accuracy 0.75\n",
      "Epoch 97 | train: Loss 0.653782 Accuracy 0.76 | validation: Loss 0.657365 Accuracy 0.76\n",
      "Epoch 98 | train: Loss 0.642961 Accuracy 0.77 | validation: Loss 0.654390 Accuracy 0.76\n",
      "Epoch 99 | train: Loss 0.646816 Accuracy 0.76 | validation: Loss 0.664026 Accuracy 0.75\n",
      "Epoch 100 | train: Loss 0.646487 Accuracy 0.76 | validation: Loss 0.648201 Accuracy 0.76\n",
      "Epoch 101 | train: Loss 0.646464 Accuracy 0.75 | validation: Loss 0.649728 Accuracy 0.76\n",
      "Epoch 102 | train: Loss 0.635170 Accuracy 0.77 | validation: Loss 0.637824 Accuracy 0.78\n",
      "Epoch 103 | train: Loss 0.635979 Accuracy 0.76 | validation: Loss 0.656215 Accuracy 0.72\n",
      "Epoch 104 | train: Loss 0.636629 Accuracy 0.77 | validation: Loss 0.651254 Accuracy 0.79\n",
      "Epoch 105 | train: Loss 0.630462 Accuracy 0.77 | validation: Loss 0.628421 Accuracy 0.78\n",
      "Epoch 106 | train: Loss 0.627345 Accuracy 0.76 | validation: Loss 0.629246 Accuracy 0.76\n",
      "Epoch 107 | train: Loss 0.629422 Accuracy 0.76 | validation: Loss 0.629884 Accuracy 0.80\n",
      "Epoch 108 | train: Loss 0.620346 Accuracy 0.77 | validation: Loss 0.641356 Accuracy 0.74\n",
      "Epoch 109 | train: Loss 0.635749 Accuracy 0.75 | validation: Loss 0.628272 Accuracy 0.78\n",
      "Epoch 110 | train: Loss 0.620146 Accuracy 0.78 | validation: Loss 0.612100 Accuracy 0.79\n",
      "Epoch 111 | train: Loss 0.624378 Accuracy 0.76 | validation: Loss 0.620567 Accuracy 0.78\n",
      "Epoch 112 | train: Loss 0.619766 Accuracy 0.78 | validation: Loss 0.638530 Accuracy 0.74\n",
      "Epoch 113 | train: Loss 0.613302 Accuracy 0.78 | validation: Loss 0.619498 Accuracy 0.79\n",
      "Epoch 114 | train: Loss 0.610501 Accuracy 0.78 | validation: Loss 0.611159 Accuracy 0.80\n",
      "Epoch 115 | train: Loss 0.612861 Accuracy 0.78 | validation: Loss 0.618526 Accuracy 0.77\n",
      "Epoch 116 | train: Loss 0.604897 Accuracy 0.78 | validation: Loss 0.624833 Accuracy 0.77\n",
      "Epoch 117 | train: Loss 0.605969 Accuracy 0.77 | validation: Loss 0.616669 Accuracy 0.78\n",
      "Epoch 118 | train: Loss 0.605491 Accuracy 0.78 | validation: Loss 0.594265 Accuracy 0.80\n",
      "Epoch 119 | train: Loss 0.599829 Accuracy 0.78 | validation: Loss 0.596876 Accuracy 0.79\n",
      "Epoch 120 | train: Loss 0.597653 Accuracy 0.78 | validation: Loss 0.600102 Accuracy 0.81\n",
      "Epoch 121 | train: Loss 0.601574 Accuracy 0.78 | validation: Loss 0.614659 Accuracy 0.76\n",
      "Epoch 122 | train: Loss 0.605864 Accuracy 0.77 | validation: Loss 0.598636 Accuracy 0.80\n",
      "Epoch 123 | train: Loss 0.590119 Accuracy 0.78 | validation: Loss 0.594487 Accuracy 0.80\n",
      "Epoch 124 | train: Loss 0.596045 Accuracy 0.77 | validation: Loss 0.593750 Accuracy 0.78\n",
      "Epoch 125 | train: Loss 0.598978 Accuracy 0.77 | validation: Loss 0.597842 Accuracy 0.79\n",
      "Epoch 126 | train: Loss 0.589481 Accuracy 0.79 | validation: Loss 0.593768 Accuracy 0.78\n",
      "Epoch 127 | train: Loss 0.595952 Accuracy 0.77 | validation: Loss 0.609406 Accuracy 0.77\n",
      "Epoch 128 | train: Loss 0.589791 Accuracy 0.78 | validation: Loss 0.587081 Accuracy 0.77\n",
      "Epoch 129 | train: Loss 0.582494 Accuracy 0.78 | validation: Loss 0.588813 Accuracy 0.81\n",
      "Epoch 130 | train: Loss 0.584903 Accuracy 0.78 | validation: Loss 0.598993 Accuracy 0.77\n",
      "Epoch 131 | train: Loss 0.584467 Accuracy 0.78 | validation: Loss 0.586681 Accuracy 0.79\n",
      "Epoch 132 | train: Loss 0.574981 Accuracy 0.79 | validation: Loss 0.576108 Accuracy 0.80\n",
      "Epoch 133 | train: Loss 0.577362 Accuracy 0.79 | validation: Loss 0.584653 Accuracy 0.78\n",
      "Epoch 134 | train: Loss 0.574473 Accuracy 0.79 | validation: Loss 0.574494 Accuracy 0.80\n",
      "Epoch 135 | train: Loss 0.569991 Accuracy 0.79 | validation: Loss 0.582216 Accuracy 0.78\n",
      "Epoch 136 | train: Loss 0.574292 Accuracy 0.78 | validation: Loss 0.568434 Accuracy 0.81\n",
      "Epoch 137 | train: Loss 0.568316 Accuracy 0.79 | validation: Loss 0.561066 Accuracy 0.81\n",
      "Epoch 138 | train: Loss 0.566213 Accuracy 0.79 | validation: Loss 0.569791 Accuracy 0.80\n",
      "Epoch 139 | train: Loss 0.566197 Accuracy 0.79 | validation: Loss 0.574908 Accuracy 0.80\n",
      "Epoch 140 | train: Loss 0.565214 Accuracy 0.80 | validation: Loss 0.584645 Accuracy 0.82\n",
      "Epoch 141 | train: Loss 0.570590 Accuracy 0.79 | validation: Loss 0.569212 Accuracy 0.78\n",
      "Epoch 142 | train: Loss 0.559909 Accuracy 0.79 | validation: Loss 0.575304 Accuracy 0.78\n",
      "Epoch 143 | train: Loss 0.566931 Accuracy 0.79 | validation: Loss 0.560939 Accuracy 0.78\n",
      "Epoch 144 | train: Loss 0.566210 Accuracy 0.78 | validation: Loss 0.560600 Accuracy 0.83\n",
      "Epoch 145 | train: Loss 0.553338 Accuracy 0.79 | validation: Loss 0.560845 Accuracy 0.82\n",
      "Epoch 146 | train: Loss 0.557336 Accuracy 0.79 | validation: Loss 0.542617 Accuracy 0.81\n",
      "Epoch 147 | train: Loss 0.557706 Accuracy 0.79 | validation: Loss 0.553489 Accuracy 0.80\n",
      "Epoch 148 | train: Loss 0.553510 Accuracy 0.80 | validation: Loss 0.563933 Accuracy 0.77\n",
      "Epoch 149 | train: Loss 0.560614 Accuracy 0.79 | validation: Loss 0.549716 Accuracy 0.82\n",
      "Epoch 150 | train: Loss 0.553221 Accuracy 0.80 | validation: Loss 0.549645 Accuracy 0.82\n",
      "Epoch 151 | train: Loss 0.546723 Accuracy 0.80 | validation: Loss 0.542049 Accuracy 0.80\n",
      "Epoch 152 | train: Loss 0.547338 Accuracy 0.80 | validation: Loss 0.550931 Accuracy 0.81\n",
      "Epoch 153 | train: Loss 0.545608 Accuracy 0.80 | validation: Loss 0.557314 Accuracy 0.79\n",
      "Epoch 154 | train: Loss 0.548116 Accuracy 0.80 | validation: Loss 0.540777 Accuracy 0.83\n",
      "Epoch 155 | train: Loss 0.546136 Accuracy 0.80 | validation: Loss 0.534333 Accuracy 0.81\n",
      "Epoch 156 | train: Loss 0.540134 Accuracy 0.81 | validation: Loss 0.558433 Accuracy 0.81\n",
      "Epoch 157 | train: Loss 0.538810 Accuracy 0.80 | validation: Loss 0.543211 Accuracy 0.81\n",
      "Epoch 158 | train: Loss 0.539479 Accuracy 0.80 | validation: Loss 0.532284 Accuracy 0.81\n",
      "Epoch 159 | train: Loss 0.546068 Accuracy 0.80 | validation: Loss 0.548399 Accuracy 0.78\n",
      "Epoch 160 | train: Loss 0.529508 Accuracy 0.80 | validation: Loss 0.539572 Accuracy 0.82\n",
      "Epoch 161 | train: Loss 0.535770 Accuracy 0.80 | validation: Loss 0.537576 Accuracy 0.82\n",
      "Epoch 162 | train: Loss 0.547680 Accuracy 0.78 | validation: Loss 0.522326 Accuracy 0.84\n",
      "Epoch 163 | train: Loss 0.530235 Accuracy 0.81 | validation: Loss 0.536501 Accuracy 0.81\n",
      "Epoch 164 | train: Loss 0.531006 Accuracy 0.80 | validation: Loss 0.546448 Accuracy 0.80\n",
      "Epoch 165 | train: Loss 0.533567 Accuracy 0.80 | validation: Loss 0.536857 Accuracy 0.82\n",
      "Epoch 166 | train: Loss 0.528929 Accuracy 0.80 | validation: Loss 0.533889 Accuracy 0.78\n",
      "Epoch 167 | train: Loss 0.531454 Accuracy 0.80 | validation: Loss 0.577330 Accuracy 0.78\n",
      "Epoch 168 | train: Loss 0.529309 Accuracy 0.80 | validation: Loss 0.527561 Accuracy 0.79\n",
      "Epoch 169 | train: Loss 0.523729 Accuracy 0.80 | validation: Loss 0.521427 Accuracy 0.82\n",
      "Epoch 170 | train: Loss 0.529360 Accuracy 0.79 | validation: Loss 0.555471 Accuracy 0.78\n",
      "Epoch 171 | train: Loss 0.520781 Accuracy 0.80 | validation: Loss 0.523488 Accuracy 0.82\n",
      "Epoch 172 | train: Loss 0.516027 Accuracy 0.81 | validation: Loss 0.526994 Accuracy 0.82\n",
      "Epoch 173 | train: Loss 0.518697 Accuracy 0.81 | validation: Loss 0.524148 Accuracy 0.79\n",
      "Epoch 174 | train: Loss 0.515152 Accuracy 0.81 | validation: Loss 0.537655 Accuracy 0.80\n",
      "Epoch 175 | train: Loss 0.516724 Accuracy 0.81 | validation: Loss 0.513977 Accuracy 0.84\n",
      "Epoch 176 | train: Loss 0.513186 Accuracy 0.81 | validation: Loss 0.508234 Accuracy 0.82\n",
      "Epoch 177 | train: Loss 0.507881 Accuracy 0.82 | validation: Loss 0.520914 Accuracy 0.83\n",
      "Epoch 178 | train: Loss 0.513082 Accuracy 0.81 | validation: Loss 0.514346 Accuracy 0.82\n",
      "Epoch 179 | train: Loss 0.510593 Accuracy 0.81 | validation: Loss 0.509185 Accuracy 0.81\n",
      "Epoch 180 | train: Loss 0.510358 Accuracy 0.81 | validation: Loss 0.531511 Accuracy 0.79\n",
      "Epoch 181 | train: Loss 0.513395 Accuracy 0.81 | validation: Loss 0.511702 Accuracy 0.82\n",
      "Epoch 182 | train: Loss 0.505347 Accuracy 0.81 | validation: Loss 0.507245 Accuracy 0.81\n",
      "Epoch 183 | train: Loss 0.501801 Accuracy 0.81 | validation: Loss 0.507465 Accuracy 0.82\n",
      "Epoch 184 | train: Loss 0.514079 Accuracy 0.81 | validation: Loss 0.532715 Accuracy 0.83\n",
      "Epoch 185 | train: Loss 0.505860 Accuracy 0.81 | validation: Loss 0.525184 Accuracy 0.78\n",
      "Epoch 186 | train: Loss 0.497676 Accuracy 0.82 | validation: Loss 0.499593 Accuracy 0.81\n",
      "Epoch 187 | train: Loss 0.502486 Accuracy 0.81 | validation: Loss 0.503648 Accuracy 0.82\n",
      "Epoch 188 | train: Loss 0.496238 Accuracy 0.82 | validation: Loss 0.496644 Accuracy 0.81\n",
      "Epoch 189 | train: Loss 0.493861 Accuracy 0.82 | validation: Loss 0.512343 Accuracy 0.80\n",
      "Epoch 190 | train: Loss 0.500257 Accuracy 0.81 | validation: Loss 0.513316 Accuracy 0.81\n",
      "Epoch 191 | train: Loss 0.507905 Accuracy 0.81 | validation: Loss 0.499336 Accuracy 0.82\n",
      "Epoch 192 | train: Loss 0.493338 Accuracy 0.81 | validation: Loss 0.496239 Accuracy 0.82\n",
      "Epoch 193 | train: Loss 0.494130 Accuracy 0.82 | validation: Loss 0.485308 Accuracy 0.83\n",
      "Epoch 194 | train: Loss 0.493995 Accuracy 0.82 | validation: Loss 0.491163 Accuracy 0.82\n",
      "Epoch 195 | train: Loss 0.490995 Accuracy 0.82 | validation: Loss 0.517994 Accuracy 0.82\n",
      "Epoch 196 | train: Loss 0.489574 Accuracy 0.82 | validation: Loss 0.493461 Accuracy 0.83\n",
      "Epoch 197 | train: Loss 0.485136 Accuracy 0.83 | validation: Loss 0.485817 Accuracy 0.83\n",
      "Epoch 198 | train: Loss 0.486841 Accuracy 0.82 | validation: Loss 0.504700 Accuracy 0.81\n",
      "Epoch 199 | train: Loss 0.484320 Accuracy 0.82 | validation: Loss 0.488035 Accuracy 0.83\n",
      "Epoch 200 | train: Loss 0.484633 Accuracy 0.82 | validation: Loss 0.500698 Accuracy 0.81\n",
      "Epoch 201 | train: Loss 0.482665 Accuracy 0.82 | validation: Loss 0.491975 Accuracy 0.82\n",
      "Epoch 202 | train: Loss 0.481769 Accuracy 0.82 | validation: Loss 0.497959 Accuracy 0.82\n",
      "Epoch 203 | train: Loss 0.481643 Accuracy 0.82 | validation: Loss 0.481069 Accuracy 0.84\n",
      "Epoch 204 | train: Loss 0.479913 Accuracy 0.82 | validation: Loss 0.476447 Accuracy 0.82\n",
      "Epoch 205 | train: Loss 0.477136 Accuracy 0.82 | validation: Loss 0.493809 Accuracy 0.81\n",
      "Epoch 206 | train: Loss 0.487068 Accuracy 0.82 | validation: Loss 0.483933 Accuracy 0.82\n",
      "Epoch 207 | train: Loss 0.479150 Accuracy 0.82 | validation: Loss 0.507463 Accuracy 0.82\n",
      "Epoch 208 | train: Loss 0.475051 Accuracy 0.83 | validation: Loss 0.488260 Accuracy 0.82\n",
      "Epoch 209 | train: Loss 0.476779 Accuracy 0.82 | validation: Loss 0.481935 Accuracy 0.83\n",
      "Epoch 210 | train: Loss 0.471338 Accuracy 0.83 | validation: Loss 0.497093 Accuracy 0.80\n",
      "Epoch 211 | train: Loss 0.482666 Accuracy 0.82 | validation: Loss 0.478631 Accuracy 0.82\n",
      "Epoch 212 | train: Loss 0.471045 Accuracy 0.83 | validation: Loss 0.489042 Accuracy 0.81\n",
      "Epoch 213 | train: Loss 0.473675 Accuracy 0.83 | validation: Loss 0.495508 Accuracy 0.83\n",
      "Epoch 214 | train: Loss 0.468488 Accuracy 0.82 | validation: Loss 0.465372 Accuracy 0.84\n",
      "Epoch 215 | train: Loss 0.475025 Accuracy 0.82 | validation: Loss 0.478132 Accuracy 0.82\n",
      "Epoch 216 | train: Loss 0.472137 Accuracy 0.83 | validation: Loss 0.481392 Accuracy 0.82\n",
      "Epoch 217 | train: Loss 0.467033 Accuracy 0.82 | validation: Loss 0.475186 Accuracy 0.83\n",
      "Epoch 218 | train: Loss 0.459596 Accuracy 0.83 | validation: Loss 0.457357 Accuracy 0.85\n",
      "Epoch 219 | train: Loss 0.462971 Accuracy 0.83 | validation: Loss 0.467424 Accuracy 0.84\n",
      "Epoch 220 | train: Loss 0.460296 Accuracy 0.83 | validation: Loss 0.477873 Accuracy 0.85\n",
      "Epoch 221 | train: Loss 0.463470 Accuracy 0.82 | validation: Loss 0.455908 Accuracy 0.84\n",
      "Epoch 222 | train: Loss 0.459026 Accuracy 0.83 | validation: Loss 0.475051 Accuracy 0.84\n",
      "Epoch 223 | train: Loss 0.461819 Accuracy 0.82 | validation: Loss 0.472450 Accuracy 0.82\n",
      "Epoch 224 | train: Loss 0.458219 Accuracy 0.83 | validation: Loss 0.477870 Accuracy 0.81\n",
      "Epoch 225 | train: Loss 0.455569 Accuracy 0.83 | validation: Loss 0.459916 Accuracy 0.82\n",
      "Epoch 226 | train: Loss 0.454668 Accuracy 0.83 | validation: Loss 0.468357 Accuracy 0.83\n",
      "Epoch 227 | train: Loss 0.450451 Accuracy 0.83 | validation: Loss 0.453486 Accuracy 0.83\n",
      "Epoch 228 | train: Loss 0.455448 Accuracy 0.84 | validation: Loss 0.457068 Accuracy 0.84\n",
      "Epoch 229 | train: Loss 0.449002 Accuracy 0.83 | validation: Loss 0.458369 Accuracy 0.86\n",
      "Epoch 230 | train: Loss 0.447093 Accuracy 0.84 | validation: Loss 0.460631 Accuracy 0.82\n",
      "Epoch 231 | train: Loss 0.450496 Accuracy 0.83 | validation: Loss 0.470006 Accuracy 0.83\n",
      "Epoch 232 | train: Loss 0.447876 Accuracy 0.83 | validation: Loss 0.459381 Accuracy 0.82\n",
      "Epoch 233 | train: Loss 0.448592 Accuracy 0.83 | validation: Loss 0.465113 Accuracy 0.82\n",
      "Epoch 234 | train: Loss 0.449650 Accuracy 0.83 | validation: Loss 0.456711 Accuracy 0.83\n",
      "Epoch 235 | train: Loss 0.447995 Accuracy 0.83 | validation: Loss 0.461432 Accuracy 0.84\n",
      "Epoch 236 | train: Loss 0.442230 Accuracy 0.84 | validation: Loss 0.473912 Accuracy 0.82\n",
      "Epoch 237 | train: Loss 0.446989 Accuracy 0.83 | validation: Loss 0.471231 Accuracy 0.87\n",
      "Epoch 238 | train: Loss 0.446072 Accuracy 0.83 | validation: Loss 0.448221 Accuracy 0.84\n",
      "Epoch 239 | train: Loss 0.438979 Accuracy 0.84 | validation: Loss 0.461107 Accuracy 0.81\n",
      "Epoch 240 | train: Loss 0.439702 Accuracy 0.83 | validation: Loss 0.456908 Accuracy 0.86\n",
      "Epoch 241 | train: Loss 0.441613 Accuracy 0.83 | validation: Loss 0.469887 Accuracy 0.83\n",
      "Epoch 242 | train: Loss 0.442256 Accuracy 0.84 | validation: Loss 0.446394 Accuracy 0.85\n",
      "Epoch 243 | train: Loss 0.436401 Accuracy 0.84 | validation: Loss 0.454656 Accuracy 0.84\n",
      "Epoch 244 | train: Loss 0.442894 Accuracy 0.84 | validation: Loss 0.456801 Accuracy 0.82\n",
      "Epoch 245 | train: Loss 0.434683 Accuracy 0.84 | validation: Loss 0.443398 Accuracy 0.84\n",
      "Epoch 246 | train: Loss 0.442639 Accuracy 0.83 | validation: Loss 0.457485 Accuracy 0.82\n",
      "Epoch 247 | train: Loss 0.439129 Accuracy 0.83 | validation: Loss 0.470922 Accuracy 0.86\n",
      "Epoch 248 | train: Loss 0.434747 Accuracy 0.84 | validation: Loss 0.441882 Accuracy 0.84\n",
      "Epoch 249 | train: Loss 0.429824 Accuracy 0.85 | validation: Loss 0.435025 Accuracy 0.86\n",
      "Epoch 250 | train: Loss 0.427895 Accuracy 0.84 | validation: Loss 0.435420 Accuracy 0.83\n",
      "Epoch 251 | train: Loss 0.429735 Accuracy 0.84 | validation: Loss 0.454213 Accuracy 0.83\n",
      "Epoch 252 | train: Loss 0.430750 Accuracy 0.84 | validation: Loss 0.436626 Accuracy 0.83\n",
      "Epoch 253 | train: Loss 0.436970 Accuracy 0.84 | validation: Loss 0.453225 Accuracy 0.82\n",
      "Epoch 254 | train: Loss 0.427826 Accuracy 0.84 | validation: Loss 0.441459 Accuracy 0.85\n",
      "Epoch 255 | train: Loss 0.427550 Accuracy 0.84 | validation: Loss 0.421903 Accuracy 0.85\n",
      "Epoch 256 | train: Loss 0.429519 Accuracy 0.84 | validation: Loss 0.433019 Accuracy 0.85\n",
      "Epoch 257 | train: Loss 0.427692 Accuracy 0.84 | validation: Loss 0.456020 Accuracy 0.86\n",
      "Epoch 258 | train: Loss 0.424741 Accuracy 0.84 | validation: Loss 0.423590 Accuracy 0.85\n",
      "Epoch 259 | train: Loss 0.432344 Accuracy 0.83 | validation: Loss 0.425798 Accuracy 0.85\n",
      "Epoch 260 | train: Loss 0.416039 Accuracy 0.85 | validation: Loss 0.423349 Accuracy 0.83\n",
      "Epoch 261 | train: Loss 0.419291 Accuracy 0.85 | validation: Loss 0.435529 Accuracy 0.82\n",
      "Epoch 262 | train: Loss 0.421626 Accuracy 0.85 | validation: Loss 0.434507 Accuracy 0.83\n",
      "Epoch 263 | train: Loss 0.420314 Accuracy 0.85 | validation: Loss 0.444446 Accuracy 0.81\n",
      "Epoch 264 | train: Loss 0.416011 Accuracy 0.85 | validation: Loss 0.433524 Accuracy 0.83\n",
      "Epoch 265 | train: Loss 0.416526 Accuracy 0.85 | validation: Loss 0.426985 Accuracy 0.84\n",
      "Epoch 266 | train: Loss 0.420744 Accuracy 0.85 | validation: Loss 0.434394 Accuracy 0.88\n",
      "Epoch 267 | train: Loss 0.410445 Accuracy 0.85 | validation: Loss 0.429094 Accuracy 0.84\n",
      "Epoch 268 | train: Loss 0.415858 Accuracy 0.84 | validation: Loss 0.426070 Accuracy 0.84\n",
      "Epoch 269 | train: Loss 0.415293 Accuracy 0.84 | validation: Loss 0.410667 Accuracy 0.85\n",
      "Epoch 270 | train: Loss 0.409160 Accuracy 0.85 | validation: Loss 0.417274 Accuracy 0.85\n",
      "Epoch 271 | train: Loss 0.408942 Accuracy 0.85 | validation: Loss 0.427676 Accuracy 0.84\n",
      "Epoch 272 | train: Loss 0.414947 Accuracy 0.84 | validation: Loss 0.425766 Accuracy 0.82\n",
      "Epoch 273 | train: Loss 0.411931 Accuracy 0.84 | validation: Loss 0.443831 Accuracy 0.88\n",
      "Epoch 274 | train: Loss 0.412458 Accuracy 0.85 | validation: Loss 0.429625 Accuracy 0.84\n",
      "Epoch 275 | train: Loss 0.406896 Accuracy 0.85 | validation: Loss 0.404431 Accuracy 0.85\n",
      "Epoch 276 | train: Loss 0.407827 Accuracy 0.85 | validation: Loss 0.423471 Accuracy 0.86\n",
      "Epoch 277 | train: Loss 0.404761 Accuracy 0.86 | validation: Loss 0.407138 Accuracy 0.86\n",
      "Epoch 278 | train: Loss 0.401307 Accuracy 0.86 | validation: Loss 0.415773 Accuracy 0.85\n",
      "Epoch 279 | train: Loss 0.407095 Accuracy 0.85 | validation: Loss 0.419084 Accuracy 0.87\n",
      "Epoch 280 | train: Loss 0.402213 Accuracy 0.85 | validation: Loss 0.407342 Accuracy 0.84\n",
      "Epoch 281 | train: Loss 0.402560 Accuracy 0.85 | validation: Loss 0.416428 Accuracy 0.84\n",
      "Epoch 282 | train: Loss 0.407969 Accuracy 0.85 | validation: Loss 0.427185 Accuracy 0.88\n",
      "Epoch 283 | train: Loss 0.405319 Accuracy 0.85 | validation: Loss 0.420288 Accuracy 0.83\n",
      "Epoch 284 | train: Loss 0.402932 Accuracy 0.86 | validation: Loss 0.423297 Accuracy 0.83\n",
      "Epoch 285 | train: Loss 0.408100 Accuracy 0.84 | validation: Loss 0.411729 Accuracy 0.82\n",
      "Epoch 286 | train: Loss 0.399192 Accuracy 0.86 | validation: Loss 0.426927 Accuracy 0.86\n",
      "Epoch 287 | train: Loss 0.395388 Accuracy 0.85 | validation: Loss 0.403877 Accuracy 0.86\n",
      "Epoch 288 | train: Loss 0.397675 Accuracy 0.85 | validation: Loss 0.418959 Accuracy 0.85\n",
      "Epoch 289 | train: Loss 0.399035 Accuracy 0.85 | validation: Loss 0.417372 Accuracy 0.85\n",
      "Epoch 290 | train: Loss 0.393190 Accuracy 0.85 | validation: Loss 0.402837 Accuracy 0.85\n",
      "Epoch 291 | train: Loss 0.397482 Accuracy 0.85 | validation: Loss 0.397579 Accuracy 0.85\n",
      "Epoch 292 | train: Loss 0.398037 Accuracy 0.86 | validation: Loss 0.389716 Accuracy 0.85\n",
      "Epoch 293 | train: Loss 0.396653 Accuracy 0.85 | validation: Loss 0.395936 Accuracy 0.89\n",
      "Epoch 294 | train: Loss 0.390752 Accuracy 0.86 | validation: Loss 0.409296 Accuracy 0.83\n",
      "Epoch 295 | train: Loss 0.393327 Accuracy 0.86 | validation: Loss 0.400784 Accuracy 0.85\n",
      "Epoch 296 | train: Loss 0.393216 Accuracy 0.85 | validation: Loss 0.387454 Accuracy 0.86\n",
      "Epoch 297 | train: Loss 0.395323 Accuracy 0.85 | validation: Loss 0.400982 Accuracy 0.86\n",
      "Epoch 298 | train: Loss 0.390534 Accuracy 0.86 | validation: Loss 0.401133 Accuracy 0.85\n",
      "Epoch 299 | train: Loss 0.389887 Accuracy 0.85 | validation: Loss 0.395867 Accuracy 0.85\n",
      "Epoch 300 | train: Loss 0.382583 Accuracy 0.86 | validation: Loss 0.412248 Accuracy 0.85\n",
      "Epoch 301 | train: Loss 0.394702 Accuracy 0.85 | validation: Loss 0.426713 Accuracy 0.84\n",
      "Epoch 302 | train: Loss 0.390076 Accuracy 0.86 | validation: Loss 0.395019 Accuracy 0.85\n",
      "Epoch 303 | train: Loss 0.384939 Accuracy 0.86 | validation: Loss 0.423664 Accuracy 0.87\n",
      "Epoch 304 | train: Loss 0.381896 Accuracy 0.86 | validation: Loss 0.404326 Accuracy 0.86\n",
      "Epoch 305 | train: Loss 0.385961 Accuracy 0.87 | validation: Loss 0.394187 Accuracy 0.83\n",
      "Epoch 306 | train: Loss 0.384219 Accuracy 0.86 | validation: Loss 0.394993 Accuracy 0.85\n",
      "Epoch 307 | train: Loss 0.381943 Accuracy 0.86 | validation: Loss 0.393982 Accuracy 0.87\n",
      "Epoch 308 | train: Loss 0.386233 Accuracy 0.85 | validation: Loss 0.390528 Accuracy 0.88\n",
      "Epoch 309 | train: Loss 0.388363 Accuracy 0.86 | validation: Loss 0.413931 Accuracy 0.86\n",
      "Epoch 310 | train: Loss 0.380593 Accuracy 0.86 | validation: Loss 0.380099 Accuracy 0.87\n",
      "Epoch 311 | train: Loss 0.387188 Accuracy 0.86 | validation: Loss 0.432098 Accuracy 0.82\n",
      "Epoch 312 | train: Loss 0.389226 Accuracy 0.85 | validation: Loss 0.386532 Accuracy 0.86\n",
      "Epoch 313 | train: Loss 0.379508 Accuracy 0.86 | validation: Loss 0.422166 Accuracy 0.82\n",
      "Epoch 314 | train: Loss 0.378598 Accuracy 0.87 | validation: Loss 0.391648 Accuracy 0.89\n",
      "Epoch 315 | train: Loss 0.372008 Accuracy 0.87 | validation: Loss 0.404270 Accuracy 0.83\n",
      "Epoch 316 | train: Loss 0.376475 Accuracy 0.87 | validation: Loss 0.398416 Accuracy 0.86\n",
      "Epoch 317 | train: Loss 0.381071 Accuracy 0.86 | validation: Loss 0.411545 Accuracy 0.86\n",
      "Epoch 318 | train: Loss 0.380454 Accuracy 0.86 | validation: Loss 0.385813 Accuracy 0.86\n",
      "Epoch 319 | train: Loss 0.371850 Accuracy 0.87 | validation: Loss 0.391995 Accuracy 0.87\n",
      "Epoch 320 | train: Loss 0.376229 Accuracy 0.87 | validation: Loss 0.390098 Accuracy 0.86\n",
      "Epoch 321 | train: Loss 0.373309 Accuracy 0.87 | validation: Loss 0.369520 Accuracy 0.87\n",
      "Epoch 322 | train: Loss 0.373030 Accuracy 0.87 | validation: Loss 0.383560 Accuracy 0.88\n",
      "Epoch 323 | train: Loss 0.371136 Accuracy 0.87 | validation: Loss 0.391653 Accuracy 0.84\n",
      "Epoch 324 | train: Loss 0.370657 Accuracy 0.87 | validation: Loss 0.393648 Accuracy 0.87\n",
      "Epoch 325 | train: Loss 0.380465 Accuracy 0.86 | validation: Loss 0.379057 Accuracy 0.87\n",
      "Epoch 326 | train: Loss 0.367521 Accuracy 0.87 | validation: Loss 0.374936 Accuracy 0.88\n",
      "Epoch 327 | train: Loss 0.363043 Accuracy 0.88 | validation: Loss 0.389578 Accuracy 0.87\n",
      "Epoch 328 | train: Loss 0.364005 Accuracy 0.87 | validation: Loss 0.360187 Accuracy 0.87\n",
      "Epoch 329 | train: Loss 0.366397 Accuracy 0.87 | validation: Loss 0.390497 Accuracy 0.89\n",
      "Epoch 330 | train: Loss 0.366622 Accuracy 0.87 | validation: Loss 0.377852 Accuracy 0.88\n",
      "Epoch 331 | train: Loss 0.362638 Accuracy 0.87 | validation: Loss 0.380254 Accuracy 0.89\n",
      "Epoch 332 | train: Loss 0.363765 Accuracy 0.87 | validation: Loss 0.381837 Accuracy 0.85\n",
      "Epoch 333 | train: Loss 0.363681 Accuracy 0.87 | validation: Loss 0.372095 Accuracy 0.87\n",
      "Epoch 334 | train: Loss 0.369364 Accuracy 0.86 | validation: Loss 0.377585 Accuracy 0.88\n",
      "Epoch 335 | train: Loss 0.366228 Accuracy 0.87 | validation: Loss 0.405283 Accuracy 0.83\n",
      "Epoch 336 | train: Loss 0.362982 Accuracy 0.87 | validation: Loss 0.381436 Accuracy 0.87\n",
      "Epoch 337 | train: Loss 0.360981 Accuracy 0.87 | validation: Loss 0.390022 Accuracy 0.89\n",
      "Epoch 338 | train: Loss 0.359323 Accuracy 0.88 | validation: Loss 0.368752 Accuracy 0.87\n",
      "Epoch 339 | train: Loss 0.356510 Accuracy 0.88 | validation: Loss 0.379735 Accuracy 0.83\n",
      "Epoch 340 | train: Loss 0.359385 Accuracy 0.87 | validation: Loss 0.372847 Accuracy 0.89\n",
      "Epoch 341 | train: Loss 0.359923 Accuracy 0.88 | validation: Loss 0.371016 Accuracy 0.86\n",
      "Epoch 342 | train: Loss 0.362745 Accuracy 0.87 | validation: Loss 0.381110 Accuracy 0.85\n",
      "Epoch 343 | train: Loss 0.354292 Accuracy 0.88 | validation: Loss 0.376980 Accuracy 0.87\n",
      "Epoch 344 | train: Loss 0.359003 Accuracy 0.87 | validation: Loss 0.368805 Accuracy 0.88\n",
      "Epoch 345 | train: Loss 0.355823 Accuracy 0.88 | validation: Loss 0.362151 Accuracy 0.88\n",
      "Epoch 346 | train: Loss 0.351414 Accuracy 0.88 | validation: Loss 0.360087 Accuracy 0.88\n",
      "Epoch 347 | train: Loss 0.353339 Accuracy 0.88 | validation: Loss 0.360578 Accuracy 0.89\n",
      "Epoch 348 | train: Loss 0.353296 Accuracy 0.88 | validation: Loss 0.382916 Accuracy 0.88\n",
      "Epoch 349 | train: Loss 0.356811 Accuracy 0.88 | validation: Loss 0.365386 Accuracy 0.89\n",
      "Epoch 350 | train: Loss 0.353218 Accuracy 0.88 | validation: Loss 0.356854 Accuracy 0.87\n",
      "Epoch 351 | train: Loss 0.349487 Accuracy 0.88 | validation: Loss 0.369411 Accuracy 0.87\n",
      "Epoch 352 | train: Loss 0.348185 Accuracy 0.88 | validation: Loss 0.363216 Accuracy 0.86\n",
      "Epoch 353 | train: Loss 0.349991 Accuracy 0.88 | validation: Loss 0.374305 Accuracy 0.88\n",
      "Epoch 354 | train: Loss 0.360325 Accuracy 0.87 | validation: Loss 0.370115 Accuracy 0.85\n",
      "Epoch 355 | train: Loss 0.355086 Accuracy 0.87 | validation: Loss 0.362095 Accuracy 0.88\n",
      "Epoch 356 | train: Loss 0.344491 Accuracy 0.89 | validation: Loss 0.362925 Accuracy 0.86\n",
      "Epoch 357 | train: Loss 0.361240 Accuracy 0.86 | validation: Loss 0.383236 Accuracy 0.86\n",
      "Epoch 358 | train: Loss 0.349581 Accuracy 0.88 | validation: Loss 0.355216 Accuracy 0.86\n",
      "Epoch 359 | train: Loss 0.348765 Accuracy 0.88 | validation: Loss 0.352507 Accuracy 0.89\n",
      "Epoch 360 | train: Loss 0.347513 Accuracy 0.88 | validation: Loss 0.362023 Accuracy 0.89\n",
      "Epoch 361 | train: Loss 0.342819 Accuracy 0.89 | validation: Loss 0.364287 Accuracy 0.86\n",
      "Epoch 362 | train: Loss 0.350808 Accuracy 0.87 | validation: Loss 0.359104 Accuracy 0.86\n",
      "Epoch 363 | train: Loss 0.341101 Accuracy 0.88 | validation: Loss 0.368592 Accuracy 0.85\n",
      "Epoch 364 | train: Loss 0.340927 Accuracy 0.89 | validation: Loss 0.353081 Accuracy 0.88\n",
      "Epoch 365 | train: Loss 0.341823 Accuracy 0.88 | validation: Loss 0.334309 Accuracy 0.89\n",
      "Epoch 366 | train: Loss 0.339523 Accuracy 0.89 | validation: Loss 0.358035 Accuracy 0.88\n",
      "Epoch 367 | train: Loss 0.343888 Accuracy 0.88 | validation: Loss 0.372297 Accuracy 0.85\n",
      "Epoch 368 | train: Loss 0.338806 Accuracy 0.89 | validation: Loss 0.353362 Accuracy 0.88\n",
      "Epoch 369 | train: Loss 0.344362 Accuracy 0.88 | validation: Loss 0.350729 Accuracy 0.88\n",
      "Epoch 370 | train: Loss 0.337832 Accuracy 0.88 | validation: Loss 0.341705 Accuracy 0.89\n",
      "Epoch 371 | train: Loss 0.339669 Accuracy 0.88 | validation: Loss 0.346622 Accuracy 0.86\n",
      "Epoch 372 | train: Loss 0.346457 Accuracy 0.87 | validation: Loss 0.359593 Accuracy 0.86\n",
      "Epoch 373 | train: Loss 0.341744 Accuracy 0.88 | validation: Loss 0.358116 Accuracy 0.89\n",
      "Epoch 374 | train: Loss 0.335907 Accuracy 0.89 | validation: Loss 0.367474 Accuracy 0.88\n",
      "Epoch 375 | train: Loss 0.342765 Accuracy 0.88 | validation: Loss 0.345153 Accuracy 0.87\n",
      "Epoch 376 | train: Loss 0.340100 Accuracy 0.88 | validation: Loss 0.365792 Accuracy 0.86\n",
      "Epoch 377 | train: Loss 0.336362 Accuracy 0.88 | validation: Loss 0.344845 Accuracy 0.88\n",
      "Epoch 378 | train: Loss 0.340003 Accuracy 0.88 | validation: Loss 0.353541 Accuracy 0.86\n",
      "Epoch 379 | train: Loss 0.337375 Accuracy 0.88 | validation: Loss 0.351032 Accuracy 0.88\n",
      "Epoch 380 | train: Loss 0.329608 Accuracy 0.89 | validation: Loss 0.348727 Accuracy 0.88\n",
      "Epoch 381 | train: Loss 0.332740 Accuracy 0.88 | validation: Loss 0.352436 Accuracy 0.86\n",
      "Epoch 382 | train: Loss 0.332379 Accuracy 0.89 | validation: Loss 0.367340 Accuracy 0.88\n",
      "Epoch 383 | train: Loss 0.337355 Accuracy 0.88 | validation: Loss 0.356447 Accuracy 0.86\n",
      "Epoch 384 | train: Loss 0.329821 Accuracy 0.89 | validation: Loss 0.338244 Accuracy 0.87\n",
      "Epoch 385 | train: Loss 0.328935 Accuracy 0.89 | validation: Loss 0.351309 Accuracy 0.88\n",
      "Epoch 386 | train: Loss 0.331284 Accuracy 0.89 | validation: Loss 0.337432 Accuracy 0.89\n",
      "Epoch 387 | train: Loss 0.324538 Accuracy 0.90 | validation: Loss 0.334163 Accuracy 0.89\n",
      "Epoch 388 | train: Loss 0.327117 Accuracy 0.89 | validation: Loss 0.361366 Accuracy 0.87\n",
      "Epoch 389 | train: Loss 0.331484 Accuracy 0.89 | validation: Loss 0.350924 Accuracy 0.86\n",
      "Epoch 390 | train: Loss 0.326325 Accuracy 0.89 | validation: Loss 0.336955 Accuracy 0.88\n",
      "Epoch 391 | train: Loss 0.331434 Accuracy 0.89 | validation: Loss 0.372662 Accuracy 0.85\n",
      "Epoch 392 | train: Loss 0.331321 Accuracy 0.88 | validation: Loss 0.341223 Accuracy 0.88\n",
      "Epoch 393 | train: Loss 0.325720 Accuracy 0.89 | validation: Loss 0.361055 Accuracy 0.86\n",
      "Epoch 394 | train: Loss 0.333115 Accuracy 0.88 | validation: Loss 0.339474 Accuracy 0.89\n",
      "Epoch 395 | train: Loss 0.323668 Accuracy 0.89 | validation: Loss 0.326315 Accuracy 0.89\n",
      "Epoch 396 | train: Loss 0.322043 Accuracy 0.89 | validation: Loss 0.337658 Accuracy 0.88\n",
      "Epoch 397 | train: Loss 0.323389 Accuracy 0.89 | validation: Loss 0.349499 Accuracy 0.87\n",
      "Epoch 398 | train: Loss 0.320697 Accuracy 0.89 | validation: Loss 0.337713 Accuracy 0.90\n",
      "Epoch 399 | train: Loss 0.318953 Accuracy 0.90 | validation: Loss 0.338048 Accuracy 0.90\n",
      "Epoch 400 | train: Loss 0.320639 Accuracy 0.89 | validation: Loss 0.330259 Accuracy 0.91\n",
      "Epoch 401 | train: Loss 0.320962 Accuracy 0.89 | validation: Loss 0.363299 Accuracy 0.88\n",
      "Epoch 402 | train: Loss 0.321257 Accuracy 0.89 | validation: Loss 0.318480 Accuracy 0.90\n",
      "Epoch 403 | train: Loss 0.317501 Accuracy 0.90 | validation: Loss 0.333804 Accuracy 0.89\n",
      "Epoch 404 | train: Loss 0.318668 Accuracy 0.89 | validation: Loss 0.335197 Accuracy 0.89\n",
      "Epoch 405 | train: Loss 0.318515 Accuracy 0.89 | validation: Loss 0.328694 Accuracy 0.89\n",
      "Epoch 406 | train: Loss 0.325219 Accuracy 0.88 | validation: Loss 0.329573 Accuracy 0.86\n",
      "Epoch 407 | train: Loss 0.326599 Accuracy 0.88 | validation: Loss 0.338451 Accuracy 0.89\n",
      "Epoch 408 | train: Loss 0.315853 Accuracy 0.90 | validation: Loss 0.329145 Accuracy 0.88\n",
      "Epoch 409 | train: Loss 0.317247 Accuracy 0.89 | validation: Loss 0.340590 Accuracy 0.86\n",
      "Epoch 410 | train: Loss 0.315025 Accuracy 0.89 | validation: Loss 0.316317 Accuracy 0.91\n",
      "Epoch 411 | train: Loss 0.316893 Accuracy 0.89 | validation: Loss 0.339316 Accuracy 0.88\n",
      "Epoch 412 | train: Loss 0.317002 Accuracy 0.89 | validation: Loss 0.332895 Accuracy 0.90\n",
      "Epoch 413 | train: Loss 0.312344 Accuracy 0.90 | validation: Loss 0.326286 Accuracy 0.89\n",
      "Epoch 414 | train: Loss 0.320296 Accuracy 0.89 | validation: Loss 0.327544 Accuracy 0.88\n",
      "Epoch 415 | train: Loss 0.312306 Accuracy 0.90 | validation: Loss 0.325874 Accuracy 0.88\n",
      "Epoch 416 | train: Loss 0.312480 Accuracy 0.90 | validation: Loss 0.323316 Accuracy 0.90\n",
      "Epoch 417 | train: Loss 0.314197 Accuracy 0.89 | validation: Loss 0.318424 Accuracy 0.90\n",
      "Epoch 418 | train: Loss 0.309456 Accuracy 0.90 | validation: Loss 0.322396 Accuracy 0.89\n",
      "Epoch 419 | train: Loss 0.312280 Accuracy 0.89 | validation: Loss 0.316345 Accuracy 0.91\n",
      "Epoch 420 | train: Loss 0.308935 Accuracy 0.90 | validation: Loss 0.324743 Accuracy 0.88\n",
      "Epoch 421 | train: Loss 0.309175 Accuracy 0.89 | validation: Loss 0.325778 Accuracy 0.90\n",
      "Epoch 422 | train: Loss 0.307057 Accuracy 0.90 | validation: Loss 0.318695 Accuracy 0.90\n",
      "Epoch 423 | train: Loss 0.308295 Accuracy 0.89 | validation: Loss 0.319816 Accuracy 0.90\n",
      "Epoch 424 | train: Loss 0.307178 Accuracy 0.90 | validation: Loss 0.315683 Accuracy 0.90\n",
      "Epoch 425 | train: Loss 0.307001 Accuracy 0.90 | validation: Loss 0.323023 Accuracy 0.89\n",
      "Epoch 426 | train: Loss 0.307044 Accuracy 0.90 | validation: Loss 0.313703 Accuracy 0.90\n",
      "Epoch 427 | train: Loss 0.304122 Accuracy 0.90 | validation: Loss 0.320702 Accuracy 0.87\n",
      "Epoch 428 | train: Loss 0.304181 Accuracy 0.89 | validation: Loss 0.327488 Accuracy 0.90\n",
      "Epoch 429 | train: Loss 0.305882 Accuracy 0.90 | validation: Loss 0.323480 Accuracy 0.89\n",
      "Epoch 430 | train: Loss 0.317121 Accuracy 0.88 | validation: Loss 0.329654 Accuracy 0.89\n",
      "Epoch 431 | train: Loss 0.306019 Accuracy 0.90 | validation: Loss 0.307158 Accuracy 0.89\n",
      "Epoch 432 | train: Loss 0.306320 Accuracy 0.90 | validation: Loss 0.318063 Accuracy 0.91\n",
      "Epoch 433 | train: Loss 0.300305 Accuracy 0.90 | validation: Loss 0.317378 Accuracy 0.90\n",
      "Epoch 434 | train: Loss 0.313195 Accuracy 0.89 | validation: Loss 0.313308 Accuracy 0.88\n",
      "Epoch 435 | train: Loss 0.303777 Accuracy 0.90 | validation: Loss 0.309907 Accuracy 0.88\n",
      "Epoch 436 | train: Loss 0.299833 Accuracy 0.90 | validation: Loss 0.317018 Accuracy 0.89\n",
      "Epoch 437 | train: Loss 0.301600 Accuracy 0.90 | validation: Loss 0.308644 Accuracy 0.89\n",
      "Epoch 438 | train: Loss 0.304716 Accuracy 0.89 | validation: Loss 0.331446 Accuracy 0.87\n",
      "Epoch 439 | train: Loss 0.304208 Accuracy 0.90 | validation: Loss 0.336195 Accuracy 0.88\n",
      "Epoch 440 | train: Loss 0.300829 Accuracy 0.90 | validation: Loss 0.315870 Accuracy 0.87\n",
      "Epoch 441 | train: Loss 0.306152 Accuracy 0.89 | validation: Loss 0.301378 Accuracy 0.90\n",
      "Epoch 442 | train: Loss 0.296648 Accuracy 0.91 | validation: Loss 0.313164 Accuracy 0.89\n",
      "Epoch 443 | train: Loss 0.296865 Accuracy 0.90 | validation: Loss 0.326421 Accuracy 0.91\n",
      "Epoch 444 | train: Loss 0.305931 Accuracy 0.89 | validation: Loss 0.307842 Accuracy 0.89\n",
      "Epoch 445 | train: Loss 0.299859 Accuracy 0.90 | validation: Loss 0.308675 Accuracy 0.89\n",
      "Epoch 446 | train: Loss 0.298590 Accuracy 0.89 | validation: Loss 0.322601 Accuracy 0.86\n",
      "Epoch 447 | train: Loss 0.296099 Accuracy 0.90 | validation: Loss 0.325266 Accuracy 0.87\n",
      "Epoch 448 | train: Loss 0.300591 Accuracy 0.89 | validation: Loss 0.292652 Accuracy 0.89\n",
      "Epoch 449 | train: Loss 0.295626 Accuracy 0.90 | validation: Loss 0.306191 Accuracy 0.89\n",
      "Epoch 450 | train: Loss 0.305961 Accuracy 0.89 | validation: Loss 0.303071 Accuracy 0.90\n",
      "Epoch 451 | train: Loss 0.293796 Accuracy 0.90 | validation: Loss 0.316047 Accuracy 0.89\n",
      "Epoch 452 | train: Loss 0.298980 Accuracy 0.90 | validation: Loss 0.311758 Accuracy 0.90\n",
      "Epoch 453 | train: Loss 0.293256 Accuracy 0.90 | validation: Loss 0.302811 Accuracy 0.88\n",
      "Epoch 454 | train: Loss 0.296951 Accuracy 0.90 | validation: Loss 0.315373 Accuracy 0.88\n",
      "Epoch 455 | train: Loss 0.297860 Accuracy 0.89 | validation: Loss 0.309602 Accuracy 0.89\n",
      "Epoch 456 | train: Loss 0.294657 Accuracy 0.90 | validation: Loss 0.302858 Accuracy 0.88\n",
      "Epoch 457 | train: Loss 0.291144 Accuracy 0.90 | validation: Loss 0.292110 Accuracy 0.91\n",
      "Epoch 458 | train: Loss 0.294247 Accuracy 0.90 | validation: Loss 0.301317 Accuracy 0.89\n",
      "Epoch 459 | train: Loss 0.296115 Accuracy 0.90 | validation: Loss 0.318676 Accuracy 0.88\n",
      "Epoch 460 | train: Loss 0.289175 Accuracy 0.90 | validation: Loss 0.297138 Accuracy 0.90\n",
      "Epoch 461 | train: Loss 0.292788 Accuracy 0.90 | validation: Loss 0.299802 Accuracy 0.90\n",
      "Epoch 462 | train: Loss 0.290032 Accuracy 0.90 | validation: Loss 0.300264 Accuracy 0.90\n",
      "Epoch 463 | train: Loss 0.292402 Accuracy 0.90 | validation: Loss 0.287675 Accuracy 0.91\n",
      "Epoch 464 | train: Loss 0.291480 Accuracy 0.90 | validation: Loss 0.311190 Accuracy 0.90\n",
      "Epoch 465 | train: Loss 0.289734 Accuracy 0.90 | validation: Loss 0.291192 Accuracy 0.90\n",
      "Epoch 466 | train: Loss 0.294657 Accuracy 0.90 | validation: Loss 0.300228 Accuracy 0.90\n",
      "Epoch 467 | train: Loss 0.289173 Accuracy 0.90 | validation: Loss 0.302356 Accuracy 0.89\n",
      "Epoch 468 | train: Loss 0.286798 Accuracy 0.90 | validation: Loss 0.295459 Accuracy 0.90\n",
      "Epoch 469 | train: Loss 0.286752 Accuracy 0.91 | validation: Loss 0.292430 Accuracy 0.91\n",
      "Epoch 470 | train: Loss 0.282088 Accuracy 0.91 | validation: Loss 0.289563 Accuracy 0.89\n",
      "Epoch 471 | train: Loss 0.283446 Accuracy 0.91 | validation: Loss 0.306040 Accuracy 0.90\n",
      "Epoch 472 | train: Loss 0.283319 Accuracy 0.90 | validation: Loss 0.292110 Accuracy 0.91\n",
      "Epoch 473 | train: Loss 0.283665 Accuracy 0.90 | validation: Loss 0.302198 Accuracy 0.91\n",
      "Epoch 474 | train: Loss 0.285953 Accuracy 0.90 | validation: Loss 0.294802 Accuracy 0.90\n",
      "Epoch 475 | train: Loss 0.282168 Accuracy 0.91 | validation: Loss 0.281627 Accuracy 0.90\n",
      "Epoch 476 | train: Loss 0.282568 Accuracy 0.91 | validation: Loss 0.313187 Accuracy 0.90\n",
      "Epoch 477 | train: Loss 0.280521 Accuracy 0.91 | validation: Loss 0.294269 Accuracy 0.89\n",
      "Epoch 478 | train: Loss 0.287417 Accuracy 0.90 | validation: Loss 0.293212 Accuracy 0.90\n",
      "Epoch 479 | train: Loss 0.287185 Accuracy 0.90 | validation: Loss 0.299618 Accuracy 0.88\n",
      "Epoch 480 | train: Loss 0.285205 Accuracy 0.90 | validation: Loss 0.305926 Accuracy 0.87\n",
      "Epoch 481 | train: Loss 0.286180 Accuracy 0.90 | validation: Loss 0.311348 Accuracy 0.89\n",
      "Epoch 482 | train: Loss 0.281109 Accuracy 0.91 | validation: Loss 0.301519 Accuracy 0.88\n",
      "Epoch 483 | train: Loss 0.283010 Accuracy 0.90 | validation: Loss 0.291230 Accuracy 0.91\n",
      "Epoch 484 | train: Loss 0.283706 Accuracy 0.90 | validation: Loss 0.284230 Accuracy 0.91\n",
      "Epoch 485 | train: Loss 0.278229 Accuracy 0.91 | validation: Loss 0.276053 Accuracy 0.92\n",
      "Epoch 486 | train: Loss 0.275250 Accuracy 0.91 | validation: Loss 0.304937 Accuracy 0.89\n",
      "Epoch 487 | train: Loss 0.284783 Accuracy 0.90 | validation: Loss 0.293126 Accuracy 0.91\n",
      "Epoch 488 | train: Loss 0.287056 Accuracy 0.89 | validation: Loss 0.308824 Accuracy 0.90\n",
      "Epoch 489 | train: Loss 0.278159 Accuracy 0.91 | validation: Loss 0.286328 Accuracy 0.91\n",
      "Epoch 490 | train: Loss 0.280893 Accuracy 0.90 | validation: Loss 0.297495 Accuracy 0.89\n",
      "Epoch 491 | train: Loss 0.280397 Accuracy 0.91 | validation: Loss 0.298302 Accuracy 0.90\n",
      "Epoch 492 | train: Loss 0.278539 Accuracy 0.91 | validation: Loss 0.293577 Accuracy 0.88\n",
      "Epoch 493 | train: Loss 0.277550 Accuracy 0.91 | validation: Loss 0.287248 Accuracy 0.90\n",
      "Epoch 494 | train: Loss 0.272915 Accuracy 0.91 | validation: Loss 0.284018 Accuracy 0.89\n",
      "Epoch 495 | train: Loss 0.274768 Accuracy 0.91 | validation: Loss 0.281464 Accuracy 0.90\n",
      "Epoch 496 | train: Loss 0.275804 Accuracy 0.90 | validation: Loss 0.278781 Accuracy 0.91\n",
      "Epoch 497 | train: Loss 0.272075 Accuracy 0.91 | validation: Loss 0.284430 Accuracy 0.89\n",
      "Epoch 498 | train: Loss 0.276774 Accuracy 0.90 | validation: Loss 0.278878 Accuracy 0.89\n",
      "Epoch 499 | train: Loss 0.269654 Accuracy 0.91 | validation: Loss 0.283072 Accuracy 0.90\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 128\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 64\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "model0 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(), lr=0.0001)\n",
    "\n",
    "model0_results = engine.train(model=model0,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              experiment_name=\"luzern_V0\",\n",
    "                              model_name=\"Neural_Net\",\n",
    "                              early_stop_patience=None,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff43e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] create SummaryWriter saving to runs\\2023-12-25-00\\luzern_V0\\Neural_Net\\1000epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a62fd934ff49e5aae6c2d871497351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train: Loss 3.876857 Accuracy 0.30 | validation: Loss 1.556792 Accuracy 0.36\n",
      "Epoch 1 | train: Loss 1.414394 Accuracy 0.45 | validation: Loss 1.381815 Accuracy 0.45\n",
      "Epoch 2 | train: Loss 1.348989 Accuracy 0.48 | validation: Loss 1.321669 Accuracy 0.51\n",
      "Epoch 3 | train: Loss 1.300869 Accuracy 0.53 | validation: Loss 1.280636 Accuracy 0.55\n",
      "Epoch 4 | train: Loss 1.261051 Accuracy 0.55 | validation: Loss 1.241374 Accuracy 0.56\n",
      "Epoch 5 | train: Loss 1.228816 Accuracy 0.57 | validation: Loss 1.220952 Accuracy 0.56\n",
      "Epoch 6 | train: Loss 1.193593 Accuracy 0.59 | validation: Loss 1.178762 Accuracy 0.60\n",
      "Epoch 7 | train: Loss 1.168743 Accuracy 0.60 | validation: Loss 1.160066 Accuracy 0.57\n",
      "Epoch 8 | train: Loss 1.136830 Accuracy 0.60 | validation: Loss 1.115764 Accuracy 0.62\n",
      "Epoch 9 | train: Loss 1.107547 Accuracy 0.62 | validation: Loss 1.092079 Accuracy 0.62\n",
      "Epoch 10 | train: Loss 1.083820 Accuracy 0.62 | validation: Loss 1.058507 Accuracy 0.61\n",
      "Epoch 11 | train: Loss 1.062855 Accuracy 0.62 | validation: Loss 1.046916 Accuracy 0.63\n",
      "Epoch 12 | train: Loss 1.044801 Accuracy 0.63 | validation: Loss 1.048737 Accuracy 0.62\n",
      "Epoch 13 | train: Loss 1.038858 Accuracy 0.62 | validation: Loss 1.038911 Accuracy 0.61\n",
      "Epoch 14 | train: Loss 1.023367 Accuracy 0.63 | validation: Loss 1.015831 Accuracy 0.62\n",
      "Epoch 15 | train: Loss 1.017173 Accuracy 0.64 | validation: Loss 0.998556 Accuracy 0.65\n",
      "Epoch 16 | train: Loss 1.003399 Accuracy 0.64 | validation: Loss 0.987078 Accuracy 0.65\n",
      "Epoch 17 | train: Loss 0.997764 Accuracy 0.64 | validation: Loss 0.999785 Accuracy 0.63\n",
      "Epoch 18 | train: Loss 0.998883 Accuracy 0.63 | validation: Loss 1.016878 Accuracy 0.62\n",
      "Epoch 19 | train: Loss 0.985047 Accuracy 0.64 | validation: Loss 0.972405 Accuracy 0.64\n",
      "Epoch 20 | train: Loss 0.974064 Accuracy 0.64 | validation: Loss 0.963166 Accuracy 0.63\n",
      "Epoch 21 | train: Loss 0.968803 Accuracy 0.64 | validation: Loss 0.971102 Accuracy 0.64\n",
      "Epoch 22 | train: Loss 0.963336 Accuracy 0.64 | validation: Loss 0.949803 Accuracy 0.65\n",
      "Epoch 23 | train: Loss 0.956807 Accuracy 0.64 | validation: Loss 0.976924 Accuracy 0.60\n",
      "Epoch 24 | train: Loss 0.947555 Accuracy 0.64 | validation: Loss 0.938279 Accuracy 0.65\n",
      "Epoch 25 | train: Loss 0.938958 Accuracy 0.65 | validation: Loss 0.941757 Accuracy 0.65\n",
      "Epoch 26 | train: Loss 0.930285 Accuracy 0.66 | validation: Loss 0.948416 Accuracy 0.65\n",
      "Epoch 27 | train: Loss 0.926858 Accuracy 0.65 | validation: Loss 0.953349 Accuracy 0.61\n",
      "Epoch 28 | train: Loss 0.926055 Accuracy 0.65 | validation: Loss 0.918128 Accuracy 0.65\n",
      "Epoch 29 | train: Loss 0.913901 Accuracy 0.66 | validation: Loss 0.899385 Accuracy 0.68\n",
      "Epoch 30 | train: Loss 0.908351 Accuracy 0.66 | validation: Loss 0.904092 Accuracy 0.65\n",
      "Epoch 31 | train: Loss 0.915568 Accuracy 0.64 | validation: Loss 0.909365 Accuracy 0.64\n",
      "Epoch 32 | train: Loss 0.903635 Accuracy 0.66 | validation: Loss 0.891791 Accuracy 0.66\n",
      "Epoch 33 | train: Loss 0.891461 Accuracy 0.66 | validation: Loss 0.883303 Accuracy 0.66\n",
      "Epoch 34 | train: Loss 0.886497 Accuracy 0.66 | validation: Loss 0.871794 Accuracy 0.67\n",
      "Epoch 35 | train: Loss 0.883316 Accuracy 0.66 | validation: Loss 0.882102 Accuracy 0.66\n",
      "Epoch 36 | train: Loss 0.885194 Accuracy 0.66 | validation: Loss 0.871692 Accuracy 0.65\n",
      "Epoch 37 | train: Loss 0.872252 Accuracy 0.67 | validation: Loss 0.879507 Accuracy 0.65\n",
      "Epoch 38 | train: Loss 0.865721 Accuracy 0.67 | validation: Loss 0.854662 Accuracy 0.68\n",
      "Epoch 39 | train: Loss 0.863849 Accuracy 0.67 | validation: Loss 0.852232 Accuracy 0.66\n",
      "Epoch 40 | train: Loss 0.853739 Accuracy 0.67 | validation: Loss 0.850874 Accuracy 0.68\n",
      "Epoch 41 | train: Loss 0.853240 Accuracy 0.67 | validation: Loss 0.867724 Accuracy 0.66\n",
      "Epoch 42 | train: Loss 0.846486 Accuracy 0.67 | validation: Loss 0.838688 Accuracy 0.67\n",
      "Epoch 43 | train: Loss 0.839194 Accuracy 0.68 | validation: Loss 0.835264 Accuracy 0.70\n",
      "Epoch 44 | train: Loss 0.836983 Accuracy 0.68 | validation: Loss 0.831703 Accuracy 0.67\n",
      "Epoch 45 | train: Loss 0.833620 Accuracy 0.68 | validation: Loss 0.818513 Accuracy 0.67\n",
      "Epoch 46 | train: Loss 0.832059 Accuracy 0.67 | validation: Loss 0.823759 Accuracy 0.69\n",
      "Epoch 47 | train: Loss 0.819347 Accuracy 0.68 | validation: Loss 0.838575 Accuracy 0.66\n",
      "Epoch 48 | train: Loss 0.821003 Accuracy 0.68 | validation: Loss 0.819700 Accuracy 0.70\n",
      "Epoch 49 | train: Loss 0.813097 Accuracy 0.68 | validation: Loss 0.800263 Accuracy 0.69\n",
      "Epoch 50 | train: Loss 0.804085 Accuracy 0.69 | validation: Loss 0.804919 Accuracy 0.67\n",
      "Epoch 51 | train: Loss 0.804133 Accuracy 0.69 | validation: Loss 0.798528 Accuracy 0.68\n",
      "Epoch 52 | train: Loss 0.794143 Accuracy 0.70 | validation: Loss 0.795558 Accuracy 0.71\n",
      "Epoch 53 | train: Loss 0.796435 Accuracy 0.68 | validation: Loss 0.809574 Accuracy 0.69\n",
      "Epoch 54 | train: Loss 0.789829 Accuracy 0.70 | validation: Loss 0.787223 Accuracy 0.68\n",
      "Epoch 55 | train: Loss 0.784643 Accuracy 0.70 | validation: Loss 0.781530 Accuracy 0.69\n",
      "Epoch 56 | train: Loss 0.777227 Accuracy 0.70 | validation: Loss 0.780031 Accuracy 0.69\n",
      "Epoch 57 | train: Loss 0.778327 Accuracy 0.70 | validation: Loss 0.796154 Accuracy 0.67\n",
      "Epoch 58 | train: Loss 0.777127 Accuracy 0.70 | validation: Loss 0.756710 Accuracy 0.72\n",
      "Epoch 59 | train: Loss 0.770429 Accuracy 0.70 | validation: Loss 0.768300 Accuracy 0.69\n",
      "Epoch 60 | train: Loss 0.765768 Accuracy 0.70 | validation: Loss 0.779893 Accuracy 0.68\n",
      "Epoch 61 | train: Loss 0.764207 Accuracy 0.71 | validation: Loss 0.766008 Accuracy 0.72\n",
      "Epoch 62 | train: Loss 0.761226 Accuracy 0.71 | validation: Loss 0.763152 Accuracy 0.71\n",
      "Epoch 63 | train: Loss 0.755245 Accuracy 0.71 | validation: Loss 0.749535 Accuracy 0.71\n",
      "Epoch 64 | train: Loss 0.749767 Accuracy 0.72 | validation: Loss 0.766685 Accuracy 0.69\n",
      "Epoch 65 | train: Loss 0.747193 Accuracy 0.71 | validation: Loss 0.750288 Accuracy 0.73\n",
      "Epoch 66 | train: Loss 0.752152 Accuracy 0.71 | validation: Loss 0.753567 Accuracy 0.72\n",
      "Epoch 67 | train: Loss 0.741941 Accuracy 0.72 | validation: Loss 0.747510 Accuracy 0.70\n",
      "Epoch 68 | train: Loss 0.735749 Accuracy 0.72 | validation: Loss 0.742711 Accuracy 0.71\n",
      "Epoch 69 | train: Loss 0.733350 Accuracy 0.72 | validation: Loss 0.754609 Accuracy 0.69\n",
      "Epoch 70 | train: Loss 0.732582 Accuracy 0.72 | validation: Loss 0.725551 Accuracy 0.73\n",
      "Epoch 71 | train: Loss 0.724374 Accuracy 0.72 | validation: Loss 0.722148 Accuracy 0.76\n",
      "Epoch 72 | train: Loss 0.727232 Accuracy 0.72 | validation: Loss 0.719122 Accuracy 0.74\n",
      "Epoch 73 | train: Loss 0.721936 Accuracy 0.72 | validation: Loss 0.753216 Accuracy 0.65\n",
      "Epoch 74 | train: Loss 0.719548 Accuracy 0.72 | validation: Loss 0.700901 Accuracy 0.76\n",
      "Epoch 75 | train: Loss 0.716251 Accuracy 0.72 | validation: Loss 0.722545 Accuracy 0.75\n",
      "Epoch 76 | train: Loss 0.713376 Accuracy 0.73 | validation: Loss 0.706243 Accuracy 0.76\n",
      "Epoch 77 | train: Loss 0.709264 Accuracy 0.74 | validation: Loss 0.711191 Accuracy 0.75\n",
      "Epoch 78 | train: Loss 0.702974 Accuracy 0.73 | validation: Loss 0.712643 Accuracy 0.75\n",
      "Epoch 79 | train: Loss 0.701102 Accuracy 0.74 | validation: Loss 0.701851 Accuracy 0.74\n",
      "Epoch 80 | train: Loss 0.697767 Accuracy 0.73 | validation: Loss 0.688841 Accuracy 0.76\n",
      "Epoch 81 | train: Loss 0.691316 Accuracy 0.75 | validation: Loss 0.704740 Accuracy 0.74\n",
      "Epoch 82 | train: Loss 0.694950 Accuracy 0.74 | validation: Loss 0.689122 Accuracy 0.75\n",
      "Epoch 83 | train: Loss 0.687552 Accuracy 0.75 | validation: Loss 0.686768 Accuracy 0.76\n",
      "Epoch 84 | train: Loss 0.686291 Accuracy 0.75 | validation: Loss 0.732790 Accuracy 0.71\n",
      "Epoch 85 | train: Loss 0.686685 Accuracy 0.75 | validation: Loss 0.684288 Accuracy 0.77\n",
      "Epoch 86 | train: Loss 0.681148 Accuracy 0.75 | validation: Loss 0.682708 Accuracy 0.74\n",
      "Epoch 87 | train: Loss 0.678964 Accuracy 0.74 | validation: Loss 0.683181 Accuracy 0.73\n",
      "Epoch 88 | train: Loss 0.681279 Accuracy 0.73 | validation: Loss 0.677932 Accuracy 0.74\n",
      "Epoch 89 | train: Loss 0.672783 Accuracy 0.75 | validation: Loss 0.675664 Accuracy 0.75\n",
      "Epoch 90 | train: Loss 0.667347 Accuracy 0.76 | validation: Loss 0.687195 Accuracy 0.70\n",
      "Epoch 91 | train: Loss 0.664437 Accuracy 0.75 | validation: Loss 0.657746 Accuracy 0.78\n",
      "Epoch 92 | train: Loss 0.665532 Accuracy 0.75 | validation: Loss 0.667544 Accuracy 0.77\n",
      "Epoch 93 | train: Loss 0.660161 Accuracy 0.76 | validation: Loss 0.645864 Accuracy 0.77\n",
      "Epoch 94 | train: Loss 0.657122 Accuracy 0.76 | validation: Loss 0.646694 Accuracy 0.77\n",
      "Epoch 95 | train: Loss 0.654480 Accuracy 0.76 | validation: Loss 0.653338 Accuracy 0.79\n",
      "Epoch 96 | train: Loss 0.658514 Accuracy 0.75 | validation: Loss 0.664294 Accuracy 0.75\n",
      "Epoch 97 | train: Loss 0.653782 Accuracy 0.76 | validation: Loss 0.657365 Accuracy 0.76\n",
      "Epoch 98 | train: Loss 0.642961 Accuracy 0.77 | validation: Loss 0.654390 Accuracy 0.76\n",
      "Epoch 99 | train: Loss 0.646816 Accuracy 0.76 | validation: Loss 0.664026 Accuracy 0.75\n",
      "Epoch 100 | train: Loss 0.646487 Accuracy 0.76 | validation: Loss 0.648201 Accuracy 0.76\n",
      "Epoch 101 | train: Loss 0.646464 Accuracy 0.75 | validation: Loss 0.649728 Accuracy 0.76\n",
      "Epoch 102 | train: Loss 0.635170 Accuracy 0.77 | validation: Loss 0.637824 Accuracy 0.78\n",
      "Epoch 103 | train: Loss 0.635979 Accuracy 0.76 | validation: Loss 0.656215 Accuracy 0.72\n",
      "Epoch 104 | train: Loss 0.636629 Accuracy 0.77 | validation: Loss 0.651254 Accuracy 0.79\n",
      "Epoch 105 | train: Loss 0.630462 Accuracy 0.77 | validation: Loss 0.628421 Accuracy 0.78\n",
      "Epoch 106 | train: Loss 0.627345 Accuracy 0.76 | validation: Loss 0.629246 Accuracy 0.76\n",
      "Epoch 107 | train: Loss 0.629422 Accuracy 0.76 | validation: Loss 0.629884 Accuracy 0.80\n",
      "Epoch 108 | train: Loss 0.620346 Accuracy 0.77 | validation: Loss 0.641356 Accuracy 0.74\n",
      "Epoch 109 | train: Loss 0.635749 Accuracy 0.75 | validation: Loss 0.628272 Accuracy 0.78\n",
      "Epoch 110 | train: Loss 0.620146 Accuracy 0.78 | validation: Loss 0.612100 Accuracy 0.79\n",
      "Epoch 111 | train: Loss 0.624378 Accuracy 0.76 | validation: Loss 0.620567 Accuracy 0.78\n",
      "Epoch 112 | train: Loss 0.619766 Accuracy 0.78 | validation: Loss 0.638530 Accuracy 0.74\n",
      "Epoch 113 | train: Loss 0.613302 Accuracy 0.78 | validation: Loss 0.619498 Accuracy 0.79\n",
      "Epoch 114 | train: Loss 0.610501 Accuracy 0.78 | validation: Loss 0.611159 Accuracy 0.80\n",
      "Epoch 115 | train: Loss 0.612861 Accuracy 0.78 | validation: Loss 0.618526 Accuracy 0.77\n",
      "Epoch 116 | train: Loss 0.604897 Accuracy 0.78 | validation: Loss 0.624833 Accuracy 0.77\n",
      "Epoch 117 | train: Loss 0.605969 Accuracy 0.77 | validation: Loss 0.616669 Accuracy 0.78\n",
      "Epoch 118 | train: Loss 0.605491 Accuracy 0.78 | validation: Loss 0.594265 Accuracy 0.80\n",
      "Epoch 119 | train: Loss 0.599829 Accuracy 0.78 | validation: Loss 0.596876 Accuracy 0.79\n",
      "Epoch 120 | train: Loss 0.597653 Accuracy 0.78 | validation: Loss 0.600102 Accuracy 0.81\n",
      "Epoch 121 | train: Loss 0.601574 Accuracy 0.78 | validation: Loss 0.614659 Accuracy 0.76\n",
      "Epoch 122 | train: Loss 0.605864 Accuracy 0.77 | validation: Loss 0.598636 Accuracy 0.80\n",
      "Epoch 123 | train: Loss 0.590119 Accuracy 0.78 | validation: Loss 0.594487 Accuracy 0.80\n",
      "Epoch 124 | train: Loss 0.596045 Accuracy 0.77 | validation: Loss 0.593750 Accuracy 0.78\n",
      "Epoch 125 | train: Loss 0.598978 Accuracy 0.77 | validation: Loss 0.597842 Accuracy 0.79\n",
      "Epoch 126 | train: Loss 0.589481 Accuracy 0.79 | validation: Loss 0.593768 Accuracy 0.78\n",
      "Epoch 127 | train: Loss 0.595952 Accuracy 0.77 | validation: Loss 0.609406 Accuracy 0.77\n",
      "Epoch 128 | train: Loss 0.589791 Accuracy 0.78 | validation: Loss 0.587081 Accuracy 0.77\n",
      "Epoch 129 | train: Loss 0.582494 Accuracy 0.78 | validation: Loss 0.588813 Accuracy 0.81\n",
      "Epoch 130 | train: Loss 0.584903 Accuracy 0.78 | validation: Loss 0.598993 Accuracy 0.77\n",
      "Epoch 131 | train: Loss 0.584467 Accuracy 0.78 | validation: Loss 0.586681 Accuracy 0.79\n",
      "Epoch 132 | train: Loss 0.574981 Accuracy 0.79 | validation: Loss 0.576108 Accuracy 0.80\n",
      "Epoch 133 | train: Loss 0.577362 Accuracy 0.79 | validation: Loss 0.584653 Accuracy 0.78\n",
      "Epoch 134 | train: Loss 0.574473 Accuracy 0.79 | validation: Loss 0.574494 Accuracy 0.80\n",
      "Epoch 135 | train: Loss 0.569991 Accuracy 0.79 | validation: Loss 0.582216 Accuracy 0.78\n",
      "Epoch 136 | train: Loss 0.574292 Accuracy 0.78 | validation: Loss 0.568434 Accuracy 0.81\n",
      "Epoch 137 | train: Loss 0.568316 Accuracy 0.79 | validation: Loss 0.561066 Accuracy 0.81\n",
      "Epoch 138 | train: Loss 0.566213 Accuracy 0.79 | validation: Loss 0.569791 Accuracy 0.80\n",
      "Epoch 139 | train: Loss 0.566197 Accuracy 0.79 | validation: Loss 0.574908 Accuracy 0.80\n",
      "Epoch 140 | train: Loss 0.565214 Accuracy 0.80 | validation: Loss 0.584645 Accuracy 0.82\n",
      "Epoch 141 | train: Loss 0.570590 Accuracy 0.79 | validation: Loss 0.569212 Accuracy 0.78\n",
      "Epoch 142 | train: Loss 0.559909 Accuracy 0.79 | validation: Loss 0.575304 Accuracy 0.78\n",
      "Epoch 143 | train: Loss 0.566931 Accuracy 0.79 | validation: Loss 0.560939 Accuracy 0.78\n",
      "Epoch 144 | train: Loss 0.566210 Accuracy 0.78 | validation: Loss 0.560600 Accuracy 0.83\n",
      "Epoch 145 | train: Loss 0.553338 Accuracy 0.79 | validation: Loss 0.560845 Accuracy 0.82\n",
      "Epoch 146 | train: Loss 0.557336 Accuracy 0.79 | validation: Loss 0.542617 Accuracy 0.81\n",
      "Epoch 147 | train: Loss 0.557706 Accuracy 0.79 | validation: Loss 0.553489 Accuracy 0.80\n",
      "Epoch 148 | train: Loss 0.553510 Accuracy 0.80 | validation: Loss 0.563933 Accuracy 0.77\n",
      "Epoch 149 | train: Loss 0.560614 Accuracy 0.79 | validation: Loss 0.549716 Accuracy 0.82\n",
      "Epoch 150 | train: Loss 0.553221 Accuracy 0.80 | validation: Loss 0.549645 Accuracy 0.82\n",
      "Epoch 151 | train: Loss 0.546723 Accuracy 0.80 | validation: Loss 0.542049 Accuracy 0.80\n",
      "Epoch 152 | train: Loss 0.547338 Accuracy 0.80 | validation: Loss 0.550931 Accuracy 0.81\n",
      "Epoch 153 | train: Loss 0.545608 Accuracy 0.80 | validation: Loss 0.557314 Accuracy 0.79\n",
      "Epoch 154 | train: Loss 0.548116 Accuracy 0.80 | validation: Loss 0.540777 Accuracy 0.83\n",
      "Epoch 155 | train: Loss 0.546136 Accuracy 0.80 | validation: Loss 0.534333 Accuracy 0.81\n",
      "Epoch 156 | train: Loss 0.540134 Accuracy 0.81 | validation: Loss 0.558433 Accuracy 0.81\n",
      "Epoch 157 | train: Loss 0.538810 Accuracy 0.80 | validation: Loss 0.543211 Accuracy 0.81\n",
      "Epoch 158 | train: Loss 0.539479 Accuracy 0.80 | validation: Loss 0.532284 Accuracy 0.81\n",
      "Epoch 159 | train: Loss 0.546068 Accuracy 0.80 | validation: Loss 0.548399 Accuracy 0.78\n",
      "Epoch 160 | train: Loss 0.529508 Accuracy 0.80 | validation: Loss 0.539572 Accuracy 0.82\n",
      "Epoch 161 | train: Loss 0.535770 Accuracy 0.80 | validation: Loss 0.537576 Accuracy 0.82\n",
      "Epoch 162 | train: Loss 0.547680 Accuracy 0.78 | validation: Loss 0.522326 Accuracy 0.84\n",
      "Epoch 163 | train: Loss 0.530235 Accuracy 0.81 | validation: Loss 0.536501 Accuracy 0.81\n",
      "Epoch 164 | train: Loss 0.531006 Accuracy 0.80 | validation: Loss 0.546448 Accuracy 0.80\n",
      "Epoch 165 | train: Loss 0.533567 Accuracy 0.80 | validation: Loss 0.536857 Accuracy 0.82\n",
      "Epoch 166 | train: Loss 0.528929 Accuracy 0.80 | validation: Loss 0.533889 Accuracy 0.78\n",
      "Epoch 167 | train: Loss 0.531454 Accuracy 0.80 | validation: Loss 0.577330 Accuracy 0.78\n",
      "Epoch 168 | train: Loss 0.529309 Accuracy 0.80 | validation: Loss 0.527561 Accuracy 0.79\n",
      "Epoch 169 | train: Loss 0.523729 Accuracy 0.80 | validation: Loss 0.521427 Accuracy 0.82\n",
      "Epoch 170 | train: Loss 0.529360 Accuracy 0.79 | validation: Loss 0.555471 Accuracy 0.78\n",
      "Epoch 171 | train: Loss 0.520781 Accuracy 0.80 | validation: Loss 0.523488 Accuracy 0.82\n",
      "Epoch 172 | train: Loss 0.516027 Accuracy 0.81 | validation: Loss 0.526994 Accuracy 0.82\n",
      "Epoch 173 | train: Loss 0.518697 Accuracy 0.81 | validation: Loss 0.524148 Accuracy 0.79\n",
      "Epoch 174 | train: Loss 0.515152 Accuracy 0.81 | validation: Loss 0.537655 Accuracy 0.80\n",
      "Epoch 175 | train: Loss 0.516724 Accuracy 0.81 | validation: Loss 0.513977 Accuracy 0.84\n",
      "Epoch 176 | train: Loss 0.513186 Accuracy 0.81 | validation: Loss 0.508234 Accuracy 0.82\n",
      "Epoch 177 | train: Loss 0.507881 Accuracy 0.82 | validation: Loss 0.520914 Accuracy 0.83\n",
      "Epoch 178 | train: Loss 0.513082 Accuracy 0.81 | validation: Loss 0.514346 Accuracy 0.82\n",
      "Epoch 179 | train: Loss 0.510593 Accuracy 0.81 | validation: Loss 0.509185 Accuracy 0.81\n",
      "Epoch 180 | train: Loss 0.510358 Accuracy 0.81 | validation: Loss 0.531511 Accuracy 0.79\n",
      "Epoch 181 | train: Loss 0.513395 Accuracy 0.81 | validation: Loss 0.511702 Accuracy 0.82\n",
      "Epoch 182 | train: Loss 0.505347 Accuracy 0.81 | validation: Loss 0.507245 Accuracy 0.81\n",
      "Epoch 183 | train: Loss 0.501801 Accuracy 0.81 | validation: Loss 0.507465 Accuracy 0.82\n",
      "Epoch 184 | train: Loss 0.514079 Accuracy 0.81 | validation: Loss 0.532715 Accuracy 0.83\n",
      "Epoch 185 | train: Loss 0.505860 Accuracy 0.81 | validation: Loss 0.525184 Accuracy 0.78\n",
      "Epoch 186 | train: Loss 0.497676 Accuracy 0.82 | validation: Loss 0.499593 Accuracy 0.81\n",
      "Epoch 187 | train: Loss 0.502486 Accuracy 0.81 | validation: Loss 0.503648 Accuracy 0.82\n",
      "Epoch 188 | train: Loss 0.496238 Accuracy 0.82 | validation: Loss 0.496644 Accuracy 0.81\n",
      "Epoch 189 | train: Loss 0.493861 Accuracy 0.82 | validation: Loss 0.512343 Accuracy 0.80\n",
      "Epoch 190 | train: Loss 0.500257 Accuracy 0.81 | validation: Loss 0.513316 Accuracy 0.81\n",
      "Epoch 191 | train: Loss 0.507905 Accuracy 0.81 | validation: Loss 0.499336 Accuracy 0.82\n",
      "Epoch 192 | train: Loss 0.493338 Accuracy 0.81 | validation: Loss 0.496239 Accuracy 0.82\n",
      "Epoch 193 | train: Loss 0.494130 Accuracy 0.82 | validation: Loss 0.485308 Accuracy 0.83\n",
      "Epoch 194 | train: Loss 0.493995 Accuracy 0.82 | validation: Loss 0.491163 Accuracy 0.82\n",
      "Epoch 195 | train: Loss 0.490995 Accuracy 0.82 | validation: Loss 0.517994 Accuracy 0.82\n",
      "Epoch 196 | train: Loss 0.489574 Accuracy 0.82 | validation: Loss 0.493461 Accuracy 0.83\n",
      "Epoch 197 | train: Loss 0.485136 Accuracy 0.83 | validation: Loss 0.485817 Accuracy 0.83\n",
      "Epoch 198 | train: Loss 0.486841 Accuracy 0.82 | validation: Loss 0.504700 Accuracy 0.81\n",
      "Epoch 199 | train: Loss 0.484320 Accuracy 0.82 | validation: Loss 0.488035 Accuracy 0.83\n",
      "Epoch 200 | train: Loss 0.484633 Accuracy 0.82 | validation: Loss 0.500698 Accuracy 0.81\n",
      "Epoch 201 | train: Loss 0.482665 Accuracy 0.82 | validation: Loss 0.491975 Accuracy 0.82\n",
      "Epoch 202 | train: Loss 0.481769 Accuracy 0.82 | validation: Loss 0.497959 Accuracy 0.82\n",
      "Epoch 203 | train: Loss 0.481643 Accuracy 0.82 | validation: Loss 0.481069 Accuracy 0.84\n",
      "Epoch 204 | train: Loss 0.479913 Accuracy 0.82 | validation: Loss 0.476447 Accuracy 0.82\n",
      "Epoch 205 | train: Loss 0.477136 Accuracy 0.82 | validation: Loss 0.493809 Accuracy 0.81\n",
      "Epoch 206 | train: Loss 0.487068 Accuracy 0.82 | validation: Loss 0.483933 Accuracy 0.82\n",
      "Epoch 207 | train: Loss 0.479150 Accuracy 0.82 | validation: Loss 0.507463 Accuracy 0.82\n",
      "Epoch 208 | train: Loss 0.475051 Accuracy 0.83 | validation: Loss 0.488260 Accuracy 0.82\n",
      "Epoch 209 | train: Loss 0.476779 Accuracy 0.82 | validation: Loss 0.481935 Accuracy 0.83\n",
      "Epoch 210 | train: Loss 0.471338 Accuracy 0.83 | validation: Loss 0.497093 Accuracy 0.80\n",
      "Epoch 211 | train: Loss 0.482666 Accuracy 0.82 | validation: Loss 0.478631 Accuracy 0.82\n",
      "Epoch 212 | train: Loss 0.471045 Accuracy 0.83 | validation: Loss 0.489042 Accuracy 0.81\n",
      "Epoch 213 | train: Loss 0.473675 Accuracy 0.83 | validation: Loss 0.495508 Accuracy 0.83\n",
      "Epoch 214 | train: Loss 0.468488 Accuracy 0.82 | validation: Loss 0.465372 Accuracy 0.84\n",
      "Epoch 215 | train: Loss 0.475025 Accuracy 0.82 | validation: Loss 0.478132 Accuracy 0.82\n",
      "Epoch 216 | train: Loss 0.472137 Accuracy 0.83 | validation: Loss 0.481392 Accuracy 0.82\n",
      "Epoch 217 | train: Loss 0.467033 Accuracy 0.82 | validation: Loss 0.475186 Accuracy 0.83\n",
      "Epoch 218 | train: Loss 0.459596 Accuracy 0.83 | validation: Loss 0.457357 Accuracy 0.85\n",
      "Epoch 219 | train: Loss 0.462971 Accuracy 0.83 | validation: Loss 0.467424 Accuracy 0.84\n",
      "Epoch 220 | train: Loss 0.460296 Accuracy 0.83 | validation: Loss 0.477873 Accuracy 0.85\n",
      "Epoch 221 | train: Loss 0.463470 Accuracy 0.82 | validation: Loss 0.455908 Accuracy 0.84\n",
      "Epoch 222 | train: Loss 0.459026 Accuracy 0.83 | validation: Loss 0.475051 Accuracy 0.84\n",
      "Epoch 223 | train: Loss 0.461819 Accuracy 0.82 | validation: Loss 0.472450 Accuracy 0.82\n",
      "Epoch 224 | train: Loss 0.458219 Accuracy 0.83 | validation: Loss 0.477870 Accuracy 0.81\n",
      "Epoch 225 | train: Loss 0.455569 Accuracy 0.83 | validation: Loss 0.459916 Accuracy 0.82\n",
      "Epoch 226 | train: Loss 0.454668 Accuracy 0.83 | validation: Loss 0.468357 Accuracy 0.83\n",
      "Epoch 227 | train: Loss 0.450451 Accuracy 0.83 | validation: Loss 0.453486 Accuracy 0.83\n",
      "Epoch 228 | train: Loss 0.455448 Accuracy 0.84 | validation: Loss 0.457068 Accuracy 0.84\n",
      "Epoch 229 | train: Loss 0.449002 Accuracy 0.83 | validation: Loss 0.458369 Accuracy 0.86\n",
      "Epoch 230 | train: Loss 0.447093 Accuracy 0.84 | validation: Loss 0.460631 Accuracy 0.82\n",
      "Epoch 231 | train: Loss 0.450496 Accuracy 0.83 | validation: Loss 0.470006 Accuracy 0.83\n",
      "Epoch 232 | train: Loss 0.447876 Accuracy 0.83 | validation: Loss 0.459381 Accuracy 0.82\n",
      "Epoch 233 | train: Loss 0.448592 Accuracy 0.83 | validation: Loss 0.465113 Accuracy 0.82\n",
      "Epoch 234 | train: Loss 0.449650 Accuracy 0.83 | validation: Loss 0.456711 Accuracy 0.83\n",
      "Epoch 235 | train: Loss 0.447995 Accuracy 0.83 | validation: Loss 0.461432 Accuracy 0.84\n",
      "Epoch 236 | train: Loss 0.442230 Accuracy 0.84 | validation: Loss 0.473912 Accuracy 0.82\n",
      "Epoch 237 | train: Loss 0.446989 Accuracy 0.83 | validation: Loss 0.471231 Accuracy 0.87\n",
      "Epoch 238 | train: Loss 0.446072 Accuracy 0.83 | validation: Loss 0.448221 Accuracy 0.84\n",
      "Epoch 239 | train: Loss 0.438979 Accuracy 0.84 | validation: Loss 0.461107 Accuracy 0.81\n",
      "Epoch 240 | train: Loss 0.439702 Accuracy 0.83 | validation: Loss 0.456908 Accuracy 0.86\n",
      "Epoch 241 | train: Loss 0.441613 Accuracy 0.83 | validation: Loss 0.469887 Accuracy 0.83\n",
      "Epoch 242 | train: Loss 0.442256 Accuracy 0.84 | validation: Loss 0.446394 Accuracy 0.85\n",
      "Epoch 243 | train: Loss 0.436401 Accuracy 0.84 | validation: Loss 0.454656 Accuracy 0.84\n",
      "Epoch 244 | train: Loss 0.442894 Accuracy 0.84 | validation: Loss 0.456801 Accuracy 0.82\n",
      "Epoch 245 | train: Loss 0.434683 Accuracy 0.84 | validation: Loss 0.443398 Accuracy 0.84\n",
      "Epoch 246 | train: Loss 0.442639 Accuracy 0.83 | validation: Loss 0.457485 Accuracy 0.82\n",
      "Epoch 247 | train: Loss 0.439129 Accuracy 0.83 | validation: Loss 0.470922 Accuracy 0.86\n",
      "Epoch 248 | train: Loss 0.434747 Accuracy 0.84 | validation: Loss 0.441882 Accuracy 0.84\n",
      "Epoch 249 | train: Loss 0.429824 Accuracy 0.85 | validation: Loss 0.435025 Accuracy 0.86\n",
      "Epoch 250 | train: Loss 0.427895 Accuracy 0.84 | validation: Loss 0.435420 Accuracy 0.83\n",
      "Epoch 251 | train: Loss 0.429735 Accuracy 0.84 | validation: Loss 0.454213 Accuracy 0.83\n",
      "Epoch 252 | train: Loss 0.430750 Accuracy 0.84 | validation: Loss 0.436626 Accuracy 0.83\n",
      "Epoch 253 | train: Loss 0.436970 Accuracy 0.84 | validation: Loss 0.453225 Accuracy 0.82\n",
      "Epoch 254 | train: Loss 0.427826 Accuracy 0.84 | validation: Loss 0.441459 Accuracy 0.85\n",
      "Epoch 255 | train: Loss 0.427550 Accuracy 0.84 | validation: Loss 0.421903 Accuracy 0.85\n",
      "Epoch 256 | train: Loss 0.429519 Accuracy 0.84 | validation: Loss 0.433019 Accuracy 0.85\n",
      "Epoch 257 | train: Loss 0.427692 Accuracy 0.84 | validation: Loss 0.456020 Accuracy 0.86\n",
      "Epoch 258 | train: Loss 0.424741 Accuracy 0.84 | validation: Loss 0.423590 Accuracy 0.85\n",
      "Epoch 259 | train: Loss 0.432344 Accuracy 0.83 | validation: Loss 0.425798 Accuracy 0.85\n",
      "Epoch 260 | train: Loss 0.416039 Accuracy 0.85 | validation: Loss 0.423349 Accuracy 0.83\n",
      "Epoch 261 | train: Loss 0.419291 Accuracy 0.85 | validation: Loss 0.435529 Accuracy 0.82\n",
      "Epoch 262 | train: Loss 0.421626 Accuracy 0.85 | validation: Loss 0.434507 Accuracy 0.83\n",
      "Epoch 263 | train: Loss 0.420314 Accuracy 0.85 | validation: Loss 0.444446 Accuracy 0.81\n",
      "Epoch 264 | train: Loss 0.416011 Accuracy 0.85 | validation: Loss 0.433524 Accuracy 0.83\n",
      "Epoch 265 | train: Loss 0.416526 Accuracy 0.85 | validation: Loss 0.426985 Accuracy 0.84\n",
      "Epoch 266 | train: Loss 0.420744 Accuracy 0.85 | validation: Loss 0.434394 Accuracy 0.88\n",
      "Epoch 267 | train: Loss 0.410445 Accuracy 0.85 | validation: Loss 0.429094 Accuracy 0.84\n",
      "Epoch 268 | train: Loss 0.415858 Accuracy 0.84 | validation: Loss 0.426070 Accuracy 0.84\n",
      "Epoch 269 | train: Loss 0.415293 Accuracy 0.84 | validation: Loss 0.410667 Accuracy 0.85\n",
      "Epoch 270 | train: Loss 0.409160 Accuracy 0.85 | validation: Loss 0.417274 Accuracy 0.85\n",
      "Epoch 271 | train: Loss 0.408942 Accuracy 0.85 | validation: Loss 0.427676 Accuracy 0.84\n",
      "Epoch 272 | train: Loss 0.414947 Accuracy 0.84 | validation: Loss 0.425766 Accuracy 0.82\n",
      "Epoch 273 | train: Loss 0.411931 Accuracy 0.84 | validation: Loss 0.443831 Accuracy 0.88\n",
      "Epoch 274 | train: Loss 0.412458 Accuracy 0.85 | validation: Loss 0.429625 Accuracy 0.84\n",
      "Epoch 275 | train: Loss 0.406896 Accuracy 0.85 | validation: Loss 0.404431 Accuracy 0.85\n",
      "Epoch 276 | train: Loss 0.407827 Accuracy 0.85 | validation: Loss 0.423471 Accuracy 0.86\n",
      "Epoch 277 | train: Loss 0.404761 Accuracy 0.86 | validation: Loss 0.407138 Accuracy 0.86\n",
      "Epoch 278 | train: Loss 0.401307 Accuracy 0.86 | validation: Loss 0.415773 Accuracy 0.85\n",
      "Epoch 279 | train: Loss 0.407095 Accuracy 0.85 | validation: Loss 0.419084 Accuracy 0.87\n",
      "Epoch 280 | train: Loss 0.402213 Accuracy 0.85 | validation: Loss 0.407342 Accuracy 0.84\n",
      "Epoch 281 | train: Loss 0.402560 Accuracy 0.85 | validation: Loss 0.416428 Accuracy 0.84\n",
      "Epoch 282 | train: Loss 0.407969 Accuracy 0.85 | validation: Loss 0.427185 Accuracy 0.88\n",
      "Epoch 283 | train: Loss 0.405319 Accuracy 0.85 | validation: Loss 0.420288 Accuracy 0.83\n",
      "Epoch 284 | train: Loss 0.402932 Accuracy 0.86 | validation: Loss 0.423297 Accuracy 0.83\n",
      "Epoch 285 | train: Loss 0.408100 Accuracy 0.84 | validation: Loss 0.411729 Accuracy 0.82\n",
      "Epoch 286 | train: Loss 0.399192 Accuracy 0.86 | validation: Loss 0.426927 Accuracy 0.86\n",
      "Epoch 287 | train: Loss 0.395388 Accuracy 0.85 | validation: Loss 0.403877 Accuracy 0.86\n",
      "Epoch 288 | train: Loss 0.397675 Accuracy 0.85 | validation: Loss 0.418959 Accuracy 0.85\n",
      "Epoch 289 | train: Loss 0.399035 Accuracy 0.85 | validation: Loss 0.417372 Accuracy 0.85\n",
      "Epoch 290 | train: Loss 0.393190 Accuracy 0.85 | validation: Loss 0.402837 Accuracy 0.85\n",
      "Epoch 291 | train: Loss 0.397482 Accuracy 0.85 | validation: Loss 0.397579 Accuracy 0.85\n",
      "Epoch 292 | train: Loss 0.398037 Accuracy 0.86 | validation: Loss 0.389716 Accuracy 0.85\n",
      "Epoch 293 | train: Loss 0.396653 Accuracy 0.85 | validation: Loss 0.395936 Accuracy 0.89\n",
      "Epoch 294 | train: Loss 0.390752 Accuracy 0.86 | validation: Loss 0.409296 Accuracy 0.83\n",
      "Epoch 295 | train: Loss 0.393327 Accuracy 0.86 | validation: Loss 0.400784 Accuracy 0.85\n",
      "Epoch 296 | train: Loss 0.393216 Accuracy 0.85 | validation: Loss 0.387454 Accuracy 0.86\n",
      "Epoch 297 | train: Loss 0.395323 Accuracy 0.85 | validation: Loss 0.400982 Accuracy 0.86\n",
      "Epoch 298 | train: Loss 0.390534 Accuracy 0.86 | validation: Loss 0.401133 Accuracy 0.85\n",
      "Epoch 299 | train: Loss 0.389887 Accuracy 0.85 | validation: Loss 0.395867 Accuracy 0.85\n",
      "Epoch 300 | train: Loss 0.382583 Accuracy 0.86 | validation: Loss 0.412248 Accuracy 0.85\n",
      "Epoch 301 | train: Loss 0.394702 Accuracy 0.85 | validation: Loss 0.426713 Accuracy 0.84\n",
      "Epoch 302 | train: Loss 0.390076 Accuracy 0.86 | validation: Loss 0.395019 Accuracy 0.85\n",
      "Epoch 303 | train: Loss 0.384939 Accuracy 0.86 | validation: Loss 0.423664 Accuracy 0.87\n",
      "Epoch 304 | train: Loss 0.381896 Accuracy 0.86 | validation: Loss 0.404326 Accuracy 0.86\n",
      "Epoch 305 | train: Loss 0.385961 Accuracy 0.87 | validation: Loss 0.394187 Accuracy 0.83\n",
      "Epoch 306 | train: Loss 0.384219 Accuracy 0.86 | validation: Loss 0.394993 Accuracy 0.85\n",
      "Epoch 307 | train: Loss 0.381943 Accuracy 0.86 | validation: Loss 0.393982 Accuracy 0.87\n",
      "Epoch 308 | train: Loss 0.386233 Accuracy 0.85 | validation: Loss 0.390528 Accuracy 0.88\n",
      "Epoch 309 | train: Loss 0.388363 Accuracy 0.86 | validation: Loss 0.413931 Accuracy 0.86\n",
      "Epoch 310 | train: Loss 0.380593 Accuracy 0.86 | validation: Loss 0.380099 Accuracy 0.87\n",
      "Epoch 311 | train: Loss 0.387188 Accuracy 0.86 | validation: Loss 0.432098 Accuracy 0.82\n",
      "Epoch 312 | train: Loss 0.389226 Accuracy 0.85 | validation: Loss 0.386532 Accuracy 0.86\n",
      "Epoch 313 | train: Loss 0.379508 Accuracy 0.86 | validation: Loss 0.422166 Accuracy 0.82\n",
      "Epoch 314 | train: Loss 0.378598 Accuracy 0.87 | validation: Loss 0.391648 Accuracy 0.89\n",
      "Epoch 315 | train: Loss 0.372008 Accuracy 0.87 | validation: Loss 0.404270 Accuracy 0.83\n",
      "Epoch 316 | train: Loss 0.376475 Accuracy 0.87 | validation: Loss 0.398416 Accuracy 0.86\n",
      "Epoch 317 | train: Loss 0.381071 Accuracy 0.86 | validation: Loss 0.411545 Accuracy 0.86\n",
      "Epoch 318 | train: Loss 0.380454 Accuracy 0.86 | validation: Loss 0.385813 Accuracy 0.86\n",
      "Epoch 319 | train: Loss 0.371850 Accuracy 0.87 | validation: Loss 0.391995 Accuracy 0.87\n",
      "Epoch 320 | train: Loss 0.376229 Accuracy 0.87 | validation: Loss 0.390098 Accuracy 0.86\n",
      "Epoch 321 | train: Loss 0.373309 Accuracy 0.87 | validation: Loss 0.369520 Accuracy 0.87\n",
      "Epoch 322 | train: Loss 0.373030 Accuracy 0.87 | validation: Loss 0.383560 Accuracy 0.88\n",
      "Epoch 323 | train: Loss 0.371136 Accuracy 0.87 | validation: Loss 0.391653 Accuracy 0.84\n",
      "Epoch 324 | train: Loss 0.370657 Accuracy 0.87 | validation: Loss 0.393648 Accuracy 0.87\n",
      "Epoch 325 | train: Loss 0.380465 Accuracy 0.86 | validation: Loss 0.379057 Accuracy 0.87\n",
      "Epoch 326 | train: Loss 0.367521 Accuracy 0.87 | validation: Loss 0.374936 Accuracy 0.88\n",
      "Epoch 327 | train: Loss 0.363043 Accuracy 0.88 | validation: Loss 0.389578 Accuracy 0.87\n",
      "Epoch 328 | train: Loss 0.364005 Accuracy 0.87 | validation: Loss 0.360187 Accuracy 0.87\n",
      "Epoch 329 | train: Loss 0.366397 Accuracy 0.87 | validation: Loss 0.390497 Accuracy 0.89\n",
      "Epoch 330 | train: Loss 0.366622 Accuracy 0.87 | validation: Loss 0.377852 Accuracy 0.88\n",
      "Epoch 331 | train: Loss 0.362638 Accuracy 0.87 | validation: Loss 0.380254 Accuracy 0.89\n",
      "Epoch 332 | train: Loss 0.363765 Accuracy 0.87 | validation: Loss 0.381837 Accuracy 0.85\n",
      "Epoch 333 | train: Loss 0.363681 Accuracy 0.87 | validation: Loss 0.372095 Accuracy 0.87\n",
      "Epoch 334 | train: Loss 0.369364 Accuracy 0.86 | validation: Loss 0.377585 Accuracy 0.88\n",
      "Epoch 335 | train: Loss 0.366228 Accuracy 0.87 | validation: Loss 0.405283 Accuracy 0.83\n",
      "Epoch 336 | train: Loss 0.362982 Accuracy 0.87 | validation: Loss 0.381436 Accuracy 0.87\n",
      "Epoch 337 | train: Loss 0.360981 Accuracy 0.87 | validation: Loss 0.390022 Accuracy 0.89\n",
      "Epoch 338 | train: Loss 0.359323 Accuracy 0.88 | validation: Loss 0.368752 Accuracy 0.87\n",
      "Epoch 339 | train: Loss 0.356510 Accuracy 0.88 | validation: Loss 0.379735 Accuracy 0.83\n",
      "Epoch 340 | train: Loss 0.359385 Accuracy 0.87 | validation: Loss 0.372847 Accuracy 0.89\n",
      "Epoch 341 | train: Loss 0.359923 Accuracy 0.88 | validation: Loss 0.371016 Accuracy 0.86\n",
      "Epoch 342 | train: Loss 0.362745 Accuracy 0.87 | validation: Loss 0.381110 Accuracy 0.85\n",
      "Epoch 343 | train: Loss 0.354292 Accuracy 0.88 | validation: Loss 0.376980 Accuracy 0.87\n",
      "Epoch 344 | train: Loss 0.359003 Accuracy 0.87 | validation: Loss 0.368805 Accuracy 0.88\n",
      "Epoch 345 | train: Loss 0.355823 Accuracy 0.88 | validation: Loss 0.362151 Accuracy 0.88\n",
      "Epoch 346 | train: Loss 0.351414 Accuracy 0.88 | validation: Loss 0.360087 Accuracy 0.88\n",
      "Epoch 347 | train: Loss 0.353339 Accuracy 0.88 | validation: Loss 0.360578 Accuracy 0.89\n",
      "Epoch 348 | train: Loss 0.353296 Accuracy 0.88 | validation: Loss 0.382916 Accuracy 0.88\n",
      "Epoch 349 | train: Loss 0.356811 Accuracy 0.88 | validation: Loss 0.365386 Accuracy 0.89\n",
      "Epoch 350 | train: Loss 0.353218 Accuracy 0.88 | validation: Loss 0.356854 Accuracy 0.87\n",
      "Epoch 351 | train: Loss 0.349487 Accuracy 0.88 | validation: Loss 0.369411 Accuracy 0.87\n",
      "Epoch 352 | train: Loss 0.348185 Accuracy 0.88 | validation: Loss 0.363216 Accuracy 0.86\n",
      "Epoch 353 | train: Loss 0.349991 Accuracy 0.88 | validation: Loss 0.374305 Accuracy 0.88\n",
      "Epoch 354 | train: Loss 0.360325 Accuracy 0.87 | validation: Loss 0.370115 Accuracy 0.85\n",
      "Epoch 355 | train: Loss 0.355086 Accuracy 0.87 | validation: Loss 0.362095 Accuracy 0.88\n",
      "Epoch 356 | train: Loss 0.344491 Accuracy 0.89 | validation: Loss 0.362925 Accuracy 0.86\n",
      "Epoch 357 | train: Loss 0.361240 Accuracy 0.86 | validation: Loss 0.383236 Accuracy 0.86\n",
      "Epoch 358 | train: Loss 0.349581 Accuracy 0.88 | validation: Loss 0.355216 Accuracy 0.86\n",
      "Epoch 359 | train: Loss 0.348765 Accuracy 0.88 | validation: Loss 0.352507 Accuracy 0.89\n",
      "Epoch 360 | train: Loss 0.347513 Accuracy 0.88 | validation: Loss 0.362023 Accuracy 0.89\n",
      "Epoch 361 | train: Loss 0.342819 Accuracy 0.89 | validation: Loss 0.364287 Accuracy 0.86\n",
      "Epoch 362 | train: Loss 0.350808 Accuracy 0.87 | validation: Loss 0.359104 Accuracy 0.86\n",
      "Epoch 363 | train: Loss 0.341101 Accuracy 0.88 | validation: Loss 0.368592 Accuracy 0.85\n",
      "Epoch 364 | train: Loss 0.340927 Accuracy 0.89 | validation: Loss 0.353081 Accuracy 0.88\n",
      "Epoch 365 | train: Loss 0.341823 Accuracy 0.88 | validation: Loss 0.334309 Accuracy 0.89\n",
      "Epoch 366 | train: Loss 0.339523 Accuracy 0.89 | validation: Loss 0.358035 Accuracy 0.88\n",
      "Epoch 367 | train: Loss 0.343888 Accuracy 0.88 | validation: Loss 0.372297 Accuracy 0.85\n",
      "Epoch 368 | train: Loss 0.338806 Accuracy 0.89 | validation: Loss 0.353362 Accuracy 0.88\n",
      "Epoch 369 | train: Loss 0.344362 Accuracy 0.88 | validation: Loss 0.350729 Accuracy 0.88\n",
      "Epoch 370 | train: Loss 0.337832 Accuracy 0.88 | validation: Loss 0.341705 Accuracy 0.89\n",
      "Epoch 371 | train: Loss 0.339669 Accuracy 0.88 | validation: Loss 0.346622 Accuracy 0.86\n",
      "Epoch 372 | train: Loss 0.346457 Accuracy 0.87 | validation: Loss 0.359593 Accuracy 0.86\n",
      "Epoch 373 | train: Loss 0.341744 Accuracy 0.88 | validation: Loss 0.358116 Accuracy 0.89\n",
      "Epoch 374 | train: Loss 0.335907 Accuracy 0.89 | validation: Loss 0.367474 Accuracy 0.88\n",
      "Epoch 375 | train: Loss 0.342765 Accuracy 0.88 | validation: Loss 0.345153 Accuracy 0.87\n",
      "Epoch 376 | train: Loss 0.340100 Accuracy 0.88 | validation: Loss 0.365792 Accuracy 0.86\n",
      "Epoch 377 | train: Loss 0.336362 Accuracy 0.88 | validation: Loss 0.344845 Accuracy 0.88\n",
      "Epoch 378 | train: Loss 0.340003 Accuracy 0.88 | validation: Loss 0.353541 Accuracy 0.86\n",
      "Epoch 379 | train: Loss 0.337375 Accuracy 0.88 | validation: Loss 0.351032 Accuracy 0.88\n",
      "Epoch 380 | train: Loss 0.329608 Accuracy 0.89 | validation: Loss 0.348727 Accuracy 0.88\n",
      "Epoch 381 | train: Loss 0.332740 Accuracy 0.88 | validation: Loss 0.352436 Accuracy 0.86\n",
      "Epoch 382 | train: Loss 0.332379 Accuracy 0.89 | validation: Loss 0.367340 Accuracy 0.88\n",
      "Epoch 383 | train: Loss 0.337355 Accuracy 0.88 | validation: Loss 0.356447 Accuracy 0.86\n",
      "Epoch 384 | train: Loss 0.329821 Accuracy 0.89 | validation: Loss 0.338244 Accuracy 0.87\n",
      "Epoch 385 | train: Loss 0.328935 Accuracy 0.89 | validation: Loss 0.351309 Accuracy 0.88\n",
      "Epoch 386 | train: Loss 0.331284 Accuracy 0.89 | validation: Loss 0.337432 Accuracy 0.89\n",
      "Epoch 387 | train: Loss 0.324538 Accuracy 0.90 | validation: Loss 0.334163 Accuracy 0.89\n",
      "Epoch 388 | train: Loss 0.327117 Accuracy 0.89 | validation: Loss 0.361366 Accuracy 0.87\n",
      "Epoch 389 | train: Loss 0.331484 Accuracy 0.89 | validation: Loss 0.350924 Accuracy 0.86\n",
      "Epoch 390 | train: Loss 0.326325 Accuracy 0.89 | validation: Loss 0.336955 Accuracy 0.88\n",
      "Epoch 391 | train: Loss 0.331434 Accuracy 0.89 | validation: Loss 0.372662 Accuracy 0.85\n",
      "Epoch 392 | train: Loss 0.331321 Accuracy 0.88 | validation: Loss 0.341223 Accuracy 0.88\n",
      "Epoch 393 | train: Loss 0.325720 Accuracy 0.89 | validation: Loss 0.361055 Accuracy 0.86\n",
      "Epoch 394 | train: Loss 0.333115 Accuracy 0.88 | validation: Loss 0.339474 Accuracy 0.89\n",
      "Epoch 395 | train: Loss 0.323668 Accuracy 0.89 | validation: Loss 0.326315 Accuracy 0.89\n",
      "Epoch 396 | train: Loss 0.322043 Accuracy 0.89 | validation: Loss 0.337658 Accuracy 0.88\n",
      "Epoch 397 | train: Loss 0.323389 Accuracy 0.89 | validation: Loss 0.349499 Accuracy 0.87\n",
      "Epoch 398 | train: Loss 0.320697 Accuracy 0.89 | validation: Loss 0.337713 Accuracy 0.90\n",
      "Epoch 399 | train: Loss 0.318953 Accuracy 0.90 | validation: Loss 0.338048 Accuracy 0.90\n",
      "Epoch 400 | train: Loss 0.320639 Accuracy 0.89 | validation: Loss 0.330259 Accuracy 0.91\n",
      "Epoch 401 | train: Loss 0.320962 Accuracy 0.89 | validation: Loss 0.363299 Accuracy 0.88\n",
      "Epoch 402 | train: Loss 0.321257 Accuracy 0.89 | validation: Loss 0.318480 Accuracy 0.90\n",
      "Epoch 403 | train: Loss 0.317501 Accuracy 0.90 | validation: Loss 0.333804 Accuracy 0.89\n",
      "Epoch 404 | train: Loss 0.318668 Accuracy 0.89 | validation: Loss 0.335197 Accuracy 0.89\n",
      "Epoch 405 | train: Loss 0.318515 Accuracy 0.89 | validation: Loss 0.328694 Accuracy 0.89\n",
      "Epoch 406 | train: Loss 0.325219 Accuracy 0.88 | validation: Loss 0.329573 Accuracy 0.86\n",
      "Epoch 407 | train: Loss 0.326599 Accuracy 0.88 | validation: Loss 0.338451 Accuracy 0.89\n",
      "Epoch 408 | train: Loss 0.315853 Accuracy 0.90 | validation: Loss 0.329145 Accuracy 0.88\n",
      "Epoch 409 | train: Loss 0.317247 Accuracy 0.89 | validation: Loss 0.340590 Accuracy 0.86\n",
      "Epoch 410 | train: Loss 0.315025 Accuracy 0.89 | validation: Loss 0.316317 Accuracy 0.91\n",
      "Epoch 411 | train: Loss 0.316893 Accuracy 0.89 | validation: Loss 0.339316 Accuracy 0.88\n",
      "Epoch 412 | train: Loss 0.317002 Accuracy 0.89 | validation: Loss 0.332895 Accuracy 0.90\n",
      "Epoch 413 | train: Loss 0.312344 Accuracy 0.90 | validation: Loss 0.326286 Accuracy 0.89\n",
      "Epoch 414 | train: Loss 0.320296 Accuracy 0.89 | validation: Loss 0.327544 Accuracy 0.88\n",
      "Epoch 415 | train: Loss 0.312306 Accuracy 0.90 | validation: Loss 0.325874 Accuracy 0.88\n",
      "Epoch 416 | train: Loss 0.312480 Accuracy 0.90 | validation: Loss 0.323316 Accuracy 0.90\n",
      "Epoch 417 | train: Loss 0.314197 Accuracy 0.89 | validation: Loss 0.318424 Accuracy 0.90\n",
      "Epoch 418 | train: Loss 0.309456 Accuracy 0.90 | validation: Loss 0.322396 Accuracy 0.89\n",
      "Epoch 419 | train: Loss 0.312280 Accuracy 0.89 | validation: Loss 0.316345 Accuracy 0.91\n",
      "Epoch 420 | train: Loss 0.308935 Accuracy 0.90 | validation: Loss 0.324743 Accuracy 0.88\n",
      "Epoch 421 | train: Loss 0.309175 Accuracy 0.89 | validation: Loss 0.325778 Accuracy 0.90\n",
      "Epoch 422 | train: Loss 0.307057 Accuracy 0.90 | validation: Loss 0.318695 Accuracy 0.90\n",
      "Epoch 423 | train: Loss 0.308295 Accuracy 0.89 | validation: Loss 0.319816 Accuracy 0.90\n",
      "Epoch 424 | train: Loss 0.307178 Accuracy 0.90 | validation: Loss 0.315683 Accuracy 0.90\n",
      "Epoch 425 | train: Loss 0.307001 Accuracy 0.90 | validation: Loss 0.323023 Accuracy 0.89\n",
      "Epoch 426 | train: Loss 0.307044 Accuracy 0.90 | validation: Loss 0.313703 Accuracy 0.90\n",
      "Epoch 427 | train: Loss 0.304122 Accuracy 0.90 | validation: Loss 0.320702 Accuracy 0.87\n",
      "Epoch 428 | train: Loss 0.304181 Accuracy 0.89 | validation: Loss 0.327488 Accuracy 0.90\n",
      "Epoch 429 | train: Loss 0.305882 Accuracy 0.90 | validation: Loss 0.323480 Accuracy 0.89\n",
      "Epoch 430 | train: Loss 0.317121 Accuracy 0.88 | validation: Loss 0.329654 Accuracy 0.89\n",
      "Epoch 431 | train: Loss 0.306019 Accuracy 0.90 | validation: Loss 0.307158 Accuracy 0.89\n",
      "Epoch 432 | train: Loss 0.306320 Accuracy 0.90 | validation: Loss 0.318063 Accuracy 0.91\n",
      "Epoch 433 | train: Loss 0.300305 Accuracy 0.90 | validation: Loss 0.317378 Accuracy 0.90\n",
      "Epoch 434 | train: Loss 0.313195 Accuracy 0.89 | validation: Loss 0.313308 Accuracy 0.88\n",
      "Epoch 435 | train: Loss 0.303777 Accuracy 0.90 | validation: Loss 0.309907 Accuracy 0.88\n",
      "Epoch 436 | train: Loss 0.299833 Accuracy 0.90 | validation: Loss 0.317018 Accuracy 0.89\n",
      "Epoch 437 | train: Loss 0.301600 Accuracy 0.90 | validation: Loss 0.308644 Accuracy 0.89\n",
      "Epoch 438 | train: Loss 0.304716 Accuracy 0.89 | validation: Loss 0.331446 Accuracy 0.87\n",
      "Epoch 439 | train: Loss 0.304208 Accuracy 0.90 | validation: Loss 0.336195 Accuracy 0.88\n",
      "Epoch 440 | train: Loss 0.300829 Accuracy 0.90 | validation: Loss 0.315870 Accuracy 0.87\n",
      "Epoch 441 | train: Loss 0.306152 Accuracy 0.89 | validation: Loss 0.301378 Accuracy 0.90\n",
      "Epoch 442 | train: Loss 0.296648 Accuracy 0.91 | validation: Loss 0.313164 Accuracy 0.89\n",
      "Epoch 443 | train: Loss 0.296865 Accuracy 0.90 | validation: Loss 0.326421 Accuracy 0.91\n",
      "Epoch 444 | train: Loss 0.305931 Accuracy 0.89 | validation: Loss 0.307842 Accuracy 0.89\n",
      "Epoch 445 | train: Loss 0.299859 Accuracy 0.90 | validation: Loss 0.308675 Accuracy 0.89\n",
      "Epoch 446 | train: Loss 0.298590 Accuracy 0.89 | validation: Loss 0.322601 Accuracy 0.86\n",
      "Epoch 447 | train: Loss 0.296099 Accuracy 0.90 | validation: Loss 0.325266 Accuracy 0.87\n",
      "Epoch 448 | train: Loss 0.300591 Accuracy 0.89 | validation: Loss 0.292652 Accuracy 0.89\n",
      "Epoch 449 | train: Loss 0.295626 Accuracy 0.90 | validation: Loss 0.306191 Accuracy 0.89\n",
      "Epoch 450 | train: Loss 0.305961 Accuracy 0.89 | validation: Loss 0.303071 Accuracy 0.90\n",
      "Epoch 451 | train: Loss 0.293796 Accuracy 0.90 | validation: Loss 0.316047 Accuracy 0.89\n",
      "Epoch 452 | train: Loss 0.298980 Accuracy 0.90 | validation: Loss 0.311758 Accuracy 0.90\n",
      "Epoch 453 | train: Loss 0.293256 Accuracy 0.90 | validation: Loss 0.302811 Accuracy 0.88\n",
      "Epoch 454 | train: Loss 0.296951 Accuracy 0.90 | validation: Loss 0.315373 Accuracy 0.88\n",
      "Epoch 455 | train: Loss 0.297860 Accuracy 0.89 | validation: Loss 0.309602 Accuracy 0.89\n",
      "Epoch 456 | train: Loss 0.294657 Accuracy 0.90 | validation: Loss 0.302858 Accuracy 0.88\n",
      "Epoch 457 | train: Loss 0.291144 Accuracy 0.90 | validation: Loss 0.292110 Accuracy 0.91\n",
      "Epoch 458 | train: Loss 0.294247 Accuracy 0.90 | validation: Loss 0.301317 Accuracy 0.89\n",
      "Epoch 459 | train: Loss 0.296115 Accuracy 0.90 | validation: Loss 0.318676 Accuracy 0.88\n",
      "Epoch 460 | train: Loss 0.289175 Accuracy 0.90 | validation: Loss 0.297138 Accuracy 0.90\n",
      "Epoch 461 | train: Loss 0.292788 Accuracy 0.90 | validation: Loss 0.299802 Accuracy 0.90\n",
      "Epoch 462 | train: Loss 0.290032 Accuracy 0.90 | validation: Loss 0.300264 Accuracy 0.90\n",
      "Epoch 463 | train: Loss 0.292402 Accuracy 0.90 | validation: Loss 0.287675 Accuracy 0.91\n",
      "Epoch 464 | train: Loss 0.291480 Accuracy 0.90 | validation: Loss 0.311190 Accuracy 0.90\n",
      "Epoch 465 | train: Loss 0.289734 Accuracy 0.90 | validation: Loss 0.291192 Accuracy 0.90\n",
      "Epoch 466 | train: Loss 0.294657 Accuracy 0.90 | validation: Loss 0.300228 Accuracy 0.90\n",
      "Epoch 467 | train: Loss 0.289173 Accuracy 0.90 | validation: Loss 0.302356 Accuracy 0.89\n",
      "Epoch 468 | train: Loss 0.286798 Accuracy 0.90 | validation: Loss 0.295459 Accuracy 0.90\n",
      "Epoch 469 | train: Loss 0.286752 Accuracy 0.91 | validation: Loss 0.292430 Accuracy 0.91\n",
      "Epoch 470 | train: Loss 0.282088 Accuracy 0.91 | validation: Loss 0.289563 Accuracy 0.89\n",
      "Epoch 471 | train: Loss 0.283446 Accuracy 0.91 | validation: Loss 0.306040 Accuracy 0.90\n",
      "Epoch 472 | train: Loss 0.283319 Accuracy 0.90 | validation: Loss 0.292110 Accuracy 0.91\n",
      "Epoch 473 | train: Loss 0.283665 Accuracy 0.90 | validation: Loss 0.302198 Accuracy 0.91\n",
      "Epoch 474 | train: Loss 0.285953 Accuracy 0.90 | validation: Loss 0.294802 Accuracy 0.90\n",
      "Epoch 475 | train: Loss 0.282168 Accuracy 0.91 | validation: Loss 0.281627 Accuracy 0.90\n",
      "Epoch 476 | train: Loss 0.282568 Accuracy 0.91 | validation: Loss 0.313187 Accuracy 0.90\n",
      "Epoch 477 | train: Loss 0.280521 Accuracy 0.91 | validation: Loss 0.294269 Accuracy 0.89\n",
      "Epoch 478 | train: Loss 0.287417 Accuracy 0.90 | validation: Loss 0.293212 Accuracy 0.90\n",
      "Epoch 479 | train: Loss 0.287185 Accuracy 0.90 | validation: Loss 0.299618 Accuracy 0.88\n",
      "Epoch 480 | train: Loss 0.285205 Accuracy 0.90 | validation: Loss 0.305926 Accuracy 0.87\n",
      "Epoch 481 | train: Loss 0.286180 Accuracy 0.90 | validation: Loss 0.311348 Accuracy 0.89\n",
      "Epoch 482 | train: Loss 0.281109 Accuracy 0.91 | validation: Loss 0.301519 Accuracy 0.88\n",
      "Epoch 483 | train: Loss 0.283010 Accuracy 0.90 | validation: Loss 0.291230 Accuracy 0.91\n",
      "Epoch 484 | train: Loss 0.283706 Accuracy 0.90 | validation: Loss 0.284230 Accuracy 0.91\n",
      "Epoch 485 | train: Loss 0.278229 Accuracy 0.91 | validation: Loss 0.276053 Accuracy 0.92\n",
      "Epoch 486 | train: Loss 0.275250 Accuracy 0.91 | validation: Loss 0.304937 Accuracy 0.89\n",
      "Epoch 487 | train: Loss 0.284783 Accuracy 0.90 | validation: Loss 0.293126 Accuracy 0.91\n",
      "Epoch 488 | train: Loss 0.287056 Accuracy 0.89 | validation: Loss 0.308824 Accuracy 0.90\n",
      "Epoch 489 | train: Loss 0.278159 Accuracy 0.91 | validation: Loss 0.286328 Accuracy 0.91\n",
      "Epoch 490 | train: Loss 0.280893 Accuracy 0.90 | validation: Loss 0.297495 Accuracy 0.89\n",
      "Epoch 491 | train: Loss 0.280397 Accuracy 0.91 | validation: Loss 0.298302 Accuracy 0.90\n",
      "Epoch 492 | train: Loss 0.278539 Accuracy 0.91 | validation: Loss 0.293577 Accuracy 0.88\n",
      "Epoch 493 | train: Loss 0.277550 Accuracy 0.91 | validation: Loss 0.287248 Accuracy 0.90\n",
      "Epoch 494 | train: Loss 0.272915 Accuracy 0.91 | validation: Loss 0.284018 Accuracy 0.89\n",
      "Epoch 495 | train: Loss 0.274768 Accuracy 0.91 | validation: Loss 0.281464 Accuracy 0.90\n",
      "Epoch 496 | train: Loss 0.275804 Accuracy 0.90 | validation: Loss 0.278781 Accuracy 0.91\n",
      "Epoch 497 | train: Loss 0.272075 Accuracy 0.91 | validation: Loss 0.284430 Accuracy 0.89\n",
      "Epoch 498 | train: Loss 0.276774 Accuracy 0.90 | validation: Loss 0.278878 Accuracy 0.89\n",
      "Epoch 499 | train: Loss 0.269654 Accuracy 0.91 | validation: Loss 0.283072 Accuracy 0.90\n",
      "Epoch 500 | train: Loss 0.270688 Accuracy 0.91 | validation: Loss 0.285461 Accuracy 0.91\n",
      "Epoch 501 | train: Loss 0.271293 Accuracy 0.91 | validation: Loss 0.294265 Accuracy 0.90\n",
      "Epoch 502 | train: Loss 0.275220 Accuracy 0.91 | validation: Loss 0.288335 Accuracy 0.91\n",
      "Epoch 503 | train: Loss 0.277256 Accuracy 0.91 | validation: Loss 0.271543 Accuracy 0.90\n",
      "Epoch 504 | train: Loss 0.274522 Accuracy 0.91 | validation: Loss 0.296620 Accuracy 0.87\n",
      "Epoch 505 | train: Loss 0.275855 Accuracy 0.90 | validation: Loss 0.282925 Accuracy 0.91\n",
      "Epoch 506 | train: Loss 0.270585 Accuracy 0.91 | validation: Loss 0.287838 Accuracy 0.89\n",
      "Epoch 507 | train: Loss 0.269827 Accuracy 0.91 | validation: Loss 0.272029 Accuracy 0.91\n",
      "Epoch 508 | train: Loss 0.266496 Accuracy 0.91 | validation: Loss 0.274489 Accuracy 0.90\n",
      "Epoch 509 | train: Loss 0.265451 Accuracy 0.91 | validation: Loss 0.277520 Accuracy 0.91\n",
      "Epoch 510 | train: Loss 0.268651 Accuracy 0.91 | validation: Loss 0.264248 Accuracy 0.92\n",
      "Epoch 511 | train: Loss 0.270179 Accuracy 0.91 | validation: Loss 0.268899 Accuracy 0.90\n",
      "Epoch 512 | train: Loss 0.266880 Accuracy 0.91 | validation: Loss 0.266817 Accuracy 0.92\n",
      "Epoch 513 | train: Loss 0.265620 Accuracy 0.92 | validation: Loss 0.270461 Accuracy 0.93\n",
      "Epoch 514 | train: Loss 0.265790 Accuracy 0.91 | validation: Loss 0.278884 Accuracy 0.92\n",
      "Epoch 515 | train: Loss 0.261978 Accuracy 0.92 | validation: Loss 0.293199 Accuracy 0.90\n",
      "Epoch 516 | train: Loss 0.279356 Accuracy 0.90 | validation: Loss 0.291635 Accuracy 0.90\n",
      "Epoch 517 | train: Loss 0.271321 Accuracy 0.91 | validation: Loss 0.279222 Accuracy 0.90\n",
      "Epoch 518 | train: Loss 0.268294 Accuracy 0.91 | validation: Loss 0.292657 Accuracy 0.90\n",
      "Epoch 519 | train: Loss 0.264216 Accuracy 0.92 | validation: Loss 0.270908 Accuracy 0.91\n",
      "Epoch 520 | train: Loss 0.263491 Accuracy 0.91 | validation: Loss 0.262458 Accuracy 0.92\n",
      "Epoch 521 | train: Loss 0.265659 Accuracy 0.91 | validation: Loss 0.286239 Accuracy 0.89\n",
      "Epoch 522 | train: Loss 0.264718 Accuracy 0.91 | validation: Loss 0.268776 Accuracy 0.91\n",
      "Epoch 523 | train: Loss 0.261386 Accuracy 0.92 | validation: Loss 0.270817 Accuracy 0.90\n",
      "Epoch 524 | train: Loss 0.263352 Accuracy 0.91 | validation: Loss 0.275866 Accuracy 0.91\n",
      "Epoch 525 | train: Loss 0.262453 Accuracy 0.91 | validation: Loss 0.296732 Accuracy 0.90\n",
      "Epoch 526 | train: Loss 0.262328 Accuracy 0.91 | validation: Loss 0.283691 Accuracy 0.91\n",
      "Epoch 527 | train: Loss 0.264926 Accuracy 0.91 | validation: Loss 0.273335 Accuracy 0.89\n",
      "Epoch 528 | train: Loss 0.268271 Accuracy 0.90 | validation: Loss 0.271428 Accuracy 0.90\n",
      "Epoch 529 | train: Loss 0.257516 Accuracy 0.92 | validation: Loss 0.270571 Accuracy 0.90\n",
      "Epoch 530 | train: Loss 0.258163 Accuracy 0.92 | validation: Loss 0.268553 Accuracy 0.92\n",
      "Epoch 531 | train: Loss 0.258089 Accuracy 0.92 | validation: Loss 0.268416 Accuracy 0.90\n",
      "Epoch 532 | train: Loss 0.254837 Accuracy 0.92 | validation: Loss 0.272214 Accuracy 0.90\n",
      "Epoch 533 | train: Loss 0.258920 Accuracy 0.91 | validation: Loss 0.265187 Accuracy 0.92\n",
      "Epoch 534 | train: Loss 0.262268 Accuracy 0.91 | validation: Loss 0.276853 Accuracy 0.91\n",
      "Epoch 535 | train: Loss 0.259497 Accuracy 0.92 | validation: Loss 0.283513 Accuracy 0.91\n",
      "Epoch 536 | train: Loss 0.266064 Accuracy 0.91 | validation: Loss 0.282918 Accuracy 0.88\n",
      "Epoch 537 | train: Loss 0.272036 Accuracy 0.90 | validation: Loss 0.282255 Accuracy 0.90\n",
      "Epoch 538 | train: Loss 0.257142 Accuracy 0.92 | validation: Loss 0.270187 Accuracy 0.90\n",
      "Epoch 539 | train: Loss 0.263096 Accuracy 0.91 | validation: Loss 0.263921 Accuracy 0.93\n",
      "Epoch 540 | train: Loss 0.263177 Accuracy 0.91 | validation: Loss 0.273938 Accuracy 0.90\n",
      "Epoch 541 | train: Loss 0.261936 Accuracy 0.91 | validation: Loss 0.257993 Accuracy 0.91\n",
      "Epoch 542 | train: Loss 0.257076 Accuracy 0.92 | validation: Loss 0.258535 Accuracy 0.93\n",
      "Epoch 543 | train: Loss 0.251527 Accuracy 0.92 | validation: Loss 0.258255 Accuracy 0.93\n",
      "Epoch 544 | train: Loss 0.257082 Accuracy 0.91 | validation: Loss 0.270597 Accuracy 0.90\n",
      "Epoch 545 | train: Loss 0.249542 Accuracy 0.92 | validation: Loss 0.270573 Accuracy 0.91\n",
      "Epoch 546 | train: Loss 0.254144 Accuracy 0.92 | validation: Loss 0.269381 Accuracy 0.92\n",
      "Epoch 547 | train: Loss 0.256579 Accuracy 0.91 | validation: Loss 0.264933 Accuracy 0.93\n",
      "Epoch 548 | train: Loss 0.250975 Accuracy 0.92 | validation: Loss 0.266718 Accuracy 0.90\n",
      "Epoch 549 | train: Loss 0.258896 Accuracy 0.91 | validation: Loss 0.280068 Accuracy 0.90\n",
      "Epoch 550 | train: Loss 0.259526 Accuracy 0.91 | validation: Loss 0.296124 Accuracy 0.87\n",
      "Epoch 551 | train: Loss 0.255279 Accuracy 0.91 | validation: Loss 0.265088 Accuracy 0.90\n",
      "Epoch 552 | train: Loss 0.252982 Accuracy 0.91 | validation: Loss 0.266716 Accuracy 0.91\n",
      "Epoch 553 | train: Loss 0.255487 Accuracy 0.91 | validation: Loss 0.263282 Accuracy 0.90\n",
      "Epoch 554 | train: Loss 0.258946 Accuracy 0.91 | validation: Loss 0.274692 Accuracy 0.91\n",
      "Epoch 555 | train: Loss 0.250980 Accuracy 0.92 | validation: Loss 0.277124 Accuracy 0.90\n",
      "Epoch 556 | train: Loss 0.247960 Accuracy 0.92 | validation: Loss 0.256974 Accuracy 0.92\n",
      "Epoch 557 | train: Loss 0.250181 Accuracy 0.91 | validation: Loss 0.260850 Accuracy 0.92\n",
      "Epoch 558 | train: Loss 0.264034 Accuracy 0.90 | validation: Loss 0.280888 Accuracy 0.90\n",
      "Epoch 559 | train: Loss 0.250665 Accuracy 0.92 | validation: Loss 0.262620 Accuracy 0.91\n",
      "Epoch 560 | train: Loss 0.252853 Accuracy 0.91 | validation: Loss 0.253201 Accuracy 0.92\n",
      "Epoch 561 | train: Loss 0.250161 Accuracy 0.92 | validation: Loss 0.268579 Accuracy 0.91\n",
      "Epoch 562 | train: Loss 0.250663 Accuracy 0.91 | validation: Loss 0.248905 Accuracy 0.91\n",
      "Epoch 563 | train: Loss 0.249319 Accuracy 0.92 | validation: Loss 0.268961 Accuracy 0.90\n",
      "Epoch 564 | train: Loss 0.259268 Accuracy 0.91 | validation: Loss 0.252095 Accuracy 0.92\n",
      "Epoch 565 | train: Loss 0.247021 Accuracy 0.92 | validation: Loss 0.281646 Accuracy 0.88\n",
      "Epoch 566 | train: Loss 0.244861 Accuracy 0.92 | validation: Loss 0.273103 Accuracy 0.90\n",
      "Epoch 567 | train: Loss 0.244699 Accuracy 0.92 | validation: Loss 0.274662 Accuracy 0.90\n",
      "Epoch 568 | train: Loss 0.249046 Accuracy 0.92 | validation: Loss 0.260032 Accuracy 0.93\n",
      "Epoch 569 | train: Loss 0.254256 Accuracy 0.91 | validation: Loss 0.266082 Accuracy 0.92\n",
      "Epoch 570 | train: Loss 0.249226 Accuracy 0.91 | validation: Loss 0.263791 Accuracy 0.91\n",
      "Epoch 571 | train: Loss 0.245464 Accuracy 0.92 | validation: Loss 0.268259 Accuracy 0.90\n",
      "Epoch 572 | train: Loss 0.245297 Accuracy 0.92 | validation: Loss 0.290567 Accuracy 0.88\n",
      "Epoch 573 | train: Loss 0.248484 Accuracy 0.92 | validation: Loss 0.254328 Accuracy 0.91\n",
      "Epoch 574 | train: Loss 0.244423 Accuracy 0.92 | validation: Loss 0.261077 Accuracy 0.91\n",
      "Epoch 575 | train: Loss 0.241747 Accuracy 0.92 | validation: Loss 0.259752 Accuracy 0.90\n",
      "Epoch 576 | train: Loss 0.246201 Accuracy 0.91 | validation: Loss 0.255996 Accuracy 0.91\n",
      "Epoch 577 | train: Loss 0.241888 Accuracy 0.93 | validation: Loss 0.255587 Accuracy 0.91\n",
      "Epoch 578 | train: Loss 0.241886 Accuracy 0.92 | validation: Loss 0.252920 Accuracy 0.91\n",
      "Epoch 579 | train: Loss 0.241668 Accuracy 0.92 | validation: Loss 0.246511 Accuracy 0.93\n",
      "Epoch 580 | train: Loss 0.241976 Accuracy 0.92 | validation: Loss 0.254014 Accuracy 0.92\n",
      "Epoch 581 | train: Loss 0.252570 Accuracy 0.91 | validation: Loss 0.249706 Accuracy 0.94\n",
      "Epoch 582 | train: Loss 0.240071 Accuracy 0.92 | validation: Loss 0.250833 Accuracy 0.92\n",
      "Epoch 583 | train: Loss 0.239662 Accuracy 0.92 | validation: Loss 0.257458 Accuracy 0.94\n",
      "Epoch 584 | train: Loss 0.240675 Accuracy 0.93 | validation: Loss 0.265243 Accuracy 0.90\n",
      "Epoch 585 | train: Loss 0.242080 Accuracy 0.92 | validation: Loss 0.260854 Accuracy 0.90\n",
      "Epoch 586 | train: Loss 0.240414 Accuracy 0.92 | validation: Loss 0.259553 Accuracy 0.92\n",
      "Epoch 587 | train: Loss 0.242819 Accuracy 0.92 | validation: Loss 0.240051 Accuracy 0.92\n",
      "Epoch 588 | train: Loss 0.239163 Accuracy 0.92 | validation: Loss 0.250586 Accuracy 0.90\n",
      "Epoch 589 | train: Loss 0.239680 Accuracy 0.92 | validation: Loss 0.258771 Accuracy 0.90\n",
      "Epoch 590 | train: Loss 0.243559 Accuracy 0.92 | validation: Loss 0.248905 Accuracy 0.93\n",
      "Epoch 591 | train: Loss 0.236188 Accuracy 0.93 | validation: Loss 0.242792 Accuracy 0.93\n",
      "Epoch 592 | train: Loss 0.236353 Accuracy 0.93 | validation: Loss 0.254337 Accuracy 0.92\n",
      "Epoch 593 | train: Loss 0.235549 Accuracy 0.93 | validation: Loss 0.240849 Accuracy 0.93\n",
      "Epoch 594 | train: Loss 0.240595 Accuracy 0.92 | validation: Loss 0.239011 Accuracy 0.94\n",
      "Epoch 595 | train: Loss 0.235070 Accuracy 0.92 | validation: Loss 0.255731 Accuracy 0.90\n",
      "Epoch 596 | train: Loss 0.237143 Accuracy 0.92 | validation: Loss 0.254676 Accuracy 0.93\n",
      "Epoch 597 | train: Loss 0.246698 Accuracy 0.91 | validation: Loss 0.265575 Accuracy 0.89\n",
      "Epoch 598 | train: Loss 0.236931 Accuracy 0.92 | validation: Loss 0.254052 Accuracy 0.91\n",
      "Epoch 599 | train: Loss 0.241008 Accuracy 0.92 | validation: Loss 0.255296 Accuracy 0.91\n",
      "Epoch 600 | train: Loss 0.235435 Accuracy 0.92 | validation: Loss 0.243783 Accuracy 0.93\n",
      "Epoch 601 | train: Loss 0.231307 Accuracy 0.93 | validation: Loss 0.235716 Accuracy 0.91\n",
      "Epoch 602 | train: Loss 0.233982 Accuracy 0.92 | validation: Loss 0.242840 Accuracy 0.93\n",
      "Epoch 603 | train: Loss 0.237401 Accuracy 0.92 | validation: Loss 0.254659 Accuracy 0.91\n",
      "Epoch 604 | train: Loss 0.234285 Accuracy 0.93 | validation: Loss 0.242910 Accuracy 0.90\n",
      "Epoch 605 | train: Loss 0.233044 Accuracy 0.92 | validation: Loss 0.256563 Accuracy 0.90\n",
      "Epoch 606 | train: Loss 0.231740 Accuracy 0.92 | validation: Loss 0.242679 Accuracy 0.92\n",
      "Epoch 607 | train: Loss 0.239938 Accuracy 0.91 | validation: Loss 0.230949 Accuracy 0.93\n",
      "Epoch 608 | train: Loss 0.229706 Accuracy 0.93 | validation: Loss 0.239274 Accuracy 0.93\n",
      "Epoch 609 | train: Loss 0.238009 Accuracy 0.91 | validation: Loss 0.245495 Accuracy 0.93\n",
      "Epoch 610 | train: Loss 0.231986 Accuracy 0.92 | validation: Loss 0.253501 Accuracy 0.90\n",
      "Epoch 611 | train: Loss 0.229383 Accuracy 0.93 | validation: Loss 0.248187 Accuracy 0.91\n",
      "Epoch 612 | train: Loss 0.232920 Accuracy 0.92 | validation: Loss 0.245860 Accuracy 0.92\n",
      "Epoch 613 | train: Loss 0.228990 Accuracy 0.93 | validation: Loss 0.241969 Accuracy 0.94\n",
      "Epoch 614 | train: Loss 0.229973 Accuracy 0.93 | validation: Loss 0.244943 Accuracy 0.90\n",
      "Epoch 615 | train: Loss 0.231600 Accuracy 0.92 | validation: Loss 0.227918 Accuracy 0.94\n",
      "Epoch 616 | train: Loss 0.230298 Accuracy 0.92 | validation: Loss 0.239411 Accuracy 0.91\n",
      "Epoch 617 | train: Loss 0.228900 Accuracy 0.93 | validation: Loss 0.240675 Accuracy 0.94\n",
      "Epoch 618 | train: Loss 0.230240 Accuracy 0.93 | validation: Loss 0.239120 Accuracy 0.93\n",
      "Epoch 619 | train: Loss 0.231039 Accuracy 0.92 | validation: Loss 0.255657 Accuracy 0.91\n",
      "Epoch 620 | train: Loss 0.242586 Accuracy 0.92 | validation: Loss 0.243568 Accuracy 0.89\n",
      "Epoch 621 | train: Loss 0.237546 Accuracy 0.92 | validation: Loss 0.226753 Accuracy 0.93\n",
      "Epoch 622 | train: Loss 0.232834 Accuracy 0.92 | validation: Loss 0.244673 Accuracy 0.92\n",
      "Epoch 623 | train: Loss 0.233089 Accuracy 0.92 | validation: Loss 0.245133 Accuracy 0.92\n",
      "Epoch 624 | train: Loss 0.228396 Accuracy 0.93 | validation: Loss 0.237434 Accuracy 0.93\n",
      "Epoch 625 | train: Loss 0.234157 Accuracy 0.92 | validation: Loss 0.250033 Accuracy 0.91\n",
      "Epoch 626 | train: Loss 0.233549 Accuracy 0.92 | validation: Loss 0.236488 Accuracy 0.91\n",
      "Epoch 627 | train: Loss 0.228377 Accuracy 0.92 | validation: Loss 0.239559 Accuracy 0.93\n",
      "Epoch 628 | train: Loss 0.231112 Accuracy 0.92 | validation: Loss 0.241739 Accuracy 0.92\n",
      "Epoch 629 | train: Loss 0.222293 Accuracy 0.93 | validation: Loss 0.235755 Accuracy 0.92\n",
      "Epoch 630 | train: Loss 0.228752 Accuracy 0.92 | validation: Loss 0.261748 Accuracy 0.89\n",
      "Epoch 631 | train: Loss 0.228052 Accuracy 0.92 | validation: Loss 0.228106 Accuracy 0.93\n",
      "Epoch 632 | train: Loss 0.232286 Accuracy 0.92 | validation: Loss 0.221605 Accuracy 0.93\n",
      "Epoch 633 | train: Loss 0.224946 Accuracy 0.93 | validation: Loss 0.247044 Accuracy 0.91\n",
      "Epoch 634 | train: Loss 0.227713 Accuracy 0.93 | validation: Loss 0.248405 Accuracy 0.91\n",
      "Epoch 635 | train: Loss 0.220890 Accuracy 0.93 | validation: Loss 0.226265 Accuracy 0.94\n",
      "Epoch 636 | train: Loss 0.227933 Accuracy 0.92 | validation: Loss 0.224807 Accuracy 0.93\n",
      "Epoch 637 | train: Loss 0.225978 Accuracy 0.92 | validation: Loss 0.225872 Accuracy 0.92\n",
      "Epoch 638 | train: Loss 0.225842 Accuracy 0.93 | validation: Loss 0.243842 Accuracy 0.91\n",
      "Epoch 639 | train: Loss 0.229132 Accuracy 0.92 | validation: Loss 0.232582 Accuracy 0.93\n",
      "Epoch 640 | train: Loss 0.223387 Accuracy 0.93 | validation: Loss 0.226240 Accuracy 0.93\n",
      "Epoch 641 | train: Loss 0.223194 Accuracy 0.93 | validation: Loss 0.242710 Accuracy 0.94\n",
      "Epoch 642 | train: Loss 0.228960 Accuracy 0.92 | validation: Loss 0.243116 Accuracy 0.93\n",
      "Epoch 643 | train: Loss 0.218645 Accuracy 0.93 | validation: Loss 0.254306 Accuracy 0.89\n",
      "Epoch 644 | train: Loss 0.226427 Accuracy 0.92 | validation: Loss 0.254390 Accuracy 0.91\n",
      "Epoch 645 | train: Loss 0.223376 Accuracy 0.92 | validation: Loss 0.231685 Accuracy 0.92\n",
      "Epoch 646 | train: Loss 0.220669 Accuracy 0.93 | validation: Loss 0.237823 Accuracy 0.93\n",
      "Epoch 647 | train: Loss 0.223828 Accuracy 0.93 | validation: Loss 0.248841 Accuracy 0.90\n",
      "Epoch 648 | train: Loss 0.231087 Accuracy 0.92 | validation: Loss 0.256202 Accuracy 0.91\n",
      "Epoch 649 | train: Loss 0.223403 Accuracy 0.93 | validation: Loss 0.237953 Accuracy 0.90\n",
      "Epoch 650 | train: Loss 0.220928 Accuracy 0.93 | validation: Loss 0.244017 Accuracy 0.91\n",
      "Epoch 651 | train: Loss 0.221939 Accuracy 0.93 | validation: Loss 0.246291 Accuracy 0.92\n",
      "Epoch 652 | train: Loss 0.222516 Accuracy 0.93 | validation: Loss 0.220903 Accuracy 0.93\n",
      "Epoch 653 | train: Loss 0.221696 Accuracy 0.92 | validation: Loss 0.227755 Accuracy 0.93\n",
      "Epoch 654 | train: Loss 0.220108 Accuracy 0.93 | validation: Loss 0.249218 Accuracy 0.92\n",
      "Epoch 655 | train: Loss 0.222948 Accuracy 0.92 | validation: Loss 0.234086 Accuracy 0.90\n",
      "Epoch 656 | train: Loss 0.220931 Accuracy 0.93 | validation: Loss 0.233892 Accuracy 0.92\n",
      "Epoch 657 | train: Loss 0.218245 Accuracy 0.93 | validation: Loss 0.243775 Accuracy 0.91\n",
      "Epoch 658 | train: Loss 0.218389 Accuracy 0.93 | validation: Loss 0.225171 Accuracy 0.92\n",
      "Epoch 659 | train: Loss 0.217487 Accuracy 0.93 | validation: Loss 0.222218 Accuracy 0.93\n",
      "Epoch 660 | train: Loss 0.218019 Accuracy 0.93 | validation: Loss 0.226031 Accuracy 0.92\n",
      "Epoch 661 | train: Loss 0.216479 Accuracy 0.93 | validation: Loss 0.227149 Accuracy 0.94\n",
      "Epoch 662 | train: Loss 0.227788 Accuracy 0.92 | validation: Loss 0.277816 Accuracy 0.88\n",
      "Epoch 663 | train: Loss 0.226552 Accuracy 0.92 | validation: Loss 0.228673 Accuracy 0.92\n",
      "Epoch 664 | train: Loss 0.220124 Accuracy 0.93 | validation: Loss 0.232640 Accuracy 0.93\n",
      "Epoch 665 | train: Loss 0.216366 Accuracy 0.93 | validation: Loss 0.250460 Accuracy 0.90\n",
      "Epoch 666 | train: Loss 0.231683 Accuracy 0.91 | validation: Loss 0.239760 Accuracy 0.94\n",
      "Epoch 667 | train: Loss 0.215331 Accuracy 0.93 | validation: Loss 0.239039 Accuracy 0.92\n",
      "Epoch 668 | train: Loss 0.215895 Accuracy 0.93 | validation: Loss 0.225817 Accuracy 0.93\n",
      "Epoch 669 | train: Loss 0.210430 Accuracy 0.94 | validation: Loss 0.230981 Accuracy 0.93\n",
      "Epoch 670 | train: Loss 0.212439 Accuracy 0.93 | validation: Loss 0.234978 Accuracy 0.91\n",
      "Epoch 671 | train: Loss 0.219130 Accuracy 0.92 | validation: Loss 0.224118 Accuracy 0.93\n",
      "Epoch 672 | train: Loss 0.215791 Accuracy 0.93 | validation: Loss 0.222750 Accuracy 0.92\n",
      "Epoch 673 | train: Loss 0.218657 Accuracy 0.92 | validation: Loss 0.233200 Accuracy 0.93\n",
      "Epoch 674 | train: Loss 0.211049 Accuracy 0.93 | validation: Loss 0.214946 Accuracy 0.94\n",
      "Epoch 675 | train: Loss 0.213055 Accuracy 0.93 | validation: Loss 0.220585 Accuracy 0.93\n",
      "Epoch 676 | train: Loss 0.210129 Accuracy 0.93 | validation: Loss 0.245351 Accuracy 0.90\n",
      "Epoch 677 | train: Loss 0.212015 Accuracy 0.93 | validation: Loss 0.228844 Accuracy 0.92\n",
      "Epoch 678 | train: Loss 0.216217 Accuracy 0.93 | validation: Loss 0.212775 Accuracy 0.93\n",
      "Epoch 679 | train: Loss 0.214354 Accuracy 0.93 | validation: Loss 0.227848 Accuracy 0.93\n",
      "Epoch 680 | train: Loss 0.211239 Accuracy 0.93 | validation: Loss 0.225045 Accuracy 0.94\n",
      "Epoch 681 | train: Loss 0.208656 Accuracy 0.94 | validation: Loss 0.218575 Accuracy 0.94\n",
      "Epoch 682 | train: Loss 0.210552 Accuracy 0.93 | validation: Loss 0.216569 Accuracy 0.93\n",
      "Epoch 683 | train: Loss 0.213776 Accuracy 0.93 | validation: Loss 0.242003 Accuracy 0.92\n",
      "Epoch 684 | train: Loss 0.212020 Accuracy 0.93 | validation: Loss 0.225266 Accuracy 0.93\n",
      "Epoch 685 | train: Loss 0.205044 Accuracy 0.94 | validation: Loss 0.228353 Accuracy 0.92\n",
      "Epoch 686 | train: Loss 0.213805 Accuracy 0.93 | validation: Loss 0.217154 Accuracy 0.93\n",
      "Epoch 687 | train: Loss 0.208863 Accuracy 0.93 | validation: Loss 0.224428 Accuracy 0.92\n",
      "Epoch 688 | train: Loss 0.214882 Accuracy 0.93 | validation: Loss 0.215001 Accuracy 0.93\n",
      "Epoch 689 | train: Loss 0.212038 Accuracy 0.93 | validation: Loss 0.224064 Accuracy 0.93\n",
      "Epoch 690 | train: Loss 0.205652 Accuracy 0.94 | validation: Loss 0.218225 Accuracy 0.93\n",
      "Epoch 691 | train: Loss 0.211304 Accuracy 0.93 | validation: Loss 0.207734 Accuracy 0.94\n",
      "Epoch 692 | train: Loss 0.205462 Accuracy 0.93 | validation: Loss 0.235367 Accuracy 0.91\n",
      "Epoch 693 | train: Loss 0.209397 Accuracy 0.93 | validation: Loss 0.242952 Accuracy 0.92\n",
      "Epoch 694 | train: Loss 0.214640 Accuracy 0.93 | validation: Loss 0.215925 Accuracy 0.92\n",
      "Epoch 695 | train: Loss 0.209941 Accuracy 0.93 | validation: Loss 0.225180 Accuracy 0.91\n",
      "Epoch 696 | train: Loss 0.212558 Accuracy 0.93 | validation: Loss 0.225003 Accuracy 0.93\n",
      "Epoch 697 | train: Loss 0.216522 Accuracy 0.92 | validation: Loss 0.217579 Accuracy 0.93\n",
      "Epoch 698 | train: Loss 0.206939 Accuracy 0.93 | validation: Loss 0.213898 Accuracy 0.93\n",
      "Epoch 699 | train: Loss 0.212151 Accuracy 0.93 | validation: Loss 0.234240 Accuracy 0.90\n",
      "Epoch 700 | train: Loss 0.210877 Accuracy 0.93 | validation: Loss 0.217656 Accuracy 0.95\n",
      "Epoch 701 | train: Loss 0.204931 Accuracy 0.93 | validation: Loss 0.218854 Accuracy 0.92\n",
      "Epoch 702 | train: Loss 0.208693 Accuracy 0.93 | validation: Loss 0.218654 Accuracy 0.92\n",
      "Epoch 703 | train: Loss 0.207387 Accuracy 0.93 | validation: Loss 0.284888 Accuracy 0.87\n",
      "Epoch 704 | train: Loss 0.214087 Accuracy 0.92 | validation: Loss 0.214782 Accuracy 0.94\n",
      "Epoch 705 | train: Loss 0.210246 Accuracy 0.93 | validation: Loss 0.219434 Accuracy 0.93\n",
      "Epoch 706 | train: Loss 0.205584 Accuracy 0.94 | validation: Loss 0.226466 Accuracy 0.91\n",
      "Epoch 707 | train: Loss 0.206535 Accuracy 0.93 | validation: Loss 0.218332 Accuracy 0.92\n",
      "Epoch 708 | train: Loss 0.209615 Accuracy 0.93 | validation: Loss 0.208972 Accuracy 0.92\n",
      "Epoch 709 | train: Loss 0.202220 Accuracy 0.94 | validation: Loss 0.221106 Accuracy 0.92\n",
      "Epoch 710 | train: Loss 0.203956 Accuracy 0.93 | validation: Loss 0.207172 Accuracy 0.93\n",
      "Epoch 711 | train: Loss 0.204074 Accuracy 0.94 | validation: Loss 0.220014 Accuracy 0.91\n",
      "Epoch 712 | train: Loss 0.203313 Accuracy 0.94 | validation: Loss 0.212151 Accuracy 0.92\n",
      "Epoch 713 | train: Loss 0.202234 Accuracy 0.93 | validation: Loss 0.214307 Accuracy 0.93\n",
      "Epoch 714 | train: Loss 0.201527 Accuracy 0.94 | validation: Loss 0.223147 Accuracy 0.92\n",
      "Epoch 715 | train: Loss 0.204531 Accuracy 0.94 | validation: Loss 0.210043 Accuracy 0.95\n",
      "Epoch 716 | train: Loss 0.202615 Accuracy 0.94 | validation: Loss 0.198328 Accuracy 0.93\n",
      "Epoch 717 | train: Loss 0.199891 Accuracy 0.94 | validation: Loss 0.216149 Accuracy 0.94\n",
      "Epoch 718 | train: Loss 0.200679 Accuracy 0.94 | validation: Loss 0.211691 Accuracy 0.92\n",
      "Epoch 719 | train: Loss 0.196657 Accuracy 0.94 | validation: Loss 0.214870 Accuracy 0.94\n",
      "Epoch 720 | train: Loss 0.197161 Accuracy 0.94 | validation: Loss 0.204938 Accuracy 0.93\n",
      "Epoch 721 | train: Loss 0.205378 Accuracy 0.93 | validation: Loss 0.269395 Accuracy 0.89\n",
      "Epoch 722 | train: Loss 0.207168 Accuracy 0.93 | validation: Loss 0.221164 Accuracy 0.92\n",
      "Epoch 723 | train: Loss 0.201188 Accuracy 0.94 | validation: Loss 0.232738 Accuracy 0.92\n",
      "Epoch 724 | train: Loss 0.202487 Accuracy 0.93 | validation: Loss 0.208489 Accuracy 0.95\n",
      "Epoch 725 | train: Loss 0.199872 Accuracy 0.94 | validation: Loss 0.219616 Accuracy 0.93\n",
      "Epoch 726 | train: Loss 0.199838 Accuracy 0.94 | validation: Loss 0.227763 Accuracy 0.90\n",
      "Epoch 727 | train: Loss 0.204815 Accuracy 0.93 | validation: Loss 0.205392 Accuracy 0.93\n",
      "Epoch 728 | train: Loss 0.198678 Accuracy 0.94 | validation: Loss 0.206704 Accuracy 0.92\n",
      "Epoch 729 | train: Loss 0.201052 Accuracy 0.93 | validation: Loss 0.213427 Accuracy 0.93\n",
      "Epoch 730 | train: Loss 0.206246 Accuracy 0.93 | validation: Loss 0.219320 Accuracy 0.93\n",
      "Epoch 731 | train: Loss 0.199728 Accuracy 0.93 | validation: Loss 0.230157 Accuracy 0.93\n",
      "Epoch 732 | train: Loss 0.202295 Accuracy 0.93 | validation: Loss 0.217141 Accuracy 0.91\n",
      "Epoch 733 | train: Loss 0.204084 Accuracy 0.93 | validation: Loss 0.225579 Accuracy 0.92\n",
      "Epoch 734 | train: Loss 0.198071 Accuracy 0.94 | validation: Loss 0.206000 Accuracy 0.94\n",
      "Epoch 735 | train: Loss 0.196590 Accuracy 0.94 | validation: Loss 0.213094 Accuracy 0.92\n",
      "Epoch 736 | train: Loss 0.200728 Accuracy 0.93 | validation: Loss 0.219368 Accuracy 0.92\n",
      "Epoch 737 | train: Loss 0.201682 Accuracy 0.93 | validation: Loss 0.254780 Accuracy 0.89\n",
      "Epoch 738 | train: Loss 0.212889 Accuracy 0.92 | validation: Loss 0.194549 Accuracy 0.94\n",
      "Epoch 739 | train: Loss 0.195604 Accuracy 0.94 | validation: Loss 0.214416 Accuracy 0.93\n",
      "Epoch 740 | train: Loss 0.198900 Accuracy 0.93 | validation: Loss 0.215479 Accuracy 0.92\n",
      "Epoch 741 | train: Loss 0.197772 Accuracy 0.94 | validation: Loss 0.208501 Accuracy 0.95\n",
      "Epoch 742 | train: Loss 0.195631 Accuracy 0.94 | validation: Loss 0.217864 Accuracy 0.93\n",
      "Epoch 743 | train: Loss 0.198989 Accuracy 0.93 | validation: Loss 0.215071 Accuracy 0.92\n",
      "Epoch 744 | train: Loss 0.192467 Accuracy 0.94 | validation: Loss 0.208303 Accuracy 0.93\n",
      "Epoch 745 | train: Loss 0.193710 Accuracy 0.94 | validation: Loss 0.208481 Accuracy 0.93\n",
      "Epoch 746 | train: Loss 0.195730 Accuracy 0.94 | validation: Loss 0.207312 Accuracy 0.94\n",
      "Epoch 747 | train: Loss 0.199442 Accuracy 0.93 | validation: Loss 0.199892 Accuracy 0.94\n",
      "Epoch 748 | train: Loss 0.195015 Accuracy 0.94 | validation: Loss 0.213015 Accuracy 0.93\n",
      "Epoch 749 | train: Loss 0.196928 Accuracy 0.93 | validation: Loss 0.213507 Accuracy 0.92\n",
      "Epoch 750 | train: Loss 0.197078 Accuracy 0.93 | validation: Loss 0.224036 Accuracy 0.93\n",
      "Epoch 751 | train: Loss 0.195910 Accuracy 0.93 | validation: Loss 0.206428 Accuracy 0.92\n",
      "Epoch 752 | train: Loss 0.194035 Accuracy 0.94 | validation: Loss 0.206426 Accuracy 0.93\n",
      "Epoch 753 | train: Loss 0.192311 Accuracy 0.94 | validation: Loss 0.211312 Accuracy 0.94\n",
      "Epoch 754 | train: Loss 0.194400 Accuracy 0.93 | validation: Loss 0.218853 Accuracy 0.92\n",
      "Epoch 755 | train: Loss 0.194106 Accuracy 0.93 | validation: Loss 0.195043 Accuracy 0.94\n",
      "Epoch 756 | train: Loss 0.197734 Accuracy 0.94 | validation: Loss 0.223656 Accuracy 0.93\n",
      "Epoch 757 | train: Loss 0.200059 Accuracy 0.93 | validation: Loss 0.205434 Accuracy 0.93\n",
      "Epoch 758 | train: Loss 0.195138 Accuracy 0.93 | validation: Loss 0.223635 Accuracy 0.92\n",
      "Epoch 759 | train: Loss 0.194057 Accuracy 0.94 | validation: Loss 0.200460 Accuracy 0.93\n",
      "Epoch 760 | train: Loss 0.192915 Accuracy 0.94 | validation: Loss 0.213648 Accuracy 0.93\n",
      "Epoch 761 | train: Loss 0.188748 Accuracy 0.94 | validation: Loss 0.196281 Accuracy 0.95\n",
      "Epoch 762 | train: Loss 0.190522 Accuracy 0.94 | validation: Loss 0.203174 Accuracy 0.94\n",
      "Epoch 763 | train: Loss 0.191507 Accuracy 0.94 | validation: Loss 0.214121 Accuracy 0.93\n",
      "Epoch 764 | train: Loss 0.190693 Accuracy 0.94 | validation: Loss 0.197509 Accuracy 0.93\n",
      "Epoch 765 | train: Loss 0.190990 Accuracy 0.94 | validation: Loss 0.200420 Accuracy 0.94\n",
      "Epoch 766 | train: Loss 0.194160 Accuracy 0.94 | validation: Loss 0.203101 Accuracy 0.93\n",
      "Epoch 767 | train: Loss 0.195686 Accuracy 0.94 | validation: Loss 0.196133 Accuracy 0.94\n",
      "Epoch 768 | train: Loss 0.198043 Accuracy 0.93 | validation: Loss 0.223970 Accuracy 0.91\n",
      "Epoch 769 | train: Loss 0.196573 Accuracy 0.93 | validation: Loss 0.198207 Accuracy 0.94\n",
      "Epoch 770 | train: Loss 0.191327 Accuracy 0.94 | validation: Loss 0.205733 Accuracy 0.92\n",
      "Epoch 771 | train: Loss 0.190742 Accuracy 0.94 | validation: Loss 0.199810 Accuracy 0.93\n",
      "Epoch 772 | train: Loss 0.186215 Accuracy 0.94 | validation: Loss 0.193582 Accuracy 0.95\n",
      "Epoch 773 | train: Loss 0.190582 Accuracy 0.93 | validation: Loss 0.205428 Accuracy 0.95\n",
      "Epoch 774 | train: Loss 0.185378 Accuracy 0.94 | validation: Loss 0.201388 Accuracy 0.95\n",
      "Epoch 775 | train: Loss 0.186621 Accuracy 0.94 | validation: Loss 0.208451 Accuracy 0.94\n",
      "Epoch 776 | train: Loss 0.187775 Accuracy 0.94 | validation: Loss 0.213982 Accuracy 0.93\n",
      "Epoch 777 | train: Loss 0.199504 Accuracy 0.93 | validation: Loss 0.237354 Accuracy 0.91\n",
      "Epoch 778 | train: Loss 0.193920 Accuracy 0.94 | validation: Loss 0.202679 Accuracy 0.93\n",
      "Epoch 779 | train: Loss 0.182336 Accuracy 0.95 | validation: Loss 0.193127 Accuracy 0.94\n",
      "Epoch 780 | train: Loss 0.187804 Accuracy 0.94 | validation: Loss 0.195119 Accuracy 0.94\n",
      "Epoch 781 | train: Loss 0.185811 Accuracy 0.94 | validation: Loss 0.206457 Accuracy 0.94\n",
      "Epoch 782 | train: Loss 0.189216 Accuracy 0.94 | validation: Loss 0.200968 Accuracy 0.93\n",
      "Epoch 783 | train: Loss 0.185389 Accuracy 0.94 | validation: Loss 0.205469 Accuracy 0.94\n",
      "Epoch 784 | train: Loss 0.187288 Accuracy 0.94 | validation: Loss 0.204532 Accuracy 0.94\n",
      "Epoch 785 | train: Loss 0.185075 Accuracy 0.94 | validation: Loss 0.213761 Accuracy 0.92\n",
      "Epoch 786 | train: Loss 0.181713 Accuracy 0.95 | validation: Loss 0.187591 Accuracy 0.95\n",
      "Epoch 787 | train: Loss 0.181279 Accuracy 0.95 | validation: Loss 0.201687 Accuracy 0.94\n",
      "Epoch 788 | train: Loss 0.186564 Accuracy 0.94 | validation: Loss 0.198780 Accuracy 0.93\n",
      "Epoch 789 | train: Loss 0.186340 Accuracy 0.94 | validation: Loss 0.197891 Accuracy 0.94\n",
      "Epoch 790 | train: Loss 0.189324 Accuracy 0.93 | validation: Loss 0.214229 Accuracy 0.92\n",
      "Epoch 791 | train: Loss 0.183418 Accuracy 0.94 | validation: Loss 0.227587 Accuracy 0.92\n",
      "Epoch 792 | train: Loss 0.184527 Accuracy 0.94 | validation: Loss 0.192011 Accuracy 0.94\n",
      "Epoch 793 | train: Loss 0.180045 Accuracy 0.94 | validation: Loss 0.191304 Accuracy 0.94\n",
      "Epoch 794 | train: Loss 0.182609 Accuracy 0.95 | validation: Loss 0.197613 Accuracy 0.94\n",
      "Epoch 795 | train: Loss 0.179266 Accuracy 0.95 | validation: Loss 0.188051 Accuracy 0.95\n",
      "Epoch 796 | train: Loss 0.183223 Accuracy 0.94 | validation: Loss 0.211032 Accuracy 0.93\n",
      "Epoch 797 | train: Loss 0.181032 Accuracy 0.95 | validation: Loss 0.198382 Accuracy 0.94\n",
      "Epoch 798 | train: Loss 0.181833 Accuracy 0.95 | validation: Loss 0.186753 Accuracy 0.94\n",
      "Epoch 799 | train: Loss 0.180447 Accuracy 0.94 | validation: Loss 0.191708 Accuracy 0.94\n",
      "Epoch 800 | train: Loss 0.186920 Accuracy 0.94 | validation: Loss 0.228903 Accuracy 0.91\n",
      "Epoch 801 | train: Loss 0.185002 Accuracy 0.94 | validation: Loss 0.198356 Accuracy 0.93\n",
      "Epoch 802 | train: Loss 0.186458 Accuracy 0.94 | validation: Loss 0.197389 Accuracy 0.95\n",
      "Epoch 803 | train: Loss 0.183093 Accuracy 0.94 | validation: Loss 0.198376 Accuracy 0.93\n",
      "Epoch 804 | train: Loss 0.186716 Accuracy 0.94 | validation: Loss 0.201289 Accuracy 0.92\n",
      "Epoch 805 | train: Loss 0.181728 Accuracy 0.94 | validation: Loss 0.207131 Accuracy 0.92\n",
      "Epoch 806 | train: Loss 0.187943 Accuracy 0.93 | validation: Loss 0.197588 Accuracy 0.95\n",
      "Epoch 807 | train: Loss 0.176940 Accuracy 0.95 | validation: Loss 0.206071 Accuracy 0.93\n",
      "Epoch 808 | train: Loss 0.183090 Accuracy 0.94 | validation: Loss 0.196116 Accuracy 0.95\n",
      "Epoch 809 | train: Loss 0.180222 Accuracy 0.94 | validation: Loss 0.201349 Accuracy 0.94\n",
      "Epoch 810 | train: Loss 0.179869 Accuracy 0.94 | validation: Loss 0.187105 Accuracy 0.93\n",
      "Epoch 811 | train: Loss 0.174501 Accuracy 0.95 | validation: Loss 0.192654 Accuracy 0.94\n",
      "Epoch 812 | train: Loss 0.178330 Accuracy 0.95 | validation: Loss 0.191881 Accuracy 0.94\n",
      "Epoch 813 | train: Loss 0.178225 Accuracy 0.95 | validation: Loss 0.185797 Accuracy 0.93\n",
      "Epoch 814 | train: Loss 0.176477 Accuracy 0.95 | validation: Loss 0.212392 Accuracy 0.92\n",
      "Epoch 815 | train: Loss 0.180558 Accuracy 0.94 | validation: Loss 0.187620 Accuracy 0.94\n",
      "Epoch 816 | train: Loss 0.180881 Accuracy 0.94 | validation: Loss 0.187809 Accuracy 0.94\n",
      "Epoch 817 | train: Loss 0.181431 Accuracy 0.94 | validation: Loss 0.185614 Accuracy 0.94\n",
      "Epoch 818 | train: Loss 0.178473 Accuracy 0.94 | validation: Loss 0.193329 Accuracy 0.93\n",
      "Epoch 819 | train: Loss 0.183675 Accuracy 0.94 | validation: Loss 0.198739 Accuracy 0.93\n",
      "Epoch 820 | train: Loss 0.177306 Accuracy 0.94 | validation: Loss 0.198009 Accuracy 0.92\n",
      "Epoch 821 | train: Loss 0.183687 Accuracy 0.94 | validation: Loss 0.206530 Accuracy 0.93\n",
      "Epoch 822 | train: Loss 0.185753 Accuracy 0.94 | validation: Loss 0.185412 Accuracy 0.94\n",
      "Epoch 823 | train: Loss 0.178871 Accuracy 0.94 | validation: Loss 0.220047 Accuracy 0.91\n",
      "Epoch 824 | train: Loss 0.181478 Accuracy 0.94 | validation: Loss 0.191420 Accuracy 0.94\n",
      "Epoch 825 | train: Loss 0.175778 Accuracy 0.94 | validation: Loss 0.198740 Accuracy 0.94\n",
      "Epoch 826 | train: Loss 0.181533 Accuracy 0.94 | validation: Loss 0.194604 Accuracy 0.95\n",
      "Epoch 827 | train: Loss 0.175536 Accuracy 0.94 | validation: Loss 0.188091 Accuracy 0.94\n",
      "Epoch 828 | train: Loss 0.186308 Accuracy 0.93 | validation: Loss 0.178761 Accuracy 0.94\n",
      "Epoch 829 | train: Loss 0.174464 Accuracy 0.95 | validation: Loss 0.206201 Accuracy 0.92\n",
      "Epoch 830 | train: Loss 0.178686 Accuracy 0.94 | validation: Loss 0.184150 Accuracy 0.96\n",
      "Epoch 831 | train: Loss 0.176372 Accuracy 0.94 | validation: Loss 0.193856 Accuracy 0.93\n",
      "Epoch 832 | train: Loss 0.178879 Accuracy 0.94 | validation: Loss 0.187067 Accuracy 0.94\n",
      "Epoch 833 | train: Loss 0.176517 Accuracy 0.94 | validation: Loss 0.187269 Accuracy 0.94\n",
      "Epoch 834 | train: Loss 0.173158 Accuracy 0.95 | validation: Loss 0.188345 Accuracy 0.93\n",
      "Epoch 835 | train: Loss 0.175295 Accuracy 0.94 | validation: Loss 0.186589 Accuracy 0.94\n",
      "Epoch 836 | train: Loss 0.174681 Accuracy 0.95 | validation: Loss 0.179318 Accuracy 0.94\n",
      "Epoch 837 | train: Loss 0.175894 Accuracy 0.94 | validation: Loss 0.198235 Accuracy 0.93\n",
      "Epoch 838 | train: Loss 0.177175 Accuracy 0.94 | validation: Loss 0.183602 Accuracy 0.94\n",
      "Epoch 839 | train: Loss 0.174154 Accuracy 0.95 | validation: Loss 0.180057 Accuracy 0.95\n",
      "Epoch 840 | train: Loss 0.176606 Accuracy 0.94 | validation: Loss 0.200658 Accuracy 0.93\n",
      "Epoch 841 | train: Loss 0.178339 Accuracy 0.94 | validation: Loss 0.189729 Accuracy 0.93\n",
      "Epoch 842 | train: Loss 0.172831 Accuracy 0.95 | validation: Loss 0.179564 Accuracy 0.95\n",
      "Epoch 843 | train: Loss 0.175466 Accuracy 0.94 | validation: Loss 0.185549 Accuracy 0.94\n",
      "Epoch 844 | train: Loss 0.172529 Accuracy 0.95 | validation: Loss 0.192657 Accuracy 0.94\n",
      "Epoch 845 | train: Loss 0.178049 Accuracy 0.94 | validation: Loss 0.233909 Accuracy 0.89\n",
      "Epoch 846 | train: Loss 0.186180 Accuracy 0.94 | validation: Loss 0.196977 Accuracy 0.93\n",
      "Epoch 847 | train: Loss 0.170872 Accuracy 0.95 | validation: Loss 0.196803 Accuracy 0.93\n",
      "Epoch 848 | train: Loss 0.171549 Accuracy 0.95 | validation: Loss 0.217897 Accuracy 0.91\n",
      "Epoch 849 | train: Loss 0.174989 Accuracy 0.94 | validation: Loss 0.183981 Accuracy 0.95\n",
      "Epoch 850 | train: Loss 0.174193 Accuracy 0.94 | validation: Loss 0.188185 Accuracy 0.94\n",
      "Epoch 851 | train: Loss 0.170048 Accuracy 0.95 | validation: Loss 0.176850 Accuracy 0.96\n",
      "Epoch 852 | train: Loss 0.167803 Accuracy 0.95 | validation: Loss 0.188486 Accuracy 0.94\n",
      "Epoch 853 | train: Loss 0.169047 Accuracy 0.95 | validation: Loss 0.187852 Accuracy 0.95\n",
      "Epoch 854 | train: Loss 0.168906 Accuracy 0.95 | validation: Loss 0.179584 Accuracy 0.95\n",
      "Epoch 855 | train: Loss 0.177614 Accuracy 0.94 | validation: Loss 0.187432 Accuracy 0.93\n",
      "Epoch 856 | train: Loss 0.170109 Accuracy 0.95 | validation: Loss 0.190973 Accuracy 0.92\n",
      "Epoch 857 | train: Loss 0.168262 Accuracy 0.95 | validation: Loss 0.177827 Accuracy 0.95\n",
      "Epoch 858 | train: Loss 0.166586 Accuracy 0.95 | validation: Loss 0.179301 Accuracy 0.93\n",
      "Epoch 859 | train: Loss 0.170470 Accuracy 0.95 | validation: Loss 0.186178 Accuracy 0.94\n",
      "Epoch 860 | train: Loss 0.174679 Accuracy 0.94 | validation: Loss 0.190367 Accuracy 0.94\n",
      "Epoch 861 | train: Loss 0.174411 Accuracy 0.94 | validation: Loss 0.186191 Accuracy 0.94\n",
      "Epoch 862 | train: Loss 0.176760 Accuracy 0.94 | validation: Loss 0.173342 Accuracy 0.94\n",
      "Epoch 863 | train: Loss 0.167526 Accuracy 0.95 | validation: Loss 0.182043 Accuracy 0.94\n",
      "Epoch 864 | train: Loss 0.173154 Accuracy 0.94 | validation: Loss 0.187728 Accuracy 0.95\n",
      "Epoch 865 | train: Loss 0.168507 Accuracy 0.95 | validation: Loss 0.185215 Accuracy 0.93\n",
      "Epoch 866 | train: Loss 0.166071 Accuracy 0.95 | validation: Loss 0.176509 Accuracy 0.94\n",
      "Epoch 867 | train: Loss 0.172125 Accuracy 0.94 | validation: Loss 0.202978 Accuracy 0.93\n",
      "Epoch 868 | train: Loss 0.172893 Accuracy 0.94 | validation: Loss 0.184247 Accuracy 0.93\n",
      "Epoch 869 | train: Loss 0.169986 Accuracy 0.94 | validation: Loss 0.180296 Accuracy 0.94\n",
      "Epoch 870 | train: Loss 0.177030 Accuracy 0.94 | validation: Loss 0.188682 Accuracy 0.94\n",
      "Epoch 871 | train: Loss 0.169343 Accuracy 0.95 | validation: Loss 0.195484 Accuracy 0.93\n",
      "Epoch 872 | train: Loss 0.167275 Accuracy 0.95 | validation: Loss 0.181284 Accuracy 0.93\n",
      "Epoch 873 | train: Loss 0.170844 Accuracy 0.95 | validation: Loss 0.182888 Accuracy 0.95\n",
      "Epoch 874 | train: Loss 0.174256 Accuracy 0.94 | validation: Loss 0.174005 Accuracy 0.95\n",
      "Epoch 875 | train: Loss 0.171065 Accuracy 0.94 | validation: Loss 0.184912 Accuracy 0.94\n",
      "Epoch 876 | train: Loss 0.167033 Accuracy 0.95 | validation: Loss 0.175013 Accuracy 0.95\n",
      "Epoch 877 | train: Loss 0.169307 Accuracy 0.94 | validation: Loss 0.189125 Accuracy 0.93\n",
      "Epoch 878 | train: Loss 0.165414 Accuracy 0.95 | validation: Loss 0.172866 Accuracy 0.96\n",
      "Epoch 879 | train: Loss 0.164788 Accuracy 0.95 | validation: Loss 0.179923 Accuracy 0.95\n",
      "Epoch 880 | train: Loss 0.163353 Accuracy 0.95 | validation: Loss 0.173429 Accuracy 0.96\n",
      "Epoch 881 | train: Loss 0.164380 Accuracy 0.95 | validation: Loss 0.206427 Accuracy 0.91\n",
      "Epoch 882 | train: Loss 0.176194 Accuracy 0.94 | validation: Loss 0.178787 Accuracy 0.95\n",
      "Epoch 883 | train: Loss 0.171506 Accuracy 0.94 | validation: Loss 0.205995 Accuracy 0.92\n",
      "Epoch 884 | train: Loss 0.167978 Accuracy 0.94 | validation: Loss 0.192407 Accuracy 0.93\n",
      "Epoch 885 | train: Loss 0.168680 Accuracy 0.95 | validation: Loss 0.183582 Accuracy 0.95\n",
      "Epoch 886 | train: Loss 0.165732 Accuracy 0.95 | validation: Loss 0.181375 Accuracy 0.95\n",
      "Epoch 887 | train: Loss 0.165490 Accuracy 0.95 | validation: Loss 0.173665 Accuracy 0.95\n",
      "Epoch 888 | train: Loss 0.165010 Accuracy 0.95 | validation: Loss 0.177107 Accuracy 0.95\n",
      "Epoch 889 | train: Loss 0.166338 Accuracy 0.95 | validation: Loss 0.180732 Accuracy 0.95\n",
      "Epoch 890 | train: Loss 0.164293 Accuracy 0.95 | validation: Loss 0.172322 Accuracy 0.95\n",
      "Epoch 891 | train: Loss 0.168901 Accuracy 0.94 | validation: Loss 0.185565 Accuracy 0.92\n",
      "Epoch 892 | train: Loss 0.166237 Accuracy 0.94 | validation: Loss 0.175620 Accuracy 0.94\n",
      "Epoch 893 | train: Loss 0.162389 Accuracy 0.95 | validation: Loss 0.176382 Accuracy 0.95\n",
      "Epoch 894 | train: Loss 0.162504 Accuracy 0.95 | validation: Loss 0.177809 Accuracy 0.96\n",
      "Epoch 895 | train: Loss 0.166242 Accuracy 0.95 | validation: Loss 0.199489 Accuracy 0.91\n",
      "Epoch 896 | train: Loss 0.166979 Accuracy 0.95 | validation: Loss 0.178080 Accuracy 0.95\n",
      "Epoch 897 | train: Loss 0.162781 Accuracy 0.95 | validation: Loss 0.180171 Accuracy 0.94\n",
      "Epoch 898 | train: Loss 0.163571 Accuracy 0.95 | validation: Loss 0.167038 Accuracy 0.95\n",
      "Epoch 899 | train: Loss 0.163638 Accuracy 0.95 | validation: Loss 0.184534 Accuracy 0.93\n",
      "Epoch 900 | train: Loss 0.165320 Accuracy 0.94 | validation: Loss 0.186277 Accuracy 0.95\n",
      "Epoch 901 | train: Loss 0.160375 Accuracy 0.95 | validation: Loss 0.174588 Accuracy 0.95\n",
      "Epoch 902 | train: Loss 0.163258 Accuracy 0.95 | validation: Loss 0.186454 Accuracy 0.92\n",
      "Epoch 903 | train: Loss 0.162988 Accuracy 0.95 | validation: Loss 0.175285 Accuracy 0.95\n",
      "Epoch 904 | train: Loss 0.161050 Accuracy 0.95 | validation: Loss 0.177364 Accuracy 0.95\n",
      "Epoch 905 | train: Loss 0.177849 Accuracy 0.94 | validation: Loss 0.181767 Accuracy 0.94\n",
      "Epoch 906 | train: Loss 0.162354 Accuracy 0.95 | validation: Loss 0.185332 Accuracy 0.93\n",
      "Epoch 907 | train: Loss 0.163213 Accuracy 0.95 | validation: Loss 0.180931 Accuracy 0.93\n",
      "Epoch 908 | train: Loss 0.167410 Accuracy 0.94 | validation: Loss 0.171669 Accuracy 0.96\n",
      "Epoch 909 | train: Loss 0.168327 Accuracy 0.95 | validation: Loss 0.178341 Accuracy 0.93\n",
      "Epoch 910 | train: Loss 0.160809 Accuracy 0.95 | validation: Loss 0.162989 Accuracy 0.96\n",
      "Epoch 911 | train: Loss 0.159662 Accuracy 0.95 | validation: Loss 0.192767 Accuracy 0.92\n",
      "Epoch 912 | train: Loss 0.163065 Accuracy 0.95 | validation: Loss 0.193048 Accuracy 0.91\n",
      "Epoch 913 | train: Loss 0.163208 Accuracy 0.95 | validation: Loss 0.173222 Accuracy 0.96\n",
      "Epoch 914 | train: Loss 0.162217 Accuracy 0.95 | validation: Loss 0.181664 Accuracy 0.93\n",
      "Epoch 915 | train: Loss 0.164221 Accuracy 0.95 | validation: Loss 0.178731 Accuracy 0.95\n",
      "Epoch 916 | train: Loss 0.165850 Accuracy 0.95 | validation: Loss 0.164403 Accuracy 0.95\n",
      "Epoch 917 | train: Loss 0.166171 Accuracy 0.94 | validation: Loss 0.199972 Accuracy 0.92\n",
      "Epoch 918 | train: Loss 0.163588 Accuracy 0.95 | validation: Loss 0.166258 Accuracy 0.96\n",
      "Epoch 919 | train: Loss 0.157622 Accuracy 0.95 | validation: Loss 0.180591 Accuracy 0.93\n",
      "Epoch 920 | train: Loss 0.159461 Accuracy 0.95 | validation: Loss 0.160391 Accuracy 0.96\n",
      "Epoch 921 | train: Loss 0.158057 Accuracy 0.95 | validation: Loss 0.169243 Accuracy 0.96\n",
      "Epoch 922 | train: Loss 0.161866 Accuracy 0.95 | validation: Loss 0.167881 Accuracy 0.94\n",
      "Epoch 923 | train: Loss 0.161851 Accuracy 0.95 | validation: Loss 0.163830 Accuracy 0.95\n",
      "Epoch 924 | train: Loss 0.165007 Accuracy 0.95 | validation: Loss 0.167634 Accuracy 0.96\n",
      "Epoch 925 | train: Loss 0.163751 Accuracy 0.95 | validation: Loss 0.161745 Accuracy 0.96\n",
      "Epoch 926 | train: Loss 0.157963 Accuracy 0.95 | validation: Loss 0.171356 Accuracy 0.94\n",
      "Epoch 927 | train: Loss 0.163072 Accuracy 0.95 | validation: Loss 0.168171 Accuracy 0.95\n",
      "Epoch 928 | train: Loss 0.159130 Accuracy 0.95 | validation: Loss 0.160111 Accuracy 0.96\n",
      "Epoch 929 | train: Loss 0.154543 Accuracy 0.95 | validation: Loss 0.160428 Accuracy 0.96\n",
      "Epoch 930 | train: Loss 0.156179 Accuracy 0.96 | validation: Loss 0.170732 Accuracy 0.94\n",
      "Epoch 931 | train: Loss 0.157752 Accuracy 0.95 | validation: Loss 0.164706 Accuracy 0.95\n",
      "Epoch 932 | train: Loss 0.157459 Accuracy 0.95 | validation: Loss 0.165351 Accuracy 0.95\n",
      "Epoch 933 | train: Loss 0.155730 Accuracy 0.95 | validation: Loss 0.166162 Accuracy 0.96\n",
      "Epoch 934 | train: Loss 0.158674 Accuracy 0.95 | validation: Loss 0.168866 Accuracy 0.94\n",
      "Epoch 935 | train: Loss 0.160143 Accuracy 0.95 | validation: Loss 0.173143 Accuracy 0.96\n",
      "Epoch 936 | train: Loss 0.158103 Accuracy 0.95 | validation: Loss 0.170777 Accuracy 0.95\n",
      "Epoch 937 | train: Loss 0.157275 Accuracy 0.95 | validation: Loss 0.159277 Accuracy 0.96\n",
      "Epoch 938 | train: Loss 0.167158 Accuracy 0.94 | validation: Loss 0.179261 Accuracy 0.94\n",
      "Epoch 939 | train: Loss 0.163493 Accuracy 0.94 | validation: Loss 0.181339 Accuracy 0.94\n",
      "Epoch 940 | train: Loss 0.157586 Accuracy 0.95 | validation: Loss 0.188350 Accuracy 0.93\n",
      "Epoch 941 | train: Loss 0.160288 Accuracy 0.95 | validation: Loss 0.171471 Accuracy 0.94\n",
      "Epoch 942 | train: Loss 0.154475 Accuracy 0.95 | validation: Loss 0.181882 Accuracy 0.93\n",
      "Epoch 943 | train: Loss 0.162024 Accuracy 0.95 | validation: Loss 0.173931 Accuracy 0.93\n",
      "Epoch 944 | train: Loss 0.151457 Accuracy 0.95 | validation: Loss 0.166829 Accuracy 0.95\n",
      "Epoch 945 | train: Loss 0.161590 Accuracy 0.95 | validation: Loss 0.159399 Accuracy 0.95\n",
      "Epoch 946 | train: Loss 0.159719 Accuracy 0.95 | validation: Loss 0.169168 Accuracy 0.95\n",
      "Epoch 947 | train: Loss 0.171070 Accuracy 0.94 | validation: Loss 0.176273 Accuracy 0.94\n",
      "Epoch 948 | train: Loss 0.167890 Accuracy 0.94 | validation: Loss 0.219746 Accuracy 0.92\n",
      "Epoch 949 | train: Loss 0.165522 Accuracy 0.94 | validation: Loss 0.222528 Accuracy 0.90\n",
      "Epoch 950 | train: Loss 0.165930 Accuracy 0.94 | validation: Loss 0.182641 Accuracy 0.93\n",
      "Epoch 951 | train: Loss 0.156018 Accuracy 0.95 | validation: Loss 0.160947 Accuracy 0.96\n",
      "Epoch 952 | train: Loss 0.156197 Accuracy 0.95 | validation: Loss 0.169432 Accuracy 0.95\n",
      "Epoch 953 | train: Loss 0.156641 Accuracy 0.95 | validation: Loss 0.174648 Accuracy 0.93\n",
      "Epoch 954 | train: Loss 0.152988 Accuracy 0.96 | validation: Loss 0.166166 Accuracy 0.94\n",
      "Epoch 955 | train: Loss 0.153388 Accuracy 0.95 | validation: Loss 0.173628 Accuracy 0.95\n",
      "Epoch 956 | train: Loss 0.151216 Accuracy 0.96 | validation: Loss 0.170710 Accuracy 0.94\n",
      "Epoch 957 | train: Loss 0.155562 Accuracy 0.95 | validation: Loss 0.164772 Accuracy 0.95\n",
      "Epoch 958 | train: Loss 0.159149 Accuracy 0.95 | validation: Loss 0.168823 Accuracy 0.94\n",
      "Epoch 959 | train: Loss 0.151430 Accuracy 0.95 | validation: Loss 0.160430 Accuracy 0.95\n",
      "Epoch 960 | train: Loss 0.157964 Accuracy 0.95 | validation: Loss 0.175010 Accuracy 0.94\n",
      "Epoch 961 | train: Loss 0.163297 Accuracy 0.95 | validation: Loss 0.182743 Accuracy 0.93\n",
      "Epoch 962 | train: Loss 0.153485 Accuracy 0.95 | validation: Loss 0.171841 Accuracy 0.94\n",
      "Epoch 963 | train: Loss 0.152778 Accuracy 0.95 | validation: Loss 0.160089 Accuracy 0.95\n",
      "Epoch 964 | train: Loss 0.159298 Accuracy 0.95 | validation: Loss 0.166296 Accuracy 0.94\n",
      "Epoch 965 | train: Loss 0.156026 Accuracy 0.95 | validation: Loss 0.157142 Accuracy 0.96\n",
      "Epoch 966 | train: Loss 0.152941 Accuracy 0.95 | validation: Loss 0.165159 Accuracy 0.95\n",
      "Epoch 967 | train: Loss 0.157666 Accuracy 0.95 | validation: Loss 0.158733 Accuracy 0.93\n",
      "Epoch 968 | train: Loss 0.152281 Accuracy 0.95 | validation: Loss 0.165132 Accuracy 0.95\n",
      "Epoch 969 | train: Loss 0.159453 Accuracy 0.95 | validation: Loss 0.172717 Accuracy 0.93\n",
      "Epoch 970 | train: Loss 0.159646 Accuracy 0.94 | validation: Loss 0.168098 Accuracy 0.94\n",
      "Epoch 971 | train: Loss 0.155384 Accuracy 0.95 | validation: Loss 0.164754 Accuracy 0.95\n",
      "Epoch 972 | train: Loss 0.151555 Accuracy 0.95 | validation: Loss 0.162324 Accuracy 0.95\n",
      "Epoch 973 | train: Loss 0.150236 Accuracy 0.95 | validation: Loss 0.162360 Accuracy 0.95\n",
      "Epoch 974 | train: Loss 0.150016 Accuracy 0.95 | validation: Loss 0.173352 Accuracy 0.95\n",
      "Epoch 975 | train: Loss 0.150463 Accuracy 0.95 | validation: Loss 0.155563 Accuracy 0.96\n",
      "Epoch 976 | train: Loss 0.150163 Accuracy 0.95 | validation: Loss 0.169811 Accuracy 0.96\n",
      "Epoch 977 | train: Loss 0.152139 Accuracy 0.95 | validation: Loss 0.156552 Accuracy 0.95\n",
      "Epoch 978 | train: Loss 0.160168 Accuracy 0.94 | validation: Loss 0.165539 Accuracy 0.95\n",
      "Epoch 979 | train: Loss 0.147747 Accuracy 0.96 | validation: Loss 0.162016 Accuracy 0.95\n",
      "Epoch 980 | train: Loss 0.152108 Accuracy 0.95 | validation: Loss 0.162533 Accuracy 0.94\n",
      "Epoch 981 | train: Loss 0.154760 Accuracy 0.95 | validation: Loss 0.155403 Accuracy 0.95\n",
      "Epoch 982 | train: Loss 0.152189 Accuracy 0.95 | validation: Loss 0.161740 Accuracy 0.96\n",
      "Epoch 983 | train: Loss 0.148146 Accuracy 0.95 | validation: Loss 0.153592 Accuracy 0.95\n",
      "Epoch 984 | train: Loss 0.154795 Accuracy 0.95 | validation: Loss 0.157860 Accuracy 0.95\n",
      "Epoch 985 | train: Loss 0.146250 Accuracy 0.96 | validation: Loss 0.157452 Accuracy 0.95\n",
      "Epoch 986 | train: Loss 0.152127 Accuracy 0.95 | validation: Loss 0.164614 Accuracy 0.95\n",
      "Epoch 987 | train: Loss 0.146027 Accuracy 0.96 | validation: Loss 0.159244 Accuracy 0.95\n",
      "Epoch 988 | train: Loss 0.149475 Accuracy 0.95 | validation: Loss 0.160563 Accuracy 0.95\n",
      "Epoch 989 | train: Loss 0.149371 Accuracy 0.95 | validation: Loss 0.157624 Accuracy 0.96\n",
      "Epoch 990 | train: Loss 0.152101 Accuracy 0.95 | validation: Loss 0.158410 Accuracy 0.95\n",
      "Epoch 991 | train: Loss 0.147046 Accuracy 0.96 | validation: Loss 0.162844 Accuracy 0.95\n",
      "Epoch 992 | train: Loss 0.147925 Accuracy 0.95 | validation: Loss 0.175167 Accuracy 0.93\n",
      "Epoch 993 | train: Loss 0.149876 Accuracy 0.95 | validation: Loss 0.157054 Accuracy 0.95\n",
      "Epoch 994 | train: Loss 0.152982 Accuracy 0.95 | validation: Loss 0.160138 Accuracy 0.96\n",
      "Epoch 995 | train: Loss 0.151598 Accuracy 0.95 | validation: Loss 0.173123 Accuracy 0.95\n",
      "Epoch 996 | train: Loss 0.154030 Accuracy 0.95 | validation: Loss 0.160716 Accuracy 0.95\n",
      "Epoch 997 | train: Loss 0.151446 Accuracy 0.95 | validation: Loss 0.180526 Accuracy 0.93\n",
      "Epoch 998 | train: Loss 0.148983 Accuracy 0.95 | validation: Loss 0.155581 Accuracy 0.96\n",
      "Epoch 999 | train: Loss 0.151847 Accuracy 0.95 | validation: Loss 0.194511 Accuracy 0.92\n"
     ]
    }
   ],
   "source": [
    "import data_setup, engine, model_architecture\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "luzern_data = data_setup.Dataloader()\n",
    "data_path = Path(\"D:\\All Python\\All_Big_raw_Data\\LOS prediction\\Traffic Dataset\\DataLoader\")\n",
    "BATCH_SIZE = 128\n",
    "city = \"luzern\"\n",
    "train_dataloader, val_dataloader, test_dataloader = luzern_data.create_dataloaders(data_dir=data_path, city_code=city,\n",
    "                                                                                   batch_size=BATCH_SIZE)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "INPUT_SHAPE = 6\n",
    "HIDDEN_UNITS = 64\n",
    "OUTPUT_SHAPE = len(luzern_data.class_names)\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "model1 = model_architecture.LOS_Classification_V0(in_put=INPUT_SHAPE, hidden_units=HIDDEN_UNITS, out_put=OUTPUT_SHAPE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model1.parameters(), lr=0.0001)\n",
    "\n",
    "model1_results = engine.train(model=model1,\n",
    "                              train_dataloader=train_dataloader,\n",
    "                              val_dataloader=val_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              optimizer=optimizer,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              experiment_name=\"luzern_V0\",\n",
    "                              model_name=\"Neural_Net\",\n",
    "                              early_stop_patience=None,\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c945f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
